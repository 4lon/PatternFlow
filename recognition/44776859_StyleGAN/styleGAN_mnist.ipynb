{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://thispersondoesnotexist.com/\n",
    "\n",
    "https://github.com/NVlabs/stylegan\n",
    "https://arxiv.org/abs/1812.04948\n",
    "https://github.com/NVlabs/stylegan2\n",
    "https://arxiv.org/abs/1912.04958\n",
    "\n",
    "https://machinelearningmastery.com/introduction-to-style-generative-adversarial-network-stylegan/\n",
    "StyleGan | Lecture 71 (Part 1) | Applied Deep Learning\n",
    "https://www.youtube.com/watch?v=hfFAUFsglLc\n",
    "AI generated faces - StyleGAN explained!\n",
    "https://www.youtube.com/watch?v=4LNO8nLxF4Y\n",
    "\n",
    "Affine appears to be == self-similar transformation via width/height shift, shear, zoom, etc.?\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/apply_affine_transform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.5.0\n",
      "Tensorflow CUDA is available.\n",
      "Tensorflow set GPU memory growth to True.\n",
      "Tensorflow is executing eagerly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Suppress tensorflow logging:\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f'Tensorflow version: {tf.__version__}')\n",
    "print(f'Tensorflow CUDA {\"is\" if tf.test.is_built_with_cuda() else \"is not\"} available.')\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print('Tensorflow set GPU memory growth to True.')\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "print(f'Tensorflow {\"is\" if tf.executing_eagerly() else \"is not\"} executing eagerly.')\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import Layer, Input, Add, Dense, Flatten, Reshape, LeakyReLU, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling, Normalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import imageio\n",
    "import time\n",
    "\n",
    "dark1 = '#191b26'\n",
    "dark2 = '#151722'\n",
    "white1 = '#fff'\n",
    "white2 = '#b3b5be'\n",
    "red1 = '#cd6152'\n",
    "red2 = '#cd6152'\n",
    "green1 = '#67a39a'\n",
    "green2 = '#253037'\n",
    "blue1 = '#4a64fd'\n",
    "blue2 = '#1b1f39'\n",
    "\n",
    "mpl.rcParams['text.color'] = white2\n",
    "mpl.rcParams['axes.labelcolor'] = white2\n",
    "mpl.rcParams['axes.facecolor'] = dark1\n",
    "mpl.rcParams['axes.edgecolor'] = white2\n",
    "mpl.rcParams['figure.facecolor'] = dark2\n",
    "mpl.rcParams['xtick.color'] = white2\n",
    "mpl.rcParams['ytick.color'] = white2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Define constants.\n",
    "BATCH_SIZE = 256\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_DIMS = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "NUM_CHANNELS = 1\n",
    "\n",
    "GRAPH_INTERVAL = 40\n",
    "PRINT_INTERVAL = 10\n",
    "\n",
    "EPOCHS = 999\n",
    "START_DIMS = (7,7)\n",
    "# LINEAR_SHAPE = (7,7,7)\n",
    "# LINEAR_SIZE = np.prod(START_DIMS + (IMAGE_SIZE,))      # Size of Dense layer in Generator.\n",
    "# LATENT_DIMS = 343           # Number of random numbers to use at Generator input.\n",
    "NUM_GENERATED_SAMPLES = 8   # Number of sample fake images to generate to visualise training.\n",
    "\n",
    "# This set of latent inputs will be used for each training graph output,\n",
    "# so we can visualise progress on the same latent samples.\n",
    "SEED = tf.random.normal([NUM_GENERATED_SAMPLES, IMAGE_SIZE])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAYAAACHjumMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAG90lEQVR4nO3dP2sUWBSH4ZllJRA7McRSggiKiIqdqS20M4JgoWAaQUTxO1gIFiKohX8RYxMUO2tJ0mhlG8RGRUMghUWiNrPdLgvqPbvObybq85STw8mtXm5xmemOjU/0OgABfwz7AMCvS2CAGIEBYgQGiBEYIObP7/1xeen1oM4B/MTGxie++rkbDBAjMECMwAAxAgPECAwQIzBAjMAAMQIDxAgMECMwQIzAADECA8QIDBAjMECMwAAxAgPECAwQIzBAjMAAMQIDxAgMECMwQIzAADECA8QIDBAjMECMwAAxAgPECAwQIzBAjMAAMQIDxAgMECMwQIzAADECA8QIDBAjMECMwAAxAgPECAwQIzBAjMAAMQIDxAgMECMwQIzAADECA8QIDBAjMECMwAAxAgPECAwQIzBAjMAAMQIDxPw57APwdfv27SvNXblypTkzOTn5g6f5R7fbLc09ePCgNHfu3LnmzMrKSmkX648bDBAjMECMwAAxAgPECAwQIzBAjMAAMQIDxAgMEOMl7xBcvny5OXPmzJnSrk+fPjVnlpeXS7sqNmzYUJo7fvx4aW7r1q3NmYMHD5Z2ra2tleYYHDcYIEZggBiBAWIEBogRGCBGYIAYgQFiBAaI8dCuj6anp0tzFy5caM4sLi6Wdp04caI58/z589Kuik2bNpXmKo8JO51O5+TJk82Z0dHR0i4P7dYfNxggRmCAGIEBYgQGiBEYIEZggBiBAWIEBogRGCDGS96i/fv3N2euXbtW2vXy5cvmzKFDh0q73r9/X5rrl+oP0b979y58En4GbjBAjMAAMQIDxAgMECMwQIzAADECA8QIDBDjoV3R3bt3mzPV320+e/Zsc2bQD+iqdu/eXZo7f/58aW5ubq458/Hjx9Ku7du3N2du375d2vXw4cPmzI0bN0q7fmduMECMwAAxAgPECAwQIzBAjMAAMQIDxAgMECMwQIyXvEVbtmxpznS73dKu+fn5Hz3O0CwtLZXmTp8+XZqbmZlpzoyOjpZ2zc7ONmeqL5EXFhZKc3yfGwwQIzBAjMAAMQIDxAgMECMwQIzAADECA8R4aFe0trbWnOn1egM4yXBVH9pVHtB1Op3OyMhIc+bOnTulXbt27WrOvHnzprTr1q1bpTm+zw0GiBEYIEZggBiBAWIEBogRGCBGYIAYgQFiBAaI8ZK36NKlS82Zq1evlnZNT083Z6o/0r5eVV7odjqdzv3795szR48e/dHj/G1ubq409+rVq779z9+ZGwwQIzBAjMAAMQIDxAgMECMwQIzAADECA8R4aFf09OnT5szq6mpp1/Xr15szz549K+0a9IOw6u9EV7/msp+P6CoeP3480P/3u3ODAWIEBogRGCBGYIAYgQFiBAaIERggRmCAGIEBYrpj4xPf/MX25aXXgzzLT29qaqo0Nzs725xZWFgo7aq8mH3x4kVp15cvX5ozFy9eLO06cuRIaa6fFhcXmzM7duwYwEl+P2PjE1/93A0GiBEYIEZggBiBAWIEBogRGCBGYIAYgQFiBAaI8Z28ffTo0aPS3L1795ozx44dK+06cOBAaa5fut1uaW5+fr40t3HjxubMnj17+vo/GRw3GCBGYIAYgQFiBAaIERggRmCAGIEBYgQGiPHQbghOnTrVnHny5Elp1+rqanNmcnKytGtkZKQ5U3kk2Ol0Oh8+fCjNVR7H9Xrf/FbXf/HD9uuPGwwQIzBAjMAAMQIDxAgMECMwQIzAADECA8QIDBDTHRuf+OYzyeWl14M8C7+QzZs3l+aWlpaaM2/fvi3t2rt3b3NmZWWltIv/Zmx84qufu8EAMQIDxAgMECMwQIzAADECA8QIDBAjMECMr8xk3bt582ZpziO69ccNBogRGCBGYIAYgQFiBAaIERggRmCAGIEBYgQGiPGSl4jDhw/3bdfnz5/7tovBcoMBYgQGiBEYIEZggBiBAWIEBogRGCBGYIAYD+2ImJqaKs11u93wSRgmNxggRmCAGIEBYgQGiBEYIEZggBiBAWIEBogRGCDGS14itm3bVprr9XrhkzBMbjBAjMAAMQIDxAgMECMwQIzAADECA8QIDBAjMECMwAAxAgPECAwQIzBAjMAAMQIDxAgMECMwQIzAADG+MpN1b2ZmZthH4H9ygwFiBAaIERggRmCAGIEBYgQGiBEYIEZggBgP7Riqubm55szy8vIATkKCGwwQIzBAjMAAMQIDxAgMECMwQIzAADECA8QIDBDjJS8RO3fuHPYRWAfcYIAYgQFiBAaIERggRmCAGIEBYgQGiBEYIEZggBiBAWIEBogRGCBGYIAYgQFiBAaIERggRmCAGIEBYr77lZlj4xODOgfwC3KDAWIEBogRGCBGYIAYgQFiBAaI+QvEwuAvHSAosQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader = tfds.load('mnist', as_supervised=True)\n",
    "image_dataset = dataloader['train']\n",
    "# Cast [0,255] images to [-1,1].\n",
    "image_dataset = image_dataset.map(lambda image, label: Rescaling(scale=1./127.5, offset=-1)(image))\n",
    "image_dataset = image_dataset.shuffle(BATCH_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "batch = image_dataset.take(1)\n",
    "image = list(batch.as_numpy_iterator())[0][0]\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up generator and discrimator.\n",
    "Display sample fake image from generator (untrained).\n",
    "Display sample prediction from discriminator (untrained)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input b and g should be 1x1xC\n",
    "class AdaInstanceNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 axis=-1,\n",
    "                 momentum=0.99,\n",
    "                 epsilon=1e-3,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 **kwargs):\n",
    "        super(AdaInstanceNormalization, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "        self.momentum = momentum\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        dim = input_shape[0][self.axis]\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                                                        'input tensor should have a defined dimension '\n",
    "                                                        'but the layer received an input with shape ' +\n",
    "                             str(input_shape[0]) + '.')\n",
    "\n",
    "        super(AdaInstanceNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        input_shape = K.int_shape(inputs[0])\n",
    "        reduction_axes = list(range(0, len(input_shape)))\n",
    "\n",
    "        # Reshape (batch*len) y vectors into (batch,1,1,len) to support batched multiplication.\n",
    "        beta = tf.reshape(inputs[1], shape=(input_shape[0], 1, 1, input_shape[-1]))\n",
    "        gamma = tf.reshape(inputs[2], shape=(input_shape[0], 1, 1, input_shape[-1]))\n",
    "\n",
    "        if self.axis is not None:\n",
    "            del reduction_axes[self.axis]\n",
    "\n",
    "        del reduction_axes[0]\n",
    "        mean = K.mean(inputs[0], reduction_axes, keepdims=True)\n",
    "        stddev = K.std(inputs[0], reduction_axes, keepdims=True) + self.epsilon\n",
    "        normed = (inputs[0] - mean) / stddev\n",
    "\n",
    "        return normed * gamma + beta\n",
    "\n",
    "    # def get_config(self):\n",
    "    #     config = {\n",
    "    #         'axis': self.axis,\n",
    "    #         'momentum': self.momentum,\n",
    "    #         'epsilon': self.epsilon,\n",
    "    #         'center': self.center,\n",
    "    #         'scale': self.scale\n",
    "    #     }\n",
    "    #     base_config = super(AdaInstanceNormalization, self).get_config()\n",
    "    #     return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "\n",
    "class ConstLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(ConstLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        if input_shape[0] is not None:\n",
    "            return tf.ones(shape=((input_shape[0],) + START_DIMS + (IMAGE_SIZE,)))\n",
    "        return tf.ones(shape=((1,) + START_DIMS + (IMAGE_SIZE,)))\n",
    "\n",
    "\n",
    "def make_generator_model():\n",
    "    # init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    inputs = Input(shape=(IMAGE_SIZE,), dtype=tf.float32, name='gen_input')\n",
    "\n",
    "    # Mapping network\n",
    "    dense1 = Dense(IMAGE_SIZE, activation='linear')(inputs)\n",
    "    dense2 = Dense(IMAGE_SIZE, activation='linear')(dense1)\n",
    "    dense3 = Dense(IMAGE_SIZE, activation='linear')(dense2)\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------\n",
    "\n",
    "    const = ConstLayer()(inputs)\n",
    "\n",
    "    a1scale = Dense(IMAGE_SIZE, activation='linear')(dense3)\n",
    "    a1bias = Dense(IMAGE_SIZE, activation='linear')(dense3)\n",
    "\n",
    "    ada1 = AdaInstanceNormalization(input_shape=(7, 7, IMAGE_SIZE))([const, a1bias, a1scale])\n",
    "\n",
    "    conv1 = Conv2DTranspose(filters=IMAGE_SIZE, kernel_size=(3, 3), strides=(1,1), padding='same')(ada1)\n",
    "    act1 = LeakyReLU(alpha=0.2)(conv1)\n",
    "\n",
    "    ada2 = AdaInstanceNormalization(input_shape=(7,7, IMAGE_SIZE))([act1, a1bias, a1scale])\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------\n",
    "\n",
    "    conv2 = Conv2DTranspose(filters=IMAGE_SIZE, kernel_size=(3, 3), strides=(2, 2), padding='same')(ada2)\n",
    "    act2 = LeakyReLU(alpha=0.2)(conv2)\n",
    "\n",
    "    a2scale = Dense(IMAGE_SIZE, activation='linear')(dense3)\n",
    "    a2bias = Dense(IMAGE_SIZE, activation='linear')(dense3)\n",
    "\n",
    "    ada3 = AdaInstanceNormalization(input_shape=(14,14, IMAGE_SIZE))([act2, a2bias, a2scale])\n",
    "\n",
    "    conv3 = Conv2DTranspose(filters=IMAGE_SIZE, kernel_size=(3, 3), strides=(2, 2), padding='same')(ada3)\n",
    "    act3 = LeakyReLU(alpha=0.2)(conv3)\n",
    "\n",
    "    ada4 = AdaInstanceNormalization(input_shape=(28,28, IMAGE_SIZE))([act3, a2bias, a2scale])\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------\n",
    "\n",
    "    conv4 = Conv2DTranspose(filters=1, kernel_size=(1, 1), strides=(1, 1), padding='same', activation='tanh')(ada4)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv4, name='synthesiser')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_discriminator_model():\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(28, (3,3), strides=(2,2), padding='same', kernel_initializer=init,\n",
    "                            input_shape=(IMAGE_DIMS + (NUM_CHANNELS,)), name='conv1'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # model.add(Conv2D(28, (3,3), strides=(2,2),\n",
    "    #                  padding='same', kernel_initializer=init, name='conv2'))\n",
    "    # model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(28, (3,3), strides=(2,2),\n",
    "                     padding='same', kernel_initializer=init, name='conv3'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid', name='disc_output'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_latent_coordinates(batches, dimensions):\n",
    "    return tf.random.normal([batches, dimensions])\n",
    "\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "# ones = tf.ones((1, LINEAR_SIZE))\n",
    "latent = generate_latent_coordinates(BATCH_SIZE, IMAGE_SIZE)\n",
    "\n",
    "# Demonstrate generator and discriminator on 1 random noise sample.\n",
    "generated_image = generator(latent, training=False)\n",
    "decision = discriminator(generated_image, training=False)\n",
    "img = generated_image.numpy()[0]\n",
    "plt.title(f'Decision: {decision[0][0]}')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def disc_loss(real_output, fake_output):\n",
    "    \"\"\"\n",
    "    How well the discriminator can distinguish real from fake images.\n",
    "    :param real_output: Classifications of real images.\n",
    "    :param fake_output: Classifications of fake images.\n",
    "    :return: Loss on real images, loss on fake images.\n",
    "    \"\"\"\n",
    "    # Compare predictions on real images to array of ones.\n",
    "    real_loss = BinaryCrossentropy()(tf.ones_like(real_output), real_output)\n",
    "    # Compare predictions on fake images to array of zeroes.\n",
    "    fake_loss = BinaryCrossentropy()(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss, fake_loss\n",
    "\n",
    "\n",
    "def gen_loss(fake_output):\n",
    "    \"\"\"\n",
    "    How well the generator can fool the discriminator.\n",
    "    We get this loss from the discriminator, and pass it to the generator.\n",
    "    :param fake_output: Discriminator classification of fake images.\n",
    "    :return: Loss of discriminator on fake images, inverted.\n",
    "    \"\"\"\n",
    "    # Compare discriminator decisions to array of ones.\n",
    "    return BinaryCrossentropy()(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "\n",
    "gen_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "disc_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "checkpoint_dir = 'C:/Pred_Models'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=gen_optimizer,\n",
    "                                 discriminator_optimizer=disc_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-39-4be90e8b2a3a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     98\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     99\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 100\u001B[1;33m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mEPOCHS\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    101\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-39-4be90e8b2a3a>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(dataset, epochs)\u001B[0m\n\u001B[0;32m     86\u001B[0m                 \u001B[0md_fake_losses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0md_fake_loss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     87\u001B[0m                 \u001B[0mdisplay\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclear_output\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 88\u001B[1;33m                 \u001B[0mplot_gan_progress\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mg_losses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0md_real_losses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0md_fake_losses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgenerator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mSEED\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     89\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mPRINT_INTERVAL\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m                 print(f'Epoch {epoch:04}: batch {i:04}/{len(dataset)} | g_loss: {g_loss} | '\n",
      "\u001B[1;32m<ipython-input-39-4be90e8b2a3a>\u001B[0m in \u001B[0;36mplot_gan_progress\u001B[1;34m(g_losses, d_real_losses, d_fake_losses, model, epoch, batch, test_input)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msavefig\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf'C:/Pred_Images/preds_at_epoch{epoch:04}_batch{batch:04}.png'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 32\u001B[1;33m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001B[0m in \u001B[0;36mshow\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    351\u001B[0m     \"\"\"\n\u001B[0;32m    352\u001B[0m     \u001B[0m_warn_if_gui_out_of_main_thread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 353\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_backend_mod\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    354\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    355\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001B[0m in \u001B[0;36mshow\u001B[1;34m(close, block)\u001B[0m\n\u001B[0;32m     39\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mfigure_manager\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mGcf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_all_fig_managers\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m             display(\n\u001B[0m\u001B[0;32m     42\u001B[0m                 \u001B[0mfigure_manager\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcanvas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m                 \u001B[0mmetadata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0m_fetch_figure_metadata\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfigure_manager\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcanvas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001B[0m in \u001B[0;36mdisplay\u001B[1;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001B[0m\n\u001B[0;32m    311\u001B[0m             \u001B[0mpublish_display_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetadata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmetadata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    312\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 313\u001B[1;33m             \u001B[0mformat_dict\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmd_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minclude\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minclude\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexclude\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mexclude\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    314\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mformat_dict\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    315\u001B[0m                 \u001B[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001B[0m in \u001B[0;36mformat\u001B[1;34m(self, obj, include, exclude)\u001B[0m\n\u001B[0;32m    178\u001B[0m             \u001B[0mmd\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    179\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 180\u001B[1;33m                 \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mformatter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    181\u001B[0m             \u001B[1;32mexcept\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    182\u001B[0m                 \u001B[1;31m# FIXME: log the exception\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\decorator.py\u001B[0m in \u001B[0;36mfun\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m    229\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mkwsyntax\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    230\u001B[0m                 \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkw\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfix\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkw\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 231\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mcaller\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mextras\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    232\u001B[0m     \u001B[0mfun\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m     \u001B[0mfun\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__doc__\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__doc__\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001B[0m in \u001B[0;36mcatch_format_error\u001B[1;34m(method, self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    222\u001B[0m     \u001B[1;34m\"\"\"show traceback on failed format call\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    223\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 224\u001B[1;33m         \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    225\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mNotImplementedError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    226\u001B[0m         \u001B[1;31m# don't warn on NotImplementedErrors\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, obj)\u001B[0m\n\u001B[0;32m    339\u001B[0m                 \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    340\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 341\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mprinter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    342\u001B[0m             \u001B[1;31m# Finally look for special method names\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    343\u001B[0m             \u001B[0mmethod\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_real_method\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprint_method\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(fig)\u001B[0m\n\u001B[0;32m    246\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    247\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;34m'png'\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mformats\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 248\u001B[1;33m         \u001B[0mpng_formatter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfor_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mFigure\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mlambda\u001B[0m \u001B[0mfig\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mprint_figure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'png'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    249\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;34m'retina'\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mformats\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;34m'png2x'\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mformats\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    250\u001B[0m         \u001B[0mpng_formatter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfor_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mFigure\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mlambda\u001B[0m \u001B[0mfig\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mretina_figure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001B[0m in \u001B[0;36mprint_figure\u001B[1;34m(fig, fmt, bbox_inches, **kwargs)\u001B[0m\n\u001B[0;32m    130\u001B[0m         \u001B[0mFigureCanvasBase\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 132\u001B[1;33m     \u001B[0mfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcanvas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprint_figure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbytes_io\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    133\u001B[0m     \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbytes_io\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetvalue\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    134\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mfmt\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'svg'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001B[0m in \u001B[0;36mprint_figure\u001B[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001B[0m\n\u001B[0;32m   2191\u001B[0m                            else suppress())\n\u001B[0;32m   2192\u001B[0m                     \u001B[1;32mwith\u001B[0m \u001B[0mctx\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2193\u001B[1;33m                         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdraw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrenderer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2194\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2195\u001B[0m                     bbox_inches = self.figure.get_tightbbox(\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001B[0m in \u001B[0;36mdraw_wrapper\u001B[1;34m(artist, renderer, *args, **kwargs)\u001B[0m\n\u001B[0;32m     39\u001B[0m                 \u001B[0mrenderer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart_filter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mdraw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0martist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrenderer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     42\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0martist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_agg_filter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001B[0m in \u001B[0;36mdraw\u001B[1;34m(self, renderer)\u001B[0m\n\u001B[0;32m   1861\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1862\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdraw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrenderer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1863\u001B[1;33m             mimage._draw_list_compositing_images(\n\u001B[0m\u001B[0;32m   1864\u001B[0m                 renderer, self, artists, self.suppressComposite)\n\u001B[0;32m   1865\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001B[0m in \u001B[0;36m_draw_list_compositing_images\u001B[1;34m(renderer, parent, artists, suppress_composite)\u001B[0m\n\u001B[0;32m    129\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mnot_composite\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mhas_images\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    130\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[1;32min\u001B[0m \u001B[0martists\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 131\u001B[1;33m             \u001B[0ma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdraw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrenderer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    132\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    133\u001B[0m         \u001B[1;31m# Composite any adjacent images together\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001B[0m in \u001B[0;36mdraw_wrapper\u001B[1;34m(artist, renderer, *args, **kwargs)\u001B[0m\n\u001B[0;32m     39\u001B[0m                 \u001B[0mrenderer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart_filter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mdraw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0martist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrenderer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     42\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0martist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_agg_filter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*inner_args, **inner_kwargs)\u001B[0m\n\u001B[0;32m    409\u001B[0m                          \u001B[1;32melse\u001B[0m \u001B[0mdeprecation_addendum\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    410\u001B[0m                 **kwargs)\n\u001B[1;32m--> 411\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minner_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0minner_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    412\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    413\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001B[0m in \u001B[0;36mdraw\u001B[1;34m(self, renderer, inframe)\u001B[0m\n\u001B[0;32m   2745\u001B[0m             \u001B[0mrenderer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstop_rasterizing\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2746\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2747\u001B[1;33m         \u001B[0mmimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_draw_list_compositing_images\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrenderer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0martists\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2748\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2749\u001B[0m         \u001B[0mrenderer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose_group\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'axes'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001B[0m in \u001B[0;36m_draw_list_compositing_images\u001B[1;34m(renderer, parent, artists, suppress_composite)\u001B[0m\n\u001B[0;32m    129\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mnot_composite\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mhas_images\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    130\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[1;32min\u001B[0m \u001B[0martists\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 131\u001B[1;33m             \u001B[0ma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdraw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrenderer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    132\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    133\u001B[0m         \u001B[1;31m# Composite any adjacent images together\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001B[0m in \u001B[0;36mdraw_wrapper\u001B[1;34m(artist, renderer, *args, **kwargs)\u001B[0m\n\u001B[0;32m     39\u001B[0m                 \u001B[0mrenderer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart_filter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mdraw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0martist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrenderer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     42\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0martist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_agg_filter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001B[0m in \u001B[0;36mdraw\u001B[1;34m(self, renderer, *args, **kwargs)\u001B[0m\n\u001B[0;32m    641\u001B[0m                 \u001B[0mrenderer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdraw_image\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ml\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrans\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    642\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 643\u001B[1;33m             im, l, b, trans = self.make_image(\n\u001B[0m\u001B[0;32m    644\u001B[0m                 renderer, renderer.get_image_magnification())\n\u001B[0;32m    645\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mim\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001B[0m in \u001B[0;36mmake_image\u001B[1;34m(self, renderer, magnification, unsampled)\u001B[0m\n\u001B[0;32m    926\u001B[0m         clip = ((self.get_clip_box() or self.axes.bbox) if self.get_clip_on()\n\u001B[0;32m    927\u001B[0m                 else self.figure.bbox)\n\u001B[1;32m--> 928\u001B[1;33m         return self._make_image(self._A, bbox, transformed_bbox, clip,\n\u001B[0m\u001B[0;32m    929\u001B[0m                                 magnification, unsampled=unsampled)\n\u001B[0;32m    930\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001B[0m in \u001B[0;36m_make_image\u001B[1;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001B[0m\n\u001B[0;32m    559\u001B[0m             \u001B[1;31m# (of int or float)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    560\u001B[0m             \u001B[1;31m# or an RGBA array of re-sampled input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 561\u001B[1;33m             \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_rgba\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbytes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnorm\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    562\u001B[0m             \u001B[1;31m# output is now a correctly sized RGBA array of uint8\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    563\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\cm.py\u001B[0m in \u001B[0;36mto_rgba\u001B[1;34m(self, x, alpha, bytes, norm)\u001B[0m\n\u001B[0;32m    331\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mnorm\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    332\u001B[0m             \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 333\u001B[1;33m         \u001B[0mrgba\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0malpha\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbytes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbytes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    334\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mrgba\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    335\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\colors.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, X, alpha, bytes)\u001B[0m\n\u001B[0;32m    574\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mxa\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"f\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    575\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merrstate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minvalid\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"ignore\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 576\u001B[1;33m                 \u001B[0mxa\u001B[0m \u001B[1;33m*=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mN\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    577\u001B[0m                 \u001B[1;31m# Negative values are out of range, but astype(int) would\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    578\u001B[0m                 \u001B[1;31m# truncate them towards zero.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def plot_gan_progress(g_losses, d_real_losses, d_fake_losses, model, epoch, batch, test_input):\n",
    "    \"\"\"\n",
    "    Plot tensorflow train and validation metrics and loss in one chart.\n",
    "    :param history: Dictionary containing the accuracy and loss history.\n",
    "    \"\"\"\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 11))\n",
    "    fig.suptitle(f'Epoch {epoch:03} | Batch {batch:03}')\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(3, 4, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(predictions[i].numpy(), cmap='gray')\n",
    "\n",
    "    plt.subplot(3, 4, (9,12))\n",
    "    plt.title(f'GAN generator and discriminator losses')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Loss')\n",
    "    if len(g_losses) > 50:\n",
    "        plt.plot(g_losses[len(g_losses)-50:], c=green1, label=f'gen loss')\n",
    "        plt.plot(d_real_losses[len(d_real_losses)-50:], c='purple', label=f'disc real loss')\n",
    "        plt.plot(d_fake_losses[len(d_fake_losses)-50:], c='#ff884d', label=f'disc fake loss')\n",
    "    else:\n",
    "        plt.plot(g_losses, c=green1, label=f'gen loss')\n",
    "        plt.plot(d_real_losses, c='purple', label=f'disc real loss')\n",
    "        plt.plot(d_fake_losses, c='#ff884d', label=f'disc fake loss')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.savefig(f'C:/Pred_Images/preds_at_epoch{epoch:04}_batch{batch:04}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    \"\"\"\n",
    "    Conduct forward and backward pass, updating weights of each model\n",
    "    by their loss.\n",
    "    :param images: Batch of images (either real or fake)\n",
    "    :return: Losses, for plotting only.\n",
    "    \"\"\"\n",
    "    # Random latent space input for generator.\n",
    "    z = generate_latent_coordinates(BATCH_SIZE, IMAGE_SIZE)\n",
    "    # const = tf.ones(shape=(BATCH_SIZE,4,4,512))\n",
    "\n",
    "    # Track gradients of each model.\n",
    "    # ie. Track what happened in what order during forward pass.\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # Forward pass.\n",
    "        generated_images = generator(z, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        g_loss = gen_loss(fake_output)\n",
    "        d_real_loss, d_fake_loss = disc_loss(real_output, fake_output)\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "\n",
    "    # Backward pass.\n",
    "    # Calculate gradient for each models trainable weights.\n",
    "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # Update generator and discriminator weights with gradients.\n",
    "    gen_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    disc_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return g_loss, d_real_loss, d_fake_loss\n",
    "\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    g_losses, d_real_losses, d_fake_losses = [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for i, image_batch in enumerate(dataset):\n",
    "            # Start training step, tracking losses.\n",
    "            g_loss, d_real_loss, d_fake_loss = train_step(image_batch)\n",
    "            g_loss, d_real_loss, d_fake_loss = g_loss.numpy(), d_real_loss.numpy(), d_fake_loss.numpy()\n",
    "\n",
    "            # Update output graph every n batches.\n",
    "            if i % GRAPH_INTERVAL == 0:\n",
    "                g_losses.append(g_loss)\n",
    "                d_real_losses.append(d_real_loss)\n",
    "                d_fake_losses.append(d_fake_loss)\n",
    "                display.clear_output(wait=True)\n",
    "                plot_gan_progress(g_losses, d_real_losses, d_fake_losses, generator, epoch, i, SEED)\n",
    "            if i % PRINT_INTERVAL == 0:\n",
    "                print(f'Epoch {epoch:04}: batch {i:04}/{len(dataset)} | g_loss: {g_loss} | '\n",
    "                      f'd_fake_loss: {d_fake_loss} | d_real_loss: {d_real_loss}', end='\\r')\n",
    "\n",
    "        # Save the model every 15 epochs\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        print('Time for epoch {} is {} sec\\n'.format(epoch + 1, time.time() - start))\n",
    "\n",
    "\n",
    "train(image_dataset, EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# checkpoint_dir = 'C:/Pred_Models'\n",
    "# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "# checkpoint = tf.train.Checkpoint(generator_optimizer=gen_optimizer,\n",
    "#                                  discriminator_optimizer=disc_optimizer,\n",
    "#                                  generator=generator,\n",
    "#                                  discriminator=discriminator)\n",
    "#\n",
    "# checkpoint.restore(\"C:/Pred_models/ckpt-16.index\")\n",
    "\n",
    "predictions = generator(generate_latent_coordinates(1, 100), training=False)\n",
    "plt.axis('off')\n",
    "plt.imshow(predictions[0].numpy(), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "predictions = generator(generate_latent_coordinates(1, 100), training=False)\n",
    "plt.axis('off')\n",
    "plt.imshow(predictions[0].numpy(), cmap='gray')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "base",
   "language": "python",
   "display_name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}