{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "LATENT_SIZE = 512\n",
    "BATCH_SIZE = 12\n",
    "\n",
    "LAYERS = int(np.log2(IMG_SIZE) - 1)\n",
    "MIX_PROB = 0.9\n",
    "CHA = 48\n",
    "\n",
    "INITIALIZER = tf.keras.initializers.he_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(num):\n",
    "    return np.random.normal(0.0, 1.0, size = [num, LATENT_SIZE]).astype('float32')\n",
    "\n",
    "def get_noise(num):\n",
    "    return list(noise(num)) * LAYERS\n",
    "\n",
    "def get_mixed_noise(num):\n",
    "    rand = int(random() - LAYERS)\n",
    "    p1 = list(noise(num)) * rand\n",
    "    p2 = list(noise(num)) * (LAYERS - rand)\n",
    "    return p1 + p2\n",
    "\n",
    "def img_dim(size):\n",
    "    return np.random.uniform(0.0, 1.0, size = [size, IMG_SIZE, IMG_SIZE, 1]).astype('float32')\n",
    "\n",
    "def pixel_norm(x, epsilon = 1e-8):\n",
    "    mean = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "    std = tf.keras.backend.std(x, axis=[1, 2], keepdims=True) + epsilon\n",
    "    return (x - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_loss(sample, output, weights):\n",
    "    grad = tf.keras.backend.gradients(output, sample, weights)\n",
    "    grad_sq = tf.keras.backend.square(grad)\n",
    "    grad_loss = tf.keras.backend.sum(grad_sq, axis=np.arrange(1, len(grad_sq.shape)))\n",
    "    return tf.keras.mean(grad_loss * weights)\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fade_in(alpha, a, b):\n",
    "    alpha = tf.reshape(alpha, [-1, 1, 1, 1])\n",
    "    alpha = tf.clip(alpha - b, 0, 1)\n",
    "    return a * alpha + ((1.0 - alpha) * (1.0 - a))\n",
    "\n",
    "def AdaIN(input_shapes):\n",
    "    y = pixel_norm(input_shapes[0])\n",
    "    #shape = [-1, 1, 1, y.shape[-1]]\n",
    "    scale = tf.reshape(input_shapes[1], (-1, 1, 1, y.shape[-1])) + 1.0\n",
    "    bias = tf.reshape(input_shapes[2], (-1, 1, 1, y.shape[-1]))\n",
    "    return y * scale + bias \n",
    "\n",
    "def fit(x):\n",
    "    h = x[1].shape[1]\n",
    "    w = x[1].shape[2]\n",
    "    return x[0][:, :h, :w, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_block(input_tensor, style, inoise, filters, up_sample = True):\n",
    "    if up_sample:\n",
    "        block = tf.keras.layers.UpSampling2D()(input_tensor)\n",
    "    else:\n",
    "        block = tf.keras.layers.Activation('linear')(input_tensor)\n",
    "\n",
    "    beta = tf.keras.layers.Dense(filters)(style)\n",
    "    delta = tf.keras.layers.Lambda(fit)([inoise, block])\n",
    "    delta = tf.keras.layers.Dense(filters, kernel_initializer='zeros')(delta)\n",
    "    gamma = tf.keras.layers.Dense(filters)(style)\n",
    "\n",
    "    block = tf.keras.layers.Conv2D(filters=filter, kernel_size=3, padding='same', \\\n",
    "        kernel_initializer=INITIALIZER)(block)\n",
    "    block = tf.keras.layers.add([block, delta])\n",
    "    block = tf.keras.layers.Lambda(AdaIN)([block, gamma, beta])\n",
    "\n",
    "    return tf.keras.layers.LeakyReLU(0.2)(block)\n",
    "\n",
    "def get_desc_block(input_tensor, filters, pool = True):\n",
    "    block = tf.keras.layers.Conv2D(filters=filters, kernel_size=3, \\\n",
    "        padding='same', kernel_initializer=INITIALIZER)(input_tensor)\n",
    "    block = tf.keras.layers.LeakyReLU(0.2)(block)\n",
    "\n",
    "    if pool:\n",
    "        block = tf.keras.layers.AveragePooling2D()(block)\n",
    "\n",
    "    return block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    def __init__(self, steps = 1, learn_rate = 1e-4, decay = 1e-5):\n",
    "        self.desc = None\n",
    "        self.gen = None\n",
    "        self.style = None\n",
    "\n",
    "        self.L_Rate = learn_rate\n",
    "        self.steps = steps\n",
    "        self.beta = 0.99\n",
    "\n",
    "        self.discriminator()\n",
    "        self.generator()\n",
    "\n",
    "        self.g_model = tf.keras.models.model_from_json(self.gen.to_json())\n",
    "        self.g_model.set_weights(self.gen.get_weights())\n",
    "        \n",
    "        self.s_model = tf.keras.models.model_from_yaml(self.style.to_yaml())\n",
    "        self.s_model.set_weights(self.style.get_weights())\n",
    "\n",
    "    def discriminator(self):\n",
    "        if self.desc:\n",
    "            return self.desc\n",
    "        \n",
    "        input_tensor = tf.keras.layers.Input(shape = [IMG_SIZE, IMG_SIZE, 3])\n",
    "\n",
    "        x = input_tensor\n",
    "        x = get_desc_block(x, 1*CHA)\n",
    "        x = get_desc_block(x, 2*CHA)\n",
    "        x = get_desc_block(x, 3*CHA)\n",
    "        x = get_desc_block(x, 4*CHA)\n",
    "        x = get_desc_block(x, 4*CHA)\n",
    "        x = get_desc_block(x, 6*CHA)\n",
    "        x = get_desc_block(x, 8*CHA)\n",
    "        x = get_desc_block(x, 16*CHA, False)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(16*CHA, kernel_initializer=INITIALIZER)(x)\n",
    "        x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "        x = tf.keras.layers.Dense(1, kernel_initializer=INITIALIZER)(x)\n",
    "\n",
    "        self.desc = tf.keras.models.Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "        return self.desc\n",
    "\n",
    "    def generator(self):\n",
    "        if self.gen:\n",
    "            return self.gen\n",
    "        \n",
    "        # Style Mapping\n",
    "        self.style = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(512, input_shape=[LATENT_SIZE]),\n",
    "                tf.keras.layers.LeakyReLU(0.2),\n",
    "                tf.keras.layers.Dense(512),\n",
    "                tf.keras.layers.LeakyReLU(0.2),\n",
    "                tf.keras.layers.Dense(512),\n",
    "                tf.keras.layers.LeakyReLU(0.2),\n",
    "                tf.keras.layers.Dense(512),\n",
    "                tf.keras.layers.LeakyReLU(0.2)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Actual Generator\n",
    "        input_style = []\n",
    "\n",
    "        for i in range(LAYERS):\n",
    "            input_style.append(tf.keras.layers.Input([512]))\n",
    "\n",
    "        input_noise = tf.keras.layers.Input([IMG_SIZE, IMG_SIZE, 1])\n",
    "\n",
    "        x = tf.keras.layers.Lambda(lambda x: x[:, :128])(input_style[0])\n",
    "        x = tf.keras.layers.Dense(4*4*4*CHA, activation=tf.nn.relu, kernel_initializer=INITIALIZER)(x)\n",
    "        x = tf.keras.layers.Reshape([4, 4, 4*CHA])(x)\n",
    "        x = get_gen_block(x, input_style[0], input_noise, 16*CHA, up_sample=False)\n",
    "        x = get_gen_block(x, input_style[1], input_noise, 8*CHA)\n",
    "        x = get_gen_block(x, input_style[2], input_noise, 6*CHA)\n",
    "        x = get_gen_block(x, input_style[3], input_noise, 4*CHA)\n",
    "        x = get_gen_block(x, input_style[4], input_noise, 3*CHA)\n",
    "        x = get_gen_block(x, input_style[5], input_noise, 2*CHA)\n",
    "        x = get_gen_block(x, input_style[6], input_noise, 1*CHA)\n",
    "        x = tf.keras.layers.Conv2D(filters=3, kernel_size=1, padding='same', kernel_initializer=INITIALIZER)(x)\n",
    "\n",
    "        self.gen = tf.keras.models.Model(inputs = input_style + input_style, outputs = x)\n",
    "\n",
    "        return self.gen\n",
    "    \n",
    "    def gen_model(self):\n",
    "        input_style = []\n",
    "        style = []\n",
    "\n",
    "        for i in range(LAYERS):\n",
    "            input_style.append(tf.keras.layers.Input([LATENT_SIZE]))\n",
    "            style.append(self.style(input_style[-1]))\n",
    "\n",
    "        input_noise = tf.keras.layers.Input([IMG_SIZE, IMG_SIZE, 1])\n",
    "\n",
    "        x = self.gen(style+[input_noise])\n",
    "\n",
    "        return tf.keras.models.Model(inputs = input_style + [input_noise], outputs = x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.optimizers.Adam(learning_rate=1e-4, beta_1=0, beta_2=0.9)\n",
    "discriminator_optimizer = tf.optimisers.Adam(learning_rate=4*1e-4, beta_1=0, beta_2=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"!!!!!!!!!!!!!! # NEED WORK # !!!!!!!!!!!!!!!!!!\"\n",
    "class StyleGAN(object):\n",
    "    def __init__(self, data_dir, steps = 1, learn_rate = 1e-4, decay = 1e-5):\n",
    "        self.GAN = GAN(steps = steps, learn_rate = learn_rate, decay = decay)\n",
    "        \n",
    "        self.generator = self.GAN.gen_model()\n",
    "        self.discriminiator = self.GAN.discriminator()\n",
    "\n",
    "        self.data = data_dir\n",
    "        \n",
    "        self.weight = np.array([10] * BATCH_SIZE).astype('float32')\n",
    "\n",
    "    def train(self):\n",
    "        # Randomly train alternating styles\n",
    "        if random.random() < MIX_PROB:\n",
    "            style = get_mixed_noise(BATCH_SIZE)\n",
    "        else:\n",
    "            style = get_noise(BATCH_SIZE)\n",
    "\n",
    "        img = self.data\n",
    "        \n",
    "        d_loss, g_loss, div = self.train_step(img, style, img_dim(BATCH_SIZE), self.weight)\n",
    "\n",
    "        new_weight = 5/(np.array(div) + 1e-7)\n",
    "        self.weight = self.gp_weight[0] * 0.9 + 0.1 * new_weight\n",
    "        self.weight = np.clip([self.weight] * BATCH_SIZE, 0.01, 10000.0).astype('float32')\n",
    "\n",
    "        # Print progress after models after 100 steps\n",
    "        if self.GAN.steps%100 == 0:\n",
    "            print(\"\\n==============================\")\n",
    "            print(\"Epoch: \", self.GAN.steps)\n",
    "            print(\"Discriminator Loss: \", d_loss)\n",
    "            print(\"Generator Loss: \", g_loss)\n",
    "            print(\"==============================\\n\")\n",
    "\n",
    "            #Save images in /Generated-img after every 500 epochs\n",
    "            if self.GAN.steps%500 == 0:\n",
    "                self.save_image(self.GAN.steps/500)\n",
    "\n",
    "        self.GAN.steps += 1\n",
    "\n",
    "    def train_step(self, images, style, noise, weight):\n",
    "        with tf.GradientTape() as g_tape, tf.GradientTape as d_tape:\n",
    "            generated_img = self.generator(style + [noise], training=True)\n",
    "            real_output = self.discriminiator(images, training=True)\n",
    "            generated_output = self.discriminiator(generated_img, training=True)\n",
    "\n",
    "            generator_loss = tf.keras.backend.mean(generated_output)\n",
    "            divergence = tf.keras.backend.mean(tf.nn.relu(1+real_output) \\\n",
    "                + tf.nn.relu(1-generated_output))\n",
    "            discriminator_loss = divergence + gradient_loss(images, real_output, weight)\n",
    "\n",
    "        gradients_of_generator = g_tape.gradient(generator_loss, self.generator.trainable_variables)\n",
    "        gradients_of_discriminator = d_tape.gradient(discriminator_loss, \\\n",
    "            self.discriminiator.trainable_variables)\n",
    "\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, \\\n",
    "            self.generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, \\\n",
    "            self.discriminiator.trainable_variables))\n",
    "        \n",
    "        return discriminator_loss, generator_loss, divergence\n",
    "\n",
    "    def save_image(self, image_num):\n",
    "        noise1 = get_noise(64)\n",
    "        noise2 = img_dim(64)\n",
    "\n",
    "        g_model = self.GAN.gen_model()\n",
    "        generated_images = g_model.predict(noise1 + [noise2])\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for i in range(0, 64, 8):\n",
    "            result.append(np.concatenate(generated_images[i:i+8], axis=1))\n",
    "\n",
    "        x = np.concatenate(result, axis = 0)\n",
    "        x = np.clip(x, 0.0, 1.0)\n",
    "\n",
    "        images = Image.fromarray(np.unit8(x*255))\n",
    "\n",
    "        images.save(\"Generated_img/img-\"+str(image_num)+\".png\")\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StyleGAN(data)\n",
    "model.save_image(0)\n",
    "\n",
    "while model.GAN.steps <= 1000001:\n",
    "    model.train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "784a2de71e312217db3d3563a6c7078fbbff23ed7ca221264310ecd9339103c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('tf-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
