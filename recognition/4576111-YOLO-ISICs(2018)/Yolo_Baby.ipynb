{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1092,
   "id": "03198a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "id": "86e02773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the constants\n",
    "S = 7 # Divide the image to have S*S cells\n",
    "C = 1 # Number of classes \n",
    "B = 2 # Number of bounding boxes to be predicted per cell\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "id": "da3b36ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import image paths\n",
    "imagesRaw = glob.glob(\"./new_images/*.jpg\")\n",
    "imagesRaw.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "id": "75daf670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all the bounding box info\n",
    "with open('boundingBoxes.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    " \n",
    "boxes = [[float(x) for x in line.strip().split(\",\")] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "id": "164834d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jpeg(image, box):\n",
    "    # Load the image turn into jpeg\n",
    "    decoded = tf.io.read_file(image)\n",
    "    imageTf = tf.image.decode_jpeg(decoded)\n",
    "    # Normalize the images\n",
    "    returnImage = tf.cast(imageTf, tf.float32) / 255.0\n",
    "    returnImage = tf.reshape(returnImage, (488,488,3))\n",
    "    \n",
    "    return returnImage, box\n",
    "\n",
    "def convertToYTrue(box):\n",
    "    # This inserts the BOX to correct GRID POSITION\n",
    "    row, col = box[1], box[2]\n",
    "    updates = tf.constant([box[3:]])\n",
    "    # Could simplify this using tf.meshgrid somehow\n",
    "    idx = tf.constant([[[row, col, 0], [row, col, 1], [row, col, 2], [row, col, 3], [row, col, 4], [row, col, 5]]])\n",
    "    output = tf.scatter_nd(idx, updates, [7, 7, 6])\n",
    "    return output\n",
    "    \n",
    "# Plots two given images\n",
    "def display(imageOne, imageTwo):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(imageOne))\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(imageTwo))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "#Convert true pixel indexes to yolo format\n",
    "def convertToYoloFormat(pixelPositions, num_boxes=1, imageWidth=488, imageHeight=488):\n",
    "    # Format is [containsObj, center_x, center_y, width, height, classes...]\n",
    "    cellHeight = imageHeight / S\n",
    "    cellWidth = imageWidth / S\n",
    "    returnBox = []\n",
    "    countStart = 0\n",
    "    countEnd = 1\n",
    "    storage = []\n",
    "    while countStart < num_boxes:\n",
    "        _ ,xMin, xMax, yMin, yMax = pixelPositions[5*countStart:4*countEnd + 1]\n",
    "        # Calculate the exact pixel index of the center of the box w.r.t the image\n",
    "        pointX = (floor((xMax - xMin)/2)) + xMin\n",
    "        pointY = (floor((yMax - yMin)/2)) + yMin\n",
    "        # Calculate the center of the box w.r.t the cell\n",
    "        centerX = (pointX - floor(pointX/cellWidth) * cellWidth)/cellWidth\n",
    "        centerY = (pointY - floor(pointY/cellHeight) * cellHeight)/cellHeight\n",
    "        # Calculate the dimensions w.r.t the cell\n",
    "        width = (xMax - xMin)/(imageHeight)\n",
    "        height = (yMax - yMin)/(imageWidth)\n",
    "        \n",
    "        returnBox = returnBox + [_, centerX, centerY, width, height]\n",
    "        countEnd += 1\n",
    "        countStart += 1\n",
    "        \n",
    "    colIndex = floor(pointX/cellWidth)\n",
    "    rowIndex = floor(pointY/cellHeight)\n",
    "    storage += colIndex, rowIndex\n",
    "    \n",
    "    return [num_boxes] + storage + returnBox + pixelPositions[5*countStart:]\n",
    "\n",
    "def generateIndexes():\n",
    "    table = []\n",
    "    for i in range(BATCH_SIZE):\n",
    "        for j in range(S*S):\n",
    "            for k in range(B):\n",
    "                table.append([i,j,k])\n",
    "    return table\n",
    "\n",
    "# Convert the yolo box format to tensor box format NEED TO UPDATE ++++\n",
    "def convertFromYolo(box, image, index):\n",
    "    xMax = box[0]*488*2\n",
    "    yMax = box[1]*488*2\n",
    "    xMin = - box[2]*488 + xMax\n",
    "    yMin = - box[3]*488 + yMax\n",
    "    return xMax, yMax, xMin, yMin\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "id": "93ba5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boxes to yolo format:\n",
    "convertedBoxes = [convertToYoloFormat(box) for box in boxes]\n",
    "# Convert the convertedBoxes to the same format as y_pred\n",
    "yTrue = [convertToYTrue(box) for box in convertedBoxes]\n",
    "# Create a new dataset, pairing images and respective boxes\n",
    "imageDataSet = tf.data.Dataset.from_tensor_slices((imagesRaw, yTrue))\n",
    "# Shuffle the data\n",
    "imageDataSet = imageDataSet.shuffle(100)\n",
    "# Map the paths to turn into images\n",
    "entireSet = imageDataSet.map(load_jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "id": "9ca8c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into train, test and validation\n",
    "trainSize = int(0.8 * 2594)\n",
    "valSize = int(0.1 * 2594)\n",
    "train = entireSet.take(trainSize)\n",
    "temp = entireSet.skip(trainSize)\n",
    "test = temp.skip(valSize)\n",
    "validation = temp.take(valSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "id": "a59ae73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches:\n",
    "train_batches = train.batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "id": "da658688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    #First Layer\n",
    "    tf.keras.layers.Conv2D(64, (7,7), strides=(2, 2),  input_shape=(488,488,3)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
    "    \n",
    "    #Second Layer\n",
    "    #tf.keras.layers.Conv2D(192, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(192, (3,3),  padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
    "    \n",
    "    #Third Layer\n",
    "    tf.keras.layers.Conv2D(128, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    #tf.keras.layers.Conv2D(512, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(512, (3,3),  padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
    "    \n",
    "    #Fourth Layer\n",
    "    # +++ Repeated block\n",
    "    tf.keras.layers.Conv2D(256, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    # +++ END BLOCK\n",
    "    tf.keras.layers.Conv2D(512, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    #tf.keras.layers.Conv2D(1024, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(1024, (3,3),  padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
    "    \n",
    "    #Fifth layer\n",
    "    # +++ Repeated Block\n",
    "    tf.keras.layers.Conv2D(512, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(1024, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(512, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(1024, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    # +++ END BLOCK\n",
    "    tf.keras.layers.Conv2D(1024, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(1024, (3,3), strides=(2, 2), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    \n",
    "    #Sixth Layer\n",
    "    tf.keras.layers.Conv2D(1024, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    #tf.keras.layers.Conv2D(1024, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(1024, (3,3),  padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    \n",
    "\n",
    "    # Final Output Layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation=LeakyReLU(alpha=0.1)),\n",
    "    tf.keras.layers.Dense(S * S * (B*5+C), input_shape=(4096,), activation=\"sigmoid\"),\n",
    "    tf.keras.layers.Reshape(target_shape = (S, S, (B*5+C)))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93dccd5",
   "metadata": {},
   "source": [
    "The yoloLoss function is an adaptation from here: https://blog.emmanuelcaradec.com/humble-yolo-implementation-in-keras/. Credit to Emmanuel Caradec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "id": "c9a0e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yoloLoss(y_true, y_pred):\n",
    "    \n",
    "    if tf.math.reduce_any(tf.math.is_nan(y_pred)):\n",
    "        print(\"\\ny_pred is NAN\")\n",
    "        test = tf.reshape(y_pred, [-1,539])\n",
    "        for e in test.numpy():\n",
    "            print(e)\n",
    "    \n",
    "    grid = [[[float(x),float(y)]]*B for y in range(S) for x in range(S)]\n",
    "    \n",
    "    true_boxes = tf.reshape(y_true[...,:5], [-1,S*S,1,5])\n",
    "    pred_boxes = tf.reshape(y_pred[...,:B*5], (-1,S*S,B,5))\n",
    "    # Reshape the 3: too S*S, B, 5 i.e. 49, 2, 5. \n",
    "    # Each cell has two bounding boxes, with each bounding box, having 5 elements. \n",
    "    \n",
    "    y_pred_conf = pred_boxes[...,0]\n",
    "    y_true_conf = true_boxes[...,0]\n",
    "    \n",
    "    y_pred_wh   = pred_boxes[...,3:5]\n",
    "    y_true_wh   = true_boxes[...,3:5]\n",
    "    # y_pred_wh. Shape (S*S,B,2). Where each cell, has B bounding boxes, with each\n",
    "    # Bounding box having two rows?\n",
    "\n",
    "    y_pred_xy   = pred_boxes[...,1:3] + grid\n",
    "    y_true_xy   = true_boxes[...,1:3]\n",
    "    # The y_true_xy will have a shape of S*S, B, 2. Where each cell, has B bounding boxes, with two colums? \n",
    "    # I understand grabbing the xy pairs, but why + the grid?\n",
    "    \n",
    "    y_true_class = tf.reshape(y_true[...,5:], [-1, S*S, C]) \n",
    "    y_pred_class = tf.reshape(y_pred[...,B*5:], [-1, S*S, C])\n",
    "    \n",
    "    \n",
    "    # Losses Calculations +++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    xy_loss    = tf.math.reduce_sum(tf.math.reduce_sum(tf.math.square(y_true_xy - y_pred_xy),\n",
    "                                                       axis=-1)*y_true_conf, axis=-1)\n",
    "    \n",
    "    # Two reduce sums  = 2 summations. Axis = -1, along last dimensions i.e. columns/entries in this case.\n",
    "    # Square is element wise. y_true_conf is the little 1, in the formula. \n",
    "\n",
    "    wh_loss    = tf.math.reduce_sum(tf.math.reduce_sum(tf.math.square(tf.math.sqrt(y_true_wh) - \n",
    "                                                                      tf.math.sqrt(y_pred_wh)), axis=-1)\n",
    "                                    *y_true_conf, axis=-1)\n",
    "    \n",
    "    # Two reduce sums  = 2 summations. Axis = -1, along last dimensions i.e. rows in this case\n",
    "    # Makes sense, matches formula. \n",
    "    \n",
    "    clss_loss  = tf.math.reduce_sum(tf.math.square(y_true_class - y_pred_class)*y_true_conf, axis=-1)       \n",
    "        \n",
    "    intersect_wh = tf.math.maximum(tf.zeros_like(y_pred_wh), (y_pred_wh + y_true_wh)/2 \n",
    "                                   - tf.math.abs(y_pred_xy - y_true_xy) )\n",
    "    \n",
    "    intersect_area = intersect_wh[...,0] * intersect_wh[...,1]\n",
    "    true_area = y_true_wh[...,0] * y_true_wh[...,1]\n",
    "    pred_area = y_pred_wh[...,0] * y_pred_wh[...,1]\n",
    "    union_area = pred_area + true_area - intersect_area\n",
    "    \n",
    "    # Make the denom not zero\n",
    "    #union_area = tf.where(tf.equal(0., union_area), tf.ones_like(union_area), union_area)\n",
    "    \n",
    "    iou = intersect_area / union_area\n",
    "    \n",
    "    union_area = tf.where(tf.math.equal(0., union_area), tf.ones_like(union_area), union_area)\n",
    "    \n",
    "    conf_loss = tf.math.reduce_sum(tf.math.square(y_true_conf*iou - y_pred_conf)*y_true_conf, axis=-1)\n",
    "    \n",
    "    loss =  clss_loss + xy_loss + wh_loss + conf_loss\n",
    "    \n",
    "    #loss = tf.where(tf.math.is_nan(loss), tf.zeros_like(loss), loss)\n",
    "    \n",
    "    return tf.math.reduce_sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "id": "b57b7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccardIndex(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compares y_true with highest prob y_pred box\n",
    "    \"\"\"\n",
    "            \n",
    "    y_true = tf.reshape(y_true[...,:5], [-1,S*S,1,5])\n",
    "    y_pred = tf.reshape(y_pred[...,:B*5], [-1,S*S,B,5])\n",
    "    \n",
    "    y_true_box = tf.gather_nd(y_true, (tf.where(tf.equal(y_true[...,4], tf.math.reduce_max(y_true[...,4]))))[0])\n",
    "    y_pred_box = tf.gather_nd(y_pred, (tf.where(tf.equal(y_pred[...,4], tf.math.reduce_max(y_pred[...,4]))))[0])\n",
    "    \n",
    "    numerator = (tf.math.reduce_sum(tf.math.multiply(y_true_box, y_pred_box)))\n",
    "    # Calculate the area of both - area that overlaps\n",
    "    denom = tf.math.reduce_sum(y_true_box) + tf.math.reduce_sum(y_pred_box) - numerator\n",
    "    iou = numerator/denom\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "id": "6de8bcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This max supression will only work when they're only exists a single class. Can be adapted.  \n",
    "def nonMaxSupression(y_true, y_pred):\n",
    "    maxTrueValue = tf.gather_nd(y_true, (tf.where(tf.equal(y_true[...,4], tf.math.reduce_max(y_true[...,4]))))[0])\n",
    "    # Grabs the max value along index 4 (reduce_max), then finds the index of the value in the tensor\n",
    "    maxPredIndex = (tf.where(tf.equal(y_pred[...,4], tf.math.reduce_max(y_pred[...,4]))))[0]\n",
    "    # Grabs the actual value, using index calculated above\n",
    "    maxPredValue = tf.gather_nd(y_pred, maxPredIndex)\n",
    "    idx = generateIndexes()\n",
    "    # Disgusting time complexity :D\n",
    "    for i in range(len(idx)):\n",
    "        box = tf.gather_nd(y_pred, idx[i])\n",
    "        val = iou(maxPredValue, box)\n",
    "        if val < 0.5:\n",
    "            del idx[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "id": "d547c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = tf.zeros([2, 7, 7, 11])\n",
    "zeros = zeros + 0.1\n",
    "for image, box in train_batches.take(1):\n",
    "    testBox = box\n",
    "    output = yoloLoss(testBox, zeros)\n",
    "    jaccard = jaccardIndex(testBox, zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "id": "ceb8626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=yoloLoss,\n",
    "              metrics=[jaccardIndex], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "id": "eccd75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "id": "efd8bb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5/2075 [..............................] - ETA: 59:23 - loss: nan - jaccardIndex: 0.5313    \n",
      "y_pred is NAN\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "in user code:\n\n    C:\\Users\\e_gui\\AppData\\Local\\Temp/ipykernel_8496/1141752945.py:10 jaccardIndex  *\n        y_pred_box = tf.gather_nd(y_pred, (tf.where(tf.equal(y_pred[...,4], tf.math.reduce_max(y_pred[...,4]))))[0])\n    C:\\Users\\e_gui\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\e_gui\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1041 _slice_helper\n        return strided_slice(\n    C:\\Users\\e_gui\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\e_gui\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1214 strided_slice\n        op = gen_array_ops.strided_slice(\n    C:\\Users\\e_gui\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10510 strided_slice\n        _ops.raise_from_not_ok_status(e, name)\n    C:\\Users\\e_gui\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    InvalidArgumentError: slice index 0 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8496/3803976030.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    851\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    844\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1284\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1285\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1286\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2847\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2849\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2851\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3630\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3631\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3632\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3634\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[1;31m# Run backwards pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m     \u001b[1;31m# Collect metrics to return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[0mreturn_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\keras\\engine\\compile_utils.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmetric_obj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m           \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mweighted_metric_obj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweighted_metric_objs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mcontrol_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mag_update_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_update_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol_status\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mag_update_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: in user code:\n\n    C:\\Users\\e_gui\\AppData\\Local\\Temp/ipykernel_8496/1141752945.py:10 jaccardIndex  *\n        y_pred_box = tf.gather_nd(y_pred, (tf.where(tf.equal(y_pred[...,4], tf.math.reduce_max(y_pred[...,4]))))[0])\n    C:\\Users\\e_gui\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\e_gui\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1041 _slice_helper\n        return strided_slice(\n    C:\\Users\\e_gui\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\e_gui\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1214 strided_slice\n        op = gen_array_ops.strided_slice(\n    C:\\Users\\e_gui\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10510 strided_slice\n        _ops.raise_from_not_ok_status(e, name)\n    C:\\Users\\e_gui\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    InvalidArgumentError: slice index 0 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/\n"
     ]
    }
   ],
   "source": [
    "history =  model.fit(train_batches, epochs=1, validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ace0792",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in test_batches.take(1):\n",
    "    # Predict mask on new image\n",
    "    boxes = model.predict(image)\n",
    "    boxes = tf.reshape(boxes[...,:B*5], [-1,S*S,B,5])\n",
    "    bestBox = tf.gather_nd(boxes, (tf.where(tf.equal(result[...,4], tf.math.reduce_max(boxes[...,4]))))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a13fb26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
