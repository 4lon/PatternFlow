{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "03198a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "86e02773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the constants\n",
    "S = 7 # Divide the image to have S*S cells\n",
    "C = 1 # Number of classes \n",
    "B = 2 # Number of bounding boxes to be predicted per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "da3b36ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import image paths\n",
    "imagesRaw = glob.glob(\"./new_images/*.jpg\")\n",
    "imagesRaw.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "75daf670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all the bounding box info\n",
    "with open('boundingBoxes.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    " \n",
    "boxes = [[float(x) for x in line.strip().split(\",\")] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "164834d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jpeg(image, box):\n",
    "    # Load the image turn into jpeg\n",
    "    decoded = tf.io.read_file(image)\n",
    "    imageTf = tf.image.decode_jpeg(decoded)\n",
    "    # Normalize the images\n",
    "    returnImage = tf.cast(imageTf, tf.float32) / 255.0\n",
    "    returnImage = tf.reshape(returnImage, (488,488,3))\n",
    "    out = tf.zeros([S,S,5+C]) + box\n",
    "    \n",
    "    return returnImage, out\n",
    "\n",
    "# Plots two given images\n",
    "def display(imageOne, imageTwo):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(imageOne))\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(imageTwo))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "#Convert true pixel indexes to yolo format\n",
    "def convertToYoloFormat(pixelPositions, num_boxes=1, imageWidth=488, imageHeight=488):\n",
    "    # Format is [containsObj, center_x, center_y, width, height, classes...]\n",
    "    cellHeight = imageHeight / S\n",
    "    cellWidth = imageWidth / S\n",
    "    returnBox = []\n",
    "    countStart = 0\n",
    "    countEnd = 1\n",
    "    while countStart < num_boxes:\n",
    "        _ ,xMin, xMax, yMin, yMax = pixelPositions[5*countStart:4*countEnd + 1]\n",
    "        pointX = (floor((xMax - xMin)/2)) + xMin\n",
    "        pointY = (floor((yMax - yMin)/2)) + yMin\n",
    "        centerX = (pointX - floor(pointX/cellWidth) * cellWidth)/cellWidth\n",
    "        centerY = (pointY - floor(pointY/cellHeight) * cellHeight)/cellHeight\n",
    "        width = (xMax - xMin)/(cellHeight)\n",
    "        height = (yMax - yMin)/(cellHeight)\n",
    "        returnBox = returnBox + [_, centerX, centerY, width, height]\n",
    "        countEnd += 1\n",
    "        countStart += 1\n",
    "        \n",
    "    return returnBox + pixelPositions[5*countStart:]\n",
    "    \n",
    "# Convert the yolo box format to tensor box format NEED TO UPDATE ++++\n",
    "def convertFromYolo(box):\n",
    "    xMax = box[0]*488*2\n",
    "    yMax = box[1]*488*2\n",
    "    xMin = - box[2]*488 + xMax\n",
    "    yMin = - box[3]*488 + yMax\n",
    "    return xMax, yMax, xMin, yMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "5bd8616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, box in imageDataSet.take(1):\n",
    "    load_jpeg(image, box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "93ba5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boxes to yolo format:\n",
    "convertedBoxes = [convertToYoloFormat(box) for box in boxes]\n",
    "# Convert the convertedBoxes to the same format as y_pred\n",
    "# Create a new dataset, pairing images and respective boxes\n",
    "imageDataSet = tf.data.Dataset.from_tensor_slices((imagesRaw, convertedBoxes))\n",
    "# Shuffle the data\n",
    "imageDataSet = imageDataSet.shuffle(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "0d59c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "entireSet = imageDataSet.map(load_jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9ca8c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into train, test and validation\n",
    "trainSize = int(0.8 * 2594)\n",
    "valSize = int(0.1 * 2594)\n",
    "train = entireSet.take(trainSize)\n",
    "temp = entireSet.skip(trainSize)\n",
    "test = temp.skip(valSize)\n",
    "validation = temp.take(valSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a59ae73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches:\n",
    "train_batches = train.batch(1)\n",
    "validation_batches = validation.batch(1)\n",
    "test_batches = test.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "da658688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    #First Layer\n",
    "    tf.keras.layers.Conv2D(64, (7,7), strides=(2, 2), activation=LeakyReLU(alpha=0.1),  input_shape=(488,488,3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
    "    \n",
    "    #Second Layer\n",
    "    tf.keras.layers.Conv2D(192, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
    "    \n",
    "    #Third Layer\n",
    "    tf.keras.layers.Conv2D(128, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
    "    \n",
    "    #Fourth Layer\n",
    "    # +++ Repeated block\n",
    "    tf.keras.layers.Conv2D(256, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    # +++ END BLOCK\n",
    "    tf.keras.layers.Conv2D(512, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(1024, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
    "    \n",
    "    #Fifth layer\n",
    "    # +++ Repeated Block\n",
    "    tf.keras.layers.Conv2D(512, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(1024, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(512, (1,1), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(1024, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    # +++ END BLOCK\n",
    "    tf.keras.layers.Conv2D(1024, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(1024, (3,3), strides=(2, 2), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    \n",
    "    #Sixth Layer\n",
    "    tf.keras.layers.Conv2D(1024, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(1024, (3,3), activation=LeakyReLU(alpha=0.1), padding=\"same\"),\n",
    "    \n",
    "\n",
    "    # Final Output Layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation=LeakyReLU(alpha=0.1)),\n",
    "    tf.keras.layers.Dense(S * S * (B*5+C), input_shape=(4096,), activation=\"sigmoid\"),\n",
    "    tf.keras.layers.Reshape(target_shape = (S, S, (B*5+C)))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93dccd5",
   "metadata": {},
   "source": [
    "The yoloLoss function is an adaptation from here: https://blog.emmanuelcaradec.com/humble-yolo-implementation-in-keras/. Credit to Emmanuel Caradec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "c9a0e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yoloLoss(y_true, y_pred):\n",
    "    grid = [[[float(x),float(y)]]*B for y in range(S) for x in range(S)]\n",
    "    \n",
    "    \n",
    "    true_boxes = tf.reshape(y_true[...,:5], [-1,S*S,1,5])\n",
    "    pred_boxes = tf.reshape(y_pred[...,:B*5], (-1,S*S,B,5))\n",
    "    # Reshape the 3: too S*S, B, 5 i.e. 49, 2, 5. \n",
    "    # Each cell has two bounding boxes, with each bounding box, having 5 elements. \n",
    "    \n",
    "    y_pred_conf = pred_boxes[...,0]\n",
    "    y_true_conf = true_boxes[...,0]\n",
    "    \n",
    "    y_pred_wh   = pred_boxes[...,3:5]\n",
    "    y_true_wh   = true_boxes[...,3:5]\n",
    "    # y_pred_wh. Shape (S*S,B,2). Where each cell, has B bounding boxes, with each\n",
    "    # Bounding box having two rows?\n",
    "\n",
    "    y_pred_xy   = pred_boxes[...,1:3] + grid\n",
    "    y_true_xy   = true_boxes[...,1:3]\n",
    "    # The y_true_xy will have a shape of S*S, B, 2. Where each cell, has B bounding boxes, with two colums? \n",
    "    # I understand grabbing the xy pairs, but why + the grid?\n",
    "    \n",
    "    y_true_class = tf.reshape(y_true[...,5:], [-1, S*S, C]) \n",
    "    y_pred_class = tf.reshape(y_pred[...,B*5:], [-1, S*S, C])\n",
    "    \n",
    "    \n",
    "    # Losses Calculations +++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    xy_loss    = tf.math.reduce_sum(tf.math.reduce_sum(tf.math.square(y_true_xy - y_pred_xy),\n",
    "                                                       axis=-1)*y_true_conf, axis=-1)\n",
    "    # Two reduce sums  = 2 summations. Axis = -1, along last dimensions i.e. columns/entries in this case.\n",
    "    # Square is element wise. y_true_conf is the little 1, in the formula. \n",
    "\n",
    "    wh_loss    = tf.math.reduce_sum(tf.math.reduce_sum(tf.math.square(tf.math.sqrt(y_true_wh) - \n",
    "                                                                      tf.math.sqrt(y_pred_wh)), axis=-1)\n",
    "                                    *y_true_conf, axis=-1)\n",
    "    # Two reduce sums  = 2 summations. Axis = -1, along last dimensions i.e. rows in this case\n",
    "    # Makes sense, matches formula. \n",
    "    \n",
    "    clss_loss  = tf.math.reduce_sum(tf.math.square(y_true_class - y_pred_class)*y_true_conf, axis=-1)\n",
    "    # Needs to be reshaped. \n",
    "    #clss_loss = tf.reshape(clss_loss, [-1, 49])\n",
    "    \n",
    "                                    \n",
    "    intersect_wh = tf.math.maximum(tf.zeros_like(y_pred_wh), (y_pred_wh + y_true_wh)/2 \n",
    "                                   - tf.math.abs(y_pred_xy - y_true_xy) )\n",
    "    \n",
    "    \n",
    "    intersect_area = intersect_wh[...,0] * intersect_wh[...,1]\n",
    "    true_area = y_true_wh[...,0] * y_true_wh[...,1]\n",
    "    pred_area = y_pred_wh[...,0] * y_pred_wh[...,1]\n",
    "    union_area = pred_area + true_area - intersect_area\n",
    "    iou = intersect_area / union_area\n",
    "\n",
    "    conf_loss = tf.math.reduce_sum(tf.math.square(y_true_conf*iou - y_pred_conf)*y_true_conf, axis=-1)\n",
    "    \n",
    "    loss =  clss_loss + xy_loss + wh_loss + conf_loss\n",
    "    return tf.math.reduce_sum(loss)\n",
    "                                    \n",
    "    #return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "0912afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highestConfidenceBox(y_true, y_pred):\n",
    "    # This will extract the best box across all batches. Kind of dumb. Need to change highest box per batch. \n",
    "    boxes = tf.reshape(y_pred[...,:B*5], (-1,S*S,B,5))\n",
    "    maxValue = tf.reduce_max(boxes[...,4])\n",
    "    location = tf.where(tf.math.equal(boxes[...,4], maxValue))[0]\n",
    "    box = boxes[int(location[0]), int(location[1]), int(location[2])]\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "b57b7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccardIndex(y_true, y_pred):\n",
    "    #output = tf.repeat(y_true, 98, axis=1)\n",
    "    \n",
    "    y_true = tf.reshape(y_true[...,:5], [-1,S*S,1,5])\n",
    "    y_pred = tf.reshape(y_pred[...,:B*5], (-1,S*S,B,5))\n",
    "    \n",
    "    numerator = (tf.math.reduce_sum(tf.math.multiply(y_true, y_pred)))\n",
    "    # Calculate the area of both - area that overlaps\n",
    "    denom = tf.math.reduce_sum(y_true) + tf.math.reduce_sum(y_true) - numerator\n",
    "    return numerator/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "d547c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = tf.zeros([1, 7, 7, 11])\n",
    "for image, box in train_batches.take(1):\n",
    "    testBox = box\n",
    "    \n",
    "output = yoloLoss(testBox, zeros)\n",
    "jaccard = jaccardIndex(testBox, zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ceb8626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=yoloLoss,\n",
    "              metrics=[jaccardIndex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "eccd75b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_120 (Conv2D)          (None, 241, 241, 64)      9472      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 120, 120, 192)     110784    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 60, 60, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 60, 60, 128)       24704     \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 60, 60, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 60, 60, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 60, 60, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 30, 30, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 30, 30, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 30, 30, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 30, 30, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 30, 30, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 30, 30, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 30, 30, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 30, 30, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 30, 30, 512)       262656    \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 30, 30, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 15, 15, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_136 (Conv2D)          (None, 15, 15, 512)       524800    \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 15, 15, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 15, 15, 512)       524800    \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 15, 15, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_140 (Conv2D)          (None, 15, 15, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_141 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              268439552 \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 539)               2208283   \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 7, 7, 11)          0         \n",
      "=================================================================\n",
      "Total params: 331,328,091\n",
      "Trainable params: 331,328,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "efd8bb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 114/2075 [>.............................] - ETA: 38:32 - loss: 2207.7048 - jaccardIndex: 4.0957"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1404/3803976030.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfEnv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history =  model.fit(train_batches, epochs=1, validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ace0792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096237b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
