{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Yolo_Baby - Latest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "03198a4d"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from math import floor"
      ],
      "id": "03198a4d",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQZTc0LEEAz8"
      },
      "source": [
        "+++ Start For Google Colab\n",
        "\n"
      ],
      "id": "PQZTc0LEEAz8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhz1SKtn2wOX",
        "outputId": "299e5614-f02a-4a21-a219-03ebd404e4d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "jhz1SKtn2wOX",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cajZaMsF2xR1"
      },
      "source": [
        "# Grab all the bounding box info\n",
        "with open('/content/drive/My Drive/boundingBoxes.txt', 'r') as f:\n",
        "    lines = f.readlines()\n",
        " \n",
        "boxes = [[float(x) for x in line.strip().split(\",\")] for line in lines]\n",
        "\n",
        "# Import image paths\n",
        "imagesRaw = glob.glob(\"/content/drive/My Drive/new_images/*.jpg\")\n",
        "imagesRaw.sort()"
      ],
      "id": "cajZaMsF2xR1",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX_qfSd7EJOr"
      },
      "source": [
        "+++ End For Google Colab"
      ],
      "id": "eX_qfSd7EJOr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c9d1b23",
        "outputId": "ac8f6b74-eaf2-4b4c-f2fa-a170def8e115"
      },
      "source": [
        "# Check if install with cuda and gpu avaiable:\n",
        "print(tf.test.is_built_with_cuda)\n",
        "print(tf.config.list_physical_devices('GPU') )"
      ],
      "id": "6c9d1b23",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function is_built_with_cuda at 0x7f7421dd1050>\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86e02773"
      },
      "source": [
        "# Define the constants\n",
        "S = 7 # Divide the image to have S*S cells\n",
        "C = 1 # Number of classes \n",
        "B = 2 # Number of bounding boxes to be predicted per cell\n",
        "BATCH_SIZE = 20"
      ],
      "id": "86e02773",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da3b36ef"
      },
      "source": [
        "# Import image paths\n",
        "imagesRaw = glob.glob(\"./new_images/*.jpg\")\n",
        "imagesRaw.sort()"
      ],
      "id": "da3b36ef"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75daf670"
      },
      "source": [
        "# Grab all the bounding box info\n",
        "with open('boundingBoxes.txt', 'r') as f:\n",
        "    lines = f.readlines()\n",
        " \n",
        "boxes = [[float(x) for x in line.strip().split(\",\")] for line in lines]"
      ],
      "id": "75daf670"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "164834d7"
      },
      "source": [
        "def load_jpeg(image, box):\n",
        "    # Load the image turn into jpeg\n",
        "    decoded = tf.io.read_file(image)\n",
        "    imageTf = tf.image.decode_jpeg(decoded)\n",
        "    # Normalize the images\n",
        "    returnImage = tf.cast(imageTf, tf.float32) / 255.0\n",
        "    returnImage = tf.reshape(returnImage, (488,488,3))\n",
        "    \n",
        "    return returnImage, box\n",
        "\n",
        "def convertToYTrue(box):\n",
        "    # This inserts the BOX to correct GRID POSITION\n",
        "    row, col = box[1], box[2]\n",
        "    updates = tf.constant([box[3:]])\n",
        "    # Could simplify this using tf.meshgrid somehow\n",
        "    idx = tf.constant([[[row, col, 0], [row, col, 1], [row, col, 2], [row, col, 3], [row, col, 4], [row, col, 5]]])\n",
        "    output = tf.ones([7,7,6]) + [-1.0, -0.1, -.1, -.1, -.1, -1.0]\n",
        "    output = tf.tensor_scatter_nd_add(output, idx, tf.zeros_like(updates) + [0, -0.9, -0.9, -0.9, -0.9, 0])\n",
        "    output = tf.tensor_scatter_nd_add(output, idx, updates)\n",
        "    return output\n",
        "    \n",
        "# Plots two given images\n",
        "def display(imageOne, imageTwo):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(imageOne))\n",
        "    plt.axis(\"off\")\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(imageTwo))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "#Convert true pixel indexes to yolo format\n",
        "def convertToYoloFormat(pixelPositions, num_boxes=1, imageWidth=488, imageHeight=488):\n",
        "    # Format is [containsObj, center_x, center_y, width, height, classes...]\n",
        "    cellHeight = imageHeight / S\n",
        "    cellWidth = imageWidth / S\n",
        "    returnBox = []\n",
        "    countStart = 0\n",
        "    countEnd = 1\n",
        "    storage = []\n",
        "    while countStart < num_boxes:\n",
        "        _ ,xMin, xMax, yMin, yMax = pixelPositions[5*countStart:4*countEnd + 1]\n",
        "        # Calculate the exact pixel index of the center of the box w.r.t the image\n",
        "        pointX = (floor((xMax - xMin)/2)) + xMin\n",
        "        pointY = (floor((yMax - yMin)/2)) + yMin\n",
        "        # Calculate the center of the box w.r.t the cell\n",
        "        centerX = (pointX - floor(pointX/cellWidth) * cellWidth)/cellWidth\n",
        "        centerY = (pointY - floor(pointY/cellHeight) * cellHeight)/cellHeight\n",
        "        # Calculate the dimensions w.r.t the cell\n",
        "        width = (xMax - xMin)/imageWidth\n",
        "        height = (yMax - yMin)/imageHeight\n",
        "        \n",
        "        returnBox = returnBox + [_, centerX, centerY, width, height]\n",
        "        countEnd += 1\n",
        "        countStart += 1\n",
        "        \n",
        "    colIndex = floor(pointX/cellWidth)\n",
        "    rowIndex = floor(pointY/cellHeight)\n",
        "    storage += colIndex, rowIndex\n",
        "    \n",
        "    return [num_boxes] + storage + returnBox + pixelPositions[5*countStart:]\n",
        "\n",
        "def generateIndexes():\n",
        "    table = []\n",
        "    for i in range(BATCH_SIZE):\n",
        "        for j in range(S*S):\n",
        "            for k in range(B):\n",
        "                table.append([i,j,k])\n",
        "    return table\n",
        "\n",
        "# Convert the yolo box format to tensor box format NEED TO UPDATE ++++\n",
        "def convertFromYolo(box, image, index):\n",
        "    xMax = box[0]*488*2\n",
        "    yMax = box[1]*488*2\n",
        "    xMin = - box[2]*488 + xMax\n",
        "    yMin = - box[3]*488 + yMax\n",
        "    return xMax, yMax, xMin, yMin\n",
        "    "
      ],
      "id": "164834d7",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAVAPL6zgSYf",
        "outputId": "a7bcff58-ac28-4970-c00d-fd73819f2619"
      },
      "source": [
        "convertToYoloFormat(boxes[0])"
      ],
      "id": "ZAVAPL6zgSYf",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 3,\n",
              " 3,\n",
              " 1.0,\n",
              " 0.24180327868852508,\n",
              " 0.1844262295081972,\n",
              " 0.8360655737704918,\n",
              " 0.5840163934426229,\n",
              " 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93ba5218"
      },
      "source": [
        "# Convert boxes to yolo format:\n",
        "convertedBoxes = [convertToYoloFormat(box) for box in boxes]\n",
        "# Convert the convertedBoxes to the same format as y_pred\n",
        "yTrue = [convertToYTrue(box) for box in convertedBoxes]\n",
        "# Create a new dataset, pairing images and respective boxes\n",
        "imageDataSet = tf.data.Dataset.from_tensor_slices((imagesRaw, yTrue))\n",
        "# Shuffle the data\n",
        "imageDataSet = imageDataSet.shuffle(100)\n",
        "# Map the paths to turn into images\n",
        "entireSet = imageDataSet.map(load_jpeg)"
      ],
      "id": "93ba5218",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ca8c8fc"
      },
      "source": [
        "# Divide the dataset into train, test and validation\n",
        "trainSize = int(0.8 * 2594)\n",
        "valSize = int(0.1 * 2594)\n",
        "train = entireSet.take(trainSize)\n",
        "temp = entireSet.skip(trainSize)\n",
        "test = temp.skip(valSize)\n",
        "validation = temp.take(valSize)"
      ],
      "id": "9ca8c8fc",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a59ae73d"
      },
      "source": [
        "# Create batches:\n",
        "train_batches = train.batch(BATCH_SIZE)\n",
        "validation_batches = validation.batch(BATCH_SIZE)\n",
        "#test_batches = test.batch(BATCH_SIZE)"
      ],
      "id": "a59ae73d",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da658688"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    #First Layer\n",
        "    tf.keras.layers.Conv2D(64, (7,7), strides=(2, 2),  input_shape=(488,488,3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
        "    \n",
        "    #Second Layer\n",
        "    tf.keras.layers.Conv2D(192, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
        "    \n",
        "    #Third Layer    \n",
        "    tf.keras.layers.Conv2D(128, (1,1),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(512, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
        "    \n",
        "    #Fourth Layer\n",
        "    # +++ Repeated block\n",
        "    tf.keras.layers.Conv2D(256, (1,1),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Conv2D(512, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, (1,1),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Conv2D(512, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, (1,1),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Conv2D(512, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, (1,1),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Conv2D(512, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    # +++ END BLOCK\n",
        "    tf.keras.layers.Conv2D(512, (1,1),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(1024, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
        "    \n",
        "    #Fifth layer\n",
        "    # +++ Repeated Block\n",
        "    tf.keras.layers.Conv2D(512, (1,1),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Conv2D(1024, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(512, (1,1),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Conv2D(1024, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    # +++ END BLOCK\n",
        "    tf.keras.layers.Conv2D(1024, (3,3),  strides=(2, 2), padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(1024, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    #Sixth Layer\n",
        "    tf.keras.layers.Conv2D(1024, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(1024, (3,3),  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    \n",
        "\n",
        "    # Final Output Layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation=LeakyReLU(alpha=0.1)),\n",
        "    tf.keras.layers.Dense(S * S * (B*5+C), input_shape=(4096,)),\n",
        "    tf.keras.layers.Reshape(target_shape = (S, S, (B*5+C)))\n",
        "    \n",
        "])"
      ],
      "id": "da658688",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c93dccd5"
      },
      "source": [
        "The yoloLoss function is an adaptation from here: https://blog.emmanuelcaradec.com/humble-yolo-implementation-in-keras/. Credit to Emmanuel Caradec"
      ],
      "id": "c93dccd5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v36kVIk8vkp"
      },
      "source": [
        "COUNT = 0"
      ],
      "id": "7v36kVIk8vkp",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9a0e7fc"
      },
      "source": [
        "def yoloLoss(y_true, y_pred):\n",
        "    # Define constants:\n",
        "    lambdaCoord = 5\n",
        "    lambdaNoob = 0.5\n",
        "\n",
        "    grid = [[[float(x),float(y)]]*B for y in range(S) for x in range(S)]\n",
        "\n",
        "    true_boxes = tf.reshape(y_true[...,:5], [-1,S*S,1,5])\n",
        "    pred_boxes = tf.reshape(y_pred[...,:B*5], (-1,S*S,B,5))\n",
        "    # Reshape the 3: too S*S, B, 5 i.e. 49, 2, 5. \n",
        "    # Each cell has two bounding boxes, with each bounding box, having 5 elements. \n",
        "    \n",
        "    # Calculate the IOU for every box.\n",
        "    num = tf.math.multiply(true_boxes[...,1:5], pred_boxes[...,1:5])\n",
        "    denom = true_boxes[...,1:5] + pred_boxes[...,1:5] - num\n",
        "    iou = tf.math.reduce_sum(num/denom,  axis=-1)\n",
        "\n",
        "    # If boxes in the same cell have the same IOU, add 1 to the first box (since they are both equal) \n",
        "    duplicates = tf.where(tf.equal(iou[...,0], iou[...,1]))\n",
        "    iou = tf.tensor_scatter_nd_add(iou, duplicates, tf.add(tf.zeros_like(duplicates, dtype=tf.float32), [1,0]))\n",
        "    \n",
        "    # Get the indices of the max IOUs and grab the respetive boxes.\n",
        "    maxIou = tf.math.reduce_max(iou, axis=-1, keepdims=True)\n",
        "    maxIdx = tf.where(tf.equal(iou, maxIou))\n",
        "    best_boxes = tf.reshape(tf.gather_nd(pred_boxes, maxIdx), [-1, S*S,1,5])\n",
        "\n",
        "    y_pred_conf = best_boxes[...,0]\n",
        "    y_true_conf = true_boxes[...,0]\n",
        "    y_true_conf_noob = tf.math.subtract(tf.ones_like(y_true_conf), y_true_conf)\n",
        "    \n",
        "    y_pred_wh   = best_boxes[...,3:5]\n",
        "    y_true_wh   = true_boxes[...,3:5]\n",
        "    # y_pred_wh. Shape (S*S,B,2). Where each cell, has B bounding boxes, with each\n",
        "    # Bounding box having two rows?\n",
        "\n",
        "    y_pred_xy   = best_boxes[...,1:3] #+ grid\n",
        "    y_true_xy   = true_boxes[...,1:3]\n",
        "    # The y_true_xy will have a shape of S*S, B, 2. Where each cell, has B bounding boxes, with two colums? \n",
        "    # I understand grabbing the xy pairs, but why + the grid?\n",
        "    \n",
        "    y_true_class = tf.reshape(y_true[...,5:], [-1, S*S, C]) \n",
        "    y_pred_class = tf.reshape(y_pred[...,B*5:], [-1, S*S, C])\n",
        "    \n",
        "    \n",
        "    # Losses Calculations +++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "    xy_loss = lambdaCoord * tf.math.reduce_sum(tf.math.reduce_sum(tf.math.square(y_true_xy - y_pred_xy),\n",
        "                                                       axis=-1)*y_true_conf, axis=-1)\n",
        "    \n",
        "    # Two reduce sums  = 2 summations. Axis = -1, along last dimensions i.e. columns/entries in this case.\n",
        "    # Square is element wise. y_true_conf is the little 1, in the formula. \n",
        "    wh_loss = lambdaCoord * tf.math.reduce_sum(tf.math.reduce_sum(tf.math.square(tf.math.sqrt(y_true_wh) - \n",
        "                                                                      tf.math.sqrt(y_pred_wh)), axis=-1)\n",
        "                                    *y_true_conf, axis=-1)      \n",
        "\n",
        "\n",
        "    conf_loss = tf.math.reduce_sum(tf.math.square(y_true_conf - y_pred_conf)*y_true_conf, axis=-1)\n",
        "    conf_loss_noob = lambdaNoob * tf.math.reduce_sum(tf.math.square(y_true_conf - y_pred_conf)*y_true_conf_noob, axis=-1)\n",
        "\n",
        "    # Two reduce sums  = 2 summations. Axis = -1, along last dimensions i.e. rows in this case\n",
        "    # Makes sense, matches formula. \n",
        "    clss_loss  = tf.math.reduce_sum(tf.math.square(y_true_class - y_pred_class)*y_true_conf, axis=-1) \n",
        "\n",
        "    loss =  clss_loss + xy_loss + wh_loss + conf_loss + conf_loss_noob\n",
        "    \n",
        "    #print(\"\\n\",\"*\"*10, loss)\n",
        "\n",
        "    return loss"
      ],
      "id": "c9a0e7fc",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b57b7049"
      },
      "source": [
        "def jaccardIndex(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compares y_true with highest prob y_pred box\n",
        "    \"\"\"\n",
        "            \n",
        "    y_true = tf.reshape(y_true[...,:5], [-1,S*S,1,5])\n",
        "    y_pred = tf.reshape(y_pred[...,:B*5], [-1,S*S,B,5])\n",
        "    \n",
        "    y_true_box = tf.gather_nd(y_true, (tf.where(tf.equal(y_true[...,0], tf.math.reduce_max(y_true[...,0]))))[0])\n",
        "    y_pred_box = tf.gather_nd(y_pred, (tf.where(tf.equal(y_pred[...,0], tf.math.reduce_max(y_pred[...,0]))))[0])\n",
        "\n",
        "    numerator = (tf.math.reduce_sum(tf.math.multiply(y_true_box, y_pred_box)))\n",
        "    # Calculate the area of both - area that overlaps\n",
        "    denom = tf.math.reduce_sum(y_true_box) + tf.math.reduce_sum(y_pred_box) - numerator\n",
        "    iou = numerator/denom\n",
        "    \n",
        "    return iou"
      ],
      "id": "b57b7049",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6de8bcf3"
      },
      "source": [
        "# This max supression will only work when they're only exists a single class. Can be adapted.  \n",
        "def nonMaxSupression(y_true, y_pred):\n",
        "    maxTrueValue = tf.gather_nd(y_true, (tf.where(tf.equal(y_true[...,4], tf.math.reduce_max(y_true[...,4]))))[0])\n",
        "    # Grabs the max value along index 4 (reduce_max), then finds the index of the value in the tensor\n",
        "    maxPredIndex = (tf.where(tf.equal(y_pred[...,4], tf.math.reduce_max(y_pred[...,4]))))[0]\n",
        "    # Grabs the actual value, using index calculated above\n",
        "    maxPredValue = tf.gather_nd(y_pred, maxPredIndex)\n",
        "    idx = generateIndexes()\n",
        "    # Disgusting time complexity :D\n",
        "    for i in range(len(idx)):\n",
        "        box = tf.gather_nd(y_pred, idx[i])\n",
        "        val = iou(maxPredValue, box)\n",
        "        if val < 0.5:\n",
        "            del idx[i]"
      ],
      "id": "6de8bcf3",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e69a0a90"
      },
      "source": [
        "y_pred = tf.zeros([BATCH_SIZE, 7, 7, 11])\n",
        "for image, box in train_batches.take(1):\n",
        "    y_true = box\n",
        "    try:\n",
        "      output = yoloLoss(y_true, y_pred)\n",
        "    except:\n",
        "      print(\"*\" * 10,y_true)\n",
        "      print('\\n', \"*\" * 10, y_pred) \n",
        "#jaccard = jaccardIndex(y_true, y_pred)"
      ],
      "id": "e69a0a90",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceb8626f"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=yoloLoss,\n",
        "              metrics=[jaccardIndex], run_eagerly=True)"
      ],
      "id": "ceb8626f",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eccd75b4"
      },
      "source": [
        "#model.summary()"
      ],
      "id": "eccd75b4",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efd8bb4a"
      },
      "source": [
        "history =  model.fit(train_batches, epochs=1, validation_data=validation_batches)"
      ],
      "id": "efd8bb4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b378a31"
      },
      "source": [
        "for image, box in test.take(1):\n",
        "  print(box)"
      ],
      "id": "2b378a31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPbqy6uSdj4A"
      },
      "source": [
        ""
      ],
      "id": "SPbqy6uSdj4A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0ZLzqgOerV9"
      },
      "source": [
        ""
      ],
      "id": "L0ZLzqgOerV9",
      "execution_count": null,
      "outputs": []
    }
  ]
}