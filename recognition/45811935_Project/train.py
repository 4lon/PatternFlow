"""
    Performs all training/validating/testing/saving of models and plotting of results (i.e.
    losses and metrics during training/validation).

    Author: Adrian Rahul Kamal Rajkamal
    Student Number: 45811935
"""
from dataset import *
from modules import *
import keras.callbacks
from keras import optimizers
import tensorflow_probability as tfp
import matplotlib.pyplot as plt

""" Main data-related constants """
FILE_PATH = "./ADNI_AD_NC_2D/AD_NC/"
IMG_DIMENSION = 256
SEED = 42

""" Hyper-parameters """
RGB = True
NUM_EMBEDDINGS = 256
BATCH_SIZE = 32
LATENT_DIM = 32
PIXEL_SHIFT = 0.5
NUM_EPOCHS = 30
VALIDATION_SPLIT = 0.3
LEARNING_RATE = 0.001
OPTIMISER = optimizers.Adam(learning_rate=LEARNING_RATE)

# Check if GPU is available and if so use it, otherwise use CPU
gpu_used = len(tf.config.list_physical_devices('GPU'))
device = "/GPU:0" if gpu_used else "/CPU:0"

# Load and pre-process data
train_data = load_preprocess_image_data(path=FILE_PATH + "train", img_dim=IMG_DIMENSION,
                                        batch_size=BATCH_SIZE, rgb=RGB,
                                        validation_split=VALIDATION_SPLIT, subset="training",
                                        seed=SEED, shift=PIXEL_SHIFT)

val_data = load_preprocess_image_data(path=FILE_PATH + "train", img_dim=IMG_DIMENSION,
                                      batch_size=BATCH_SIZE, rgb=RGB,
                                      validation_split=VALIDATION_SPLIT, subset="validation",
                                      seed=SEED, shift=PIXEL_SHIFT)

test_data = load_preprocess_image_data(path=FILE_PATH + "test", img_dim=IMG_DIMENSION,
                                       batch_size=BATCH_SIZE, rgb=RGB, shift=PIXEL_SHIFT)


# Calculate number of elements in each dataset (i.e. unbatched)
full_train_data = train_data.unbatch()
num_train_images = full_train_data.reduce(np.int32(0), lambda x, _: x + 1).numpy()

full_val_data = val_data.unbatch()
num_val_images = full_val_data.reduce(np.int32(0), lambda x, _: x + 1).numpy()

full_test_data = test_data.unbatch()
num_test_images = full_test_data.reduce(np.int32(0), lambda x, _: x + 1).numpy()

# Calculate (unbiased) training variance (across all pixels of all images)
num_train_pixels = num_train_images * IMG_DIMENSION ** 2

image_sum = full_train_data.reduce(np.float32(0), lambda x, y: x + y).numpy().flatten()
total_pixel_sum = image_sum.sum()
mean_pixel_train = total_pixel_sum / num_train_pixels

image_sse = full_train_data.reduce(np.float32(0), lambda x, y: x + (y - mean_pixel_train) ** 2) \
    .numpy().flatten()
var_pixel_train = image_sse.sum() / (num_train_pixels - 1)

# Create VQ-VAE model
vqvae = VQVAE(tr_var=var_pixel_train, num_encoded=NUM_EMBEDDINGS, latent_dim=LATENT_DIM, rgb=RGB)


# Define SSIM metric and Callback


def mean_ssim(data, data_size, model):
    """
    Calculate mean SSIM over given dataset, comparing reconstructions generated by the given model.

    Args:
        data: The given dataset (e.g. training/validation/test)
        data_size: The number of elements in the (entire) dataset
        model: The given model

    Returns: mean SSIM over data.

    """
    ssim_sum = 0

    for image_batch in data:
        # Unshift the normalised images and reconstructions in this batch
        image_batch_unshifted = image_batch + PIXEL_SHIFT
        reconstruction_batch = model.predict(image_batch)
        reconstruction_batch_unshifted = reconstruction_batch + PIXEL_SHIFT

        # Calculate and sum over all SSIMs between images in this batch (max_val of 1 as the images
        # are still normalised by the constant of 255)
        total_batch_ssim = tf.math.reduce_sum(tf.image.ssim(image_batch_unshifted,
                                                            reconstruction_batch_unshifted,
                                                            max_val=1.0))
        # Add batch sum SSIM to total
        ssim_sum += total_batch_ssim

    # Return mean SSIM over entire dataset
    return ssim_sum / data_size


class SSIMTracking(keras.callbacks.Callback):
    """ Calculates and displays the mean SSIM after each epoch """

    def __init__(self, dataset, dataset_size, dataset_name="Training"):
        super(SSIMTracking, self).__init__()
        self._dataset = dataset
        self._dataset_name = dataset_name
        self._dataset_size = dataset_size

    def on_epoch_end(self, epoch, logs=None):
        """ Calculate and display the mean SSIM on each epoch """
        print(f"Epoch {epoch}: {self._dataset_name} Mean SSIM: "
              f"{mean_ssim(self._dataset, self._dataset_size, self.model)}")


# Train VQ-VAE
vqvae.compile(optimizer=OPTIMISER)

with tf.device(device):
    history = vqvae.fit(train_data,
                        epochs=NUM_EPOCHS,
                        batch_size=BATCH_SIZE,
                        callbacks=[SSIMTracking(dataset=train_data, dataset_size=num_train_images),
                                   SSIMTracking(dataset=val_data, dataset_size=num_val_images,
                                                dataset_name="Validation")]
                        )

# Save

# Plot

# Test/generate --> maybe load saved model above and put this in predict.py

# Get trained VQ-VAE codebooks

# Create PixelCNN model

# Compile & Fit (with trained VQ-VAE codebooks)

# Save

# Plot

# Test/generate --> maybe load saved model above and put this in predict.py
