"""
    Performs all training/validating/testing/saving of models and plotting of results (i.e.
    losses and metrics during training/validation).

    Author: Adrian Rahul Kamal Rajkamal
    Student Number: 45811935
"""
from os import mkdir
from os.path import exists
from dataset import *
from modules import *
import keras.callbacks
from keras import optimizers
from keras.models import load_model
import tensorflow_probability as tfp
import matplotlib.pyplot as plt
import pandas as pd

""" Main data/setup-related constants """
FILE_PATH = "./ADNI_AD_NC_2D/AD_NC/"
SAVED_MODEL_PATH = "./SavedModels/"  # Doesn't have to exist yet - code will create directory if not
RESULTS_PATH = "./Results/"  # Doesn't have to exist yet - code will create directory if not
IMG_DIMENSION = 256
SEED = 42
TRAINING_VQVAE = False  # Set to True to train the VQ-VAE
TRAINING_PIXELCNN = True  # Set to True train the PixelCNN

""" Hyper-parameters """
RGB = True
NUM_EMBEDDINGS = 256
BATCH_SIZE = 32
LATENT_DIM = 32
PIXEL_SHIFT = 0.5
NUM_EPOCHS_VQVAE = 7
NUM_EPOCHS_PIXEL = 30
VALIDATION_SPLIT = 0.3
LEARNING_RATE = 0.001
OPTIMISER = optimizers.Adam(learning_rate=LEARNING_RATE)

# Check if GPU is available and if so use it, otherwise use CPU
gpu_used = len(tf.config.list_physical_devices('GPU'))
device = "/GPU:0" if gpu_used else "/CPU:0"

# Load and pre-process data
train_data = load_preprocess_image_data(path=FILE_PATH + "train", img_dim=IMG_DIMENSION,
                                        batch_size=BATCH_SIZE, rgb=RGB,
                                        validation_split=VALIDATION_SPLIT, subset="training",
                                        seed=SEED, shift=PIXEL_SHIFT)

val_data = load_preprocess_image_data(path=FILE_PATH + "train", img_dim=IMG_DIMENSION,
                                      batch_size=BATCH_SIZE, rgb=RGB,
                                      validation_split=VALIDATION_SPLIT, subset="validation",
                                      seed=SEED, shift=PIXEL_SHIFT)

test_data = load_preprocess_image_data(path=FILE_PATH + "test", img_dim=IMG_DIMENSION,
                                       batch_size=BATCH_SIZE, rgb=RGB, shift=PIXEL_SHIFT)


# Calculate number of elements in each dataset (i.e. unbatched)
full_train_data = train_data.unbatch()
num_train_images = full_train_data.reduce(np.int32(0), lambda x, _: x + 1).numpy()

full_val_data = val_data.unbatch()
num_val_images = full_val_data.reduce(np.int32(0), lambda x, _: x + 1).numpy()

full_test_data = test_data.unbatch()
num_test_images = full_test_data.reduce(np.int32(0), lambda x, _: x + 1).numpy()

# Calculate (unbiased) training variance (across all pixels of all images)
num_train_pixels = num_train_images * IMG_DIMENSION ** 2

image_sum = full_train_data.reduce(np.float32(0), lambda x, y: x + y).numpy().flatten()
total_pixel_sum = image_sum.sum()
mean_pixel_train = total_pixel_sum / num_train_pixels

image_sse = full_train_data.reduce(np.float32(0), lambda x, y: x + (y - mean_pixel_train) ** 2) \
    .numpy().flatten()
var_pixel_train = image_sse.sum() / (num_train_pixels - 1)

# Create VQ-VAE model
vqvae = VQVAE(tr_var=var_pixel_train, num_encoded=NUM_EMBEDDINGS, latent_dim=LATENT_DIM, rgb=RGB)


# Define SSIM metric


def mean_ssim(data, data_size, model):
    """
    Calculate mean SSIM over given dataset, comparing reconstructions generated by the given model.

    Args:
        data: The given dataset (e.g. training/validation/test)
        data_size: The number of elements in the (entire) dataset
        model: The given model

    Returns: mean SSIM over data.

    """
    ssim_sum = 0

    for image_batch in data:
        # Unshift the normalised images and reconstructions in this batch
        image_batch_unshifted = image_batch + PIXEL_SHIFT
        reconstruction_batch = model.predict(image_batch)
        reconstruction_batch_unshifted = reconstruction_batch + PIXEL_SHIFT

        # Calculate and sum over all SSIMs between images in this batch (max_val of 1 as the images
        # are still normalised by the constant of 255)
        total_batch_ssim = tf.math.reduce_sum(tf.image.ssim(image_batch_unshifted,
                                                            reconstruction_batch_unshifted,
                                                            max_val=1.0))
        # Add batch sum SSIM to total
        ssim_sum += total_batch_ssim

    # Return mean SSIM over entire dataset
    return (ssim_sum / data_size).numpy()


# Create directory to store model results (if said directory does not already exist)
if not exists(SAVED_MODEL_PATH):
    mkdir(SAVED_MODEL_PATH)

# Store training loss/metric results in CSV file - change append parameter to True if wanting to
# continue training
training_csv_logger = keras.callbacks.CSVLogger(SAVED_MODEL_PATH + 'training.log', separator=',',
                                                append=False)

# Initialise final mean SSIM values
final_train_mean_ssim = final_val_mean_ssim = 0

# Train VQ-VAE
vqvae.compile(optimizer=OPTIMISER)

if TRAINING_VQVAE:
    with tf.device(device):
        # Train data (datasets are of type tf.dataset, so are already batched - hence no need to
        # specify batch sizes here)
        vqvae.fit(train_data, epochs=NUM_EPOCHS_VQVAE, callbacks=[training_csv_logger],
                  validation_data=val_data)

        # Final SSIM Values
        final_train_mean_ssim = mean_ssim(train_data, num_train_images, vqvae)
        final_val_mean_ssim = mean_ssim(val_data, num_val_images, vqvae)
        print("Final Training Mean SSIM", final_train_mean_ssim)
        print("Final Validation Mean SSIM", final_val_mean_ssim)

    # Save model
    vqvae.save(SAVED_MODEL_PATH + "trained_model")


vqvae = load_model(SAVED_MODEL_PATH + "trained_model")
print(vqvae.summary())

# Plot training losses/metrics


def plot_results(epoch_results):
    """ Plots and saves all train/val losses"""
    # Make folder to save plots
    if not exists(RESULTS_PATH):
        mkdir(RESULTS_PATH)

    # Total losses
    plt.figure()
    plt.plot(epoch_results['total_loss'], label='Total Loss (Training)')
    plt.plot(epoch_results['val_total_loss'], label='Total Loss (Validation)')

    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Total Loss')
    plt.legend(loc='upper right')

    plt.savefig(RESULTS_PATH + 'total_losses.png')

    # Reconstruction losses
    plt.figure()
    plt.plot(epoch_results['reconstruction_loss'], label='Reconstruction Loss (Training)')
    plt.plot(epoch_results['val_reconstruction_loss'], label='Reconstruction Loss (Validation)')

    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Total Loss')
    plt.legend(loc='upper right')

    plt.savefig(RESULTS_PATH + 'reconstruction_losses.png')

    # Quantisation losses
    plt.figure()
    plt.plot(epoch_results['vq_loss'], label='Quantisation Loss (Training)')
    plt.plot(epoch_results['val_vq_loss'], label='Quantisation Loss (Validation)')

    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Total Loss')
    plt.legend(loc='upper right')

    plt.savefig(RESULTS_PATH + 'quantisation_losses.png')


training_results = pd.read_csv(SAVED_MODEL_PATH + 'training.log', sep=',', engine='python')
plot_results(training_results)

# Generate reconstructions on test set


# Get trained VQ-VAE codebooks

# Create PixelCNN model

# Compile & Fit (with trained VQ-VAE codebooks)

if TRAINING_PIXELCNN:
    pass

# Save

# Plot

# Test/generate --> maybe load saved model above and put this in predict.py

# FROM Ed: I would do a full test set prediction in train.py as it is a necessary step during
# model development, and only predict on a few samples in predict.py to demonstrate running the code
# in inference mode.
