"""
    Performs all training/validating/testing/saving of models and plotting of results (i.e.
    losses and metrics during training/validation).

    Author: Adrian Rahul Kamal Rajkamal
    Student Number: 45811935
"""
import sys
from os import mkdir
from os.path import exists
from dataset import *
from modules import *
import keras.callbacks
from keras import optimizers, losses
import tensorflow_probability as tfp
import matplotlib.pyplot as plt
import pandas as pd

""" Main data/setup-related constants """
FILE_PATH = "./ADNI_AD_NC_2D/AD_NC/"
SAVED_WEIGHTS_PATH = "./SavedWeights/"  # Doesn't have to exist - code will create directory if not
RESULTS_PATH = "./Results/"  # Doesn't have to exist yet - code will create directory if not
IMG_SHAPE = 256
SEED = 42
NUM_IMAGES_TO_SHOW = 5

TRAINING_VQVAE = False  # Set to True to train the VQ-VAE
TRAINING_PIXELCNN = True  # Set to True train the PixelCNN

""" Hyper-parameters """
RGB = True
BETA = 0.25
NUM_EMBEDDINGS = 256
BATCH_SIZE = 32
LATENT_DIM = 32
PIXEL_SHIFT = 0.5
NUM_EPOCHS_VQVAE = 7
NUM_EPOCHS_PIXEL = 30
VALIDATION_SPLIT = 0.3
VQVAE_LEARNING_RATE = 0.001
VQVAE_OPTIMISER = optimizers.Adam(learning_rate=VQVAE_LEARNING_RATE)
NUM_RESIDUAL_LAYERS = 2
NUM_PIXEL_B_LAYERS = 2
PIXEL_CNN_LEARNING_RATE = VQVAE_LEARNING_RATE
PIXEL_CNN_OPTIMISER = VQVAE_OPTIMISER
PIXEL_CNN_LOSS = losses.SparseCategoricalCrossentropy(from_logits=True)

# Define the number of channels in each image based on whether it is RGB or grayscale
num_channels = 3 if RGB else 1

# Check if GPU is available and if so use it, otherwise use CPU
gpu_used = len(tf.config.list_physical_devices('GPU'))
device = "/GPU:0" if gpu_used else "/CPU:0"

""" Loading Data and Calculating Variance & Mean SSIM """

# Load and pre-process data
train_data = load_preprocess_image_data(path=FILE_PATH + "train", img_dim=IMG_SHAPE,
                                        batch_size=BATCH_SIZE, rgb=RGB,
                                        validation_split=VALIDATION_SPLIT, subset="training",
                                        seed=SEED, shift=PIXEL_SHIFT)

val_data = load_preprocess_image_data(path=FILE_PATH + "train", img_dim=IMG_SHAPE,
                                      batch_size=BATCH_SIZE, rgb=RGB,
                                      validation_split=VALIDATION_SPLIT, subset="validation",
                                      seed=SEED, shift=PIXEL_SHIFT)

test_data = load_preprocess_image_data(path=FILE_PATH + "test", img_dim=IMG_SHAPE,
                                       batch_size=BATCH_SIZE, rgb=RGB, shift=PIXEL_SHIFT)


# Calculate number of elements in each dataset (i.e. unbatched)
full_train_data = train_data.unbatch()
num_train_images = full_train_data.reduce(np.int32(0), lambda x, _: x + 1).numpy()

full_val_data = val_data.unbatch()
num_val_images = full_val_data.reduce(np.int32(0), lambda x, _: x + 1).numpy()

full_test_data = test_data.unbatch()
num_test_images = full_test_data.reduce(np.int32(0), lambda x, _: x + 1).numpy()

# Calculate (unbiased) training variance (across all pixels of all images)
num_train_pixels = num_train_images * num_channels * IMG_SHAPE ** 2

image_sum = full_train_data.reduce(np.float32(0), lambda x, y: x + y).numpy().flatten()
total_pixel_sum = image_sum.sum()
mean_pixel_train = total_pixel_sum / num_train_pixels

image_sse = full_train_data.reduce(np.float32(0), lambda x, y: x + (y - mean_pixel_train) ** 2) \
    .numpy().flatten()
var_pixel_train = image_sse.sum() / (num_train_pixels - 1)

# Define SSIM metric


def mean_ssim(data, data_size, model):
    """
    Calculate mean SSIM over given dataset, comparing reconstructions generated by the given model.

    Args:
        data: The given dataset (e.g. training/validation/test)
        data_size: The number of elements in the (entire) dataset
        model: The given model

    Returns: mean SSIM over data.

    """
    ssim_sum = 0

    for image_batch in data:
        # Unshift the normalised images and reconstructions in this batch
        image_batch_unshifted = image_batch + PIXEL_SHIFT
        reconstruction_batch = model.predict(image_batch)
        reconstruction_batch_unshifted = reconstruction_batch + PIXEL_SHIFT

        # Calculate and sum over all SSIMs between images in this batch (max_val of 1 as the images
        # are still normalised by the constant of 255)
        total_batch_ssim = tf.math.reduce_sum(tf.image.ssim(image_batch_unshifted,
                                                            reconstruction_batch_unshifted,
                                                            max_val=1.0))
        # Add batch sum SSIM to total
        ssim_sum += total_batch_ssim

    # Return mean SSIM over entire dataset
    return (ssim_sum / data_size).numpy()


""" VQ-VAE Model (Train/Val/Test/Save/Plot) """


# Create VQ-VAE model
vqvae = VQVAE(tr_var=var_pixel_train, num_encoded=NUM_EMBEDDINGS, latent_dim=LATENT_DIM, beta=BETA,
              num_channels=num_channels)


# Create directory to store model weights (if said directory does not already exist)
if not exists(SAVED_WEIGHTS_PATH):
    mkdir(SAVED_WEIGHTS_PATH)
    
# Create directory to save all results (if said directory does not already exist)
    if not exists(RESULTS_PATH):
        mkdir(RESULTS_PATH)

# Store training loss/metric results in CSV file - change append parameter to True if wanting to
# continue training
training_csv_logger = keras.callbacks.CSVLogger(SAVED_WEIGHTS_PATH + 'training.log', separator=',',
                                                append=False)

# Initialise final mean SSIM values
final_train_mean_ssim = final_val_mean_ssim = 0

# Train VQ-VAE
vqvae.compile(optimizer=VQVAE_OPTIMISER)

if TRAINING_VQVAE:
    with tf.device(device):
        # Train data (datasets are of type tf.dataset, so are already batched - hence no need to
        # specify batch sizes here)
        vqvae.fit(train_data, epochs=NUM_EPOCHS_VQVAE, callbacks=[training_csv_logger],
                  validation_data=val_data)

        # Final SSIM Values
        final_train_mean_ssim = mean_ssim(train_data, num_train_images, vqvae)
        final_val_mean_ssim = mean_ssim(val_data, num_val_images, vqvae)

        # Print results to file
        main_stdout = sys.stdout

        with open(RESULTS_PATH + 'main_results.txt', 'a') as f:
            sys.stdout = f
            print("Final Training Mean SSIM", final_train_mean_ssim)
            print("Final Validation Mean SSIM", final_val_mean_ssim)
            sys.stdout = main_stdout

        # Save trained model
        vqvae.save_weights(SAVED_WEIGHTS_PATH + "trained_model_weights")

# Load trained model
vqvae = VQVAE(tr_var=var_pixel_train, num_encoded=NUM_EMBEDDINGS, latent_dim=LATENT_DIM,
              num_channels=num_channels)
vqvae.load_weights(SAVED_WEIGHTS_PATH + "trained_model_weights")

# Plot training losses/metrics


def plot_results(epoch_results):
    """ Plots and saves all train/val losses"""
    # Total losses
    plt.figure()
    plt.plot(epoch_results['total_loss'], label='Total Loss (Training)')
    plt.plot(epoch_results['val_total_loss'], label='Total Loss (Validation)')

    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Total Loss')
    plt.legend(loc='upper right')

    plt.savefig(RESULTS_PATH + 'total_losses.png')

    # Reconstruction losses
    plt.figure()
    plt.plot(epoch_results['reconstruction_loss'], label='Reconstruction Loss (Training)')
    plt.plot(epoch_results['val_reconstruction_loss'], label='Reconstruction Loss (Validation)')

    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Total Loss')
    plt.legend(loc='upper right')

    plt.savefig(RESULTS_PATH + 'reconstruction_losses.png')

    # Quantisation losses
    plt.figure()
    plt.plot(epoch_results['vq_loss'], label='Quantisation Loss (Training)')
    plt.plot(epoch_results['val_vq_loss'], label='Quantisation Loss (Validation)')

    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Total Loss')
    plt.legend(loc='upper right')

    plt.savefig(RESULTS_PATH + 'quantisation_losses.png')


training_results = pd.read_csv(SAVED_WEIGHTS_PATH + 'training.log', sep=',', engine='python')
plot_results(training_results)


def show_vqvae_results(images):
    """
    Plots and saves the input, codebook, and reconstructions made by the VQ-VAE, of the given 
    images. Also calculates and saves the SSIM between each image and its reconstruction.
    
    Args:
        images: images to pass through the VQ-VAE

    Returns:
        Saves VQ-VAE images and SSIM results
    """

    # Reconstruction
    reconstructed = vqvae.predict(images)
    
    # Code (Flattened)
    encoder_outputs = vqvae.get_encoder().predict(images)
    encoder_outputs_flattened = encoder_outputs.reshape(-1, encoder_outputs.shape[-1])
    codebook_indices = vqvae.get_vq().get_codebook_indices(encoder_outputs_flattened)
    
    # Code (reshaped)
    codebook_indices = codebook_indices.numpy().reshape(encoder_outputs.shape[:-1])
    
    # Unshift and reshape reconstructions and original images and print SSIM values
    plt.figure()
    for i in range(len(images)):
        test_image = tf.reshape(images[i], (1, IMG_SHAPE, IMG_SHAPE, num_channels))\
                         + PIXEL_SHIFT
    
        reconstructed_image = tf.reshape(reconstructed[i],
                                         (1, IMG_SHAPE, IMG_SHAPE, num_channels)) + PIXEL_SHIFT
    
        codebook_image = codebook_indices[i]
    
        plt.subplot(1, 3, 1)
        plt.imshow(tf.squeeze(test_image))
        plt.title("Test Image")
        plt.axis("off")
    
        plt.subplot(1, 3, 2)
        plt.imshow(codebook_image)
        plt.title("Codebook")
        plt.axis("off")
    
        plt.subplot(1, 3, 3)
        plt.imshow(tf.squeeze(reconstructed_image))
        plt.title("Reconstruction")
        plt.axis("off")
    
        plt.savefig(RESULTS_PATH + f'vq_vae_reconstructions_{i}.png')
    
        ssim = tf.math.reduce_sum(tf.image.ssim(test_image, reconstructed_image, max_val=1.0)).numpy()
    
        main_stdout = sys.stdout
        with open(RESULTS_PATH + 'main_results.txt', 'a') as f:
            sys.stdout = f
            print(f"SSIM between Test Image {i} and Reconstruction: ", ssim)
            sys.stdout = main_stdout


# Generate and plot 10 reconstructions from test set, along with their codes and inputs and SSIMs
for sample_batch in test_data.take(1).as_numpy_iterator():
    sample_batch = sample_batch[:NUM_IMAGES_TO_SHOW]
    show_vqvae_results(sample_batch)


# Print overall mean test SSIM for VQ-VAE to file:
with tf.device(device):
    test_mean_ssim_vqvae = mean_ssim(test_data, num_test_images, vqvae)
    main_stdout = sys.stdout
    with open(RESULTS_PATH + 'main_results.txt', 'a') as f:
        sys.stdout = f
        print("VQ-VAE Test Mean SSIM:", test_mean_ssim_vqvae)
        sys.stdout = main_stdout

""" PixelCNN Model (Train/Val/Test/Save/Plot) """

# Get trained VQ-VAE codebooks

# Create PixelCNN model

# Compile & Fit (with trained VQ-VAE codebooks)

# Save

# Plot

# Test/generate --> maybe load saved model above and put this in predict.py

# FROM Ed: I would do a full test set prediction in train.py as it is a necessary step during
# model development, and only predict on a few samples in predict.py to demonstrate running the code
# in inference mode.
