# Knee MRI Image stylegan
Student name: Mengyao Ma
Student number: s4585787  

### Generative Adversarial Network 
![Gan structure](recognition\45857876\images\gan.png)  
**GAN** is short for **Generative Adversarial Network** proposed by Ian Goodfellow in 2014. The main structure of GAN includes a **Generator(G)** and a **Discriminator (D)**.  For the generator, the input requires an n-dimensional vector, and the output is a picture with the pixel size of the picture, while the discriminator discriminates the pictures generated by the generator and labels them as "fake" or "real".   


### StyleGAN
**StyleGAN** is inspired by **style transfer**  to design a **new generator structure**.  In addtion, StyleGAN is **evolved** from **ProGAN** and uses a similar network structure. StyleGAN uses style to affect the posture and identity characteristics of the face, and noise to affect details such as hair strands, wrinkles, and skin tone. 


## The main StyleGAN structure  
[Traditional genertaor and StyleGAN generator](recognition\45857876\images\v2-f1db8c75f4efd04e7eef68b56fefc4d3_1440w.jpg)  
Through observation, it can be found that different layers and resolutions will affect different features. The lower the layer and resolution, the coarser the features it affects. We can divide these characteristics into three types:  
1. Rough-(resolution 0-8^2^), affecting posture, general hairstyle, facial shape, etc.; 
2. Medium-(resolution 16^2^-32^2^), affecting finer facial features, hairstyles, opening of eyes or Closed, etc.; 
3. High-quality-(resolution 64^2^-1024^2^), affecting color (eyes, hair and skin) and microscopic features;  

In traditional gan, the generator only feeds the random variables as latent code into input layer.
### Mapping Network

To better solve the Feature unwrapping problem, the Mapping network is added into Generator. It consists of 8 fully connected layers. The Mapping network convert the latent code into 18 vectors after affin transform. These vectors A learned affin transform are added into the synthesis generator network(two for each resolution). The vectors A can control the style on certain resolution.

### AdaIN module

[AdaIN](recognition\45857876\images\20190325144840976.png)   
At each resolution, two A will affect the generator twice, once after Upsampling and once after Convolution by using AdaIN.
Like the equation ablow, expand A into scaling factors y~ùë†,ùëñ~ and deviation factors y~ùëè,ùëñ~, and make a weighted sum of these two factors and the normalized convolution output to apply an influence.  

### Random nosie

To control the character detail and diversity of image generated, add a scaled noise to each channel before the Adain module. 

### Style mixing



## loss function applied

In this task, I explore two loss functions to find the influence of loss function.  

### 1.  Logistic  loss function
### 2. Relativistic Average Hinge loss function


## Output of each resolution 

## Style mixing output

[test_image](recognition\45857876\images\figure03-style-mixing.png)  

## Requirments

yacs
tqdm
numpy (only for visualization)
torchvision
torch

## Execute the code

python train.py
The default setting:

## Reference
Paper:  
Code:   
https://github.com/lernapparat/lernapparat
https://github.com/NVlabs/stylegan
https://github.com/akanimax/pro_gan_pytorch
