{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"styleGAN.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1MGdz7dTs_VJ5__my50nr_cxgBhH72Vgm","authorship_tag":"ABX9TyMjAHVLi9HAUMcElLvapyql"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hHzcLRkr6BIE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635321329055,"user_tz":-600,"elapsed":497,"user":{"displayName":"Joe Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16493752761663840459"}},"outputId":"d3fdb44b-34ef-437b-e455-dfe95ce1f63a"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Oct 27 07:55:27 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    46W / 350W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"EgruSdeh6Dl7"},"source":["!unzip 'drive/MyDrive/COMP3710/OASIS.zip' -d 'sample_data/data/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SHZFAdKXLPrg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635321702239,"user_tz":-600,"elapsed":332,"user":{"displayName":"Joe Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16493752761663840459"}},"outputId":"ce787127-ee36-4813-fc65-152fc5f5b795"},"source":["import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt \n","import torch \n","import torch.nn as nn \n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import grad\n","from torch.utils.data import DataLoader,SubsetRandomSampler\n","from torchvision.utils import save_image\n","from torchvision.utils import make_grid\n","from torchvision.io import read_image\n","from torchvision import datasets, transforms\n","from torchsummary import summary\n","import pickle as pkl\n","from tqdm import tqdm\n","from PIL import Image\n","torch.manual_seed(777)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fc2069239d0>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"O83d9dbYZiCY"},"source":["\"\"\"\n","learned from:\n","https://github.com/lernapparat/lernapparat/blob/master/style_gan/pytorch_style_gan_test_discriminator.ipynb\n","https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/GANs/StyleGAN/model.py\n","https://github.com/facebookresearch/pytorch_GAN_zoo/tree/b75dee40918caabb4fe7ec561522717bf096a8cb/models/networks\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRi5GeWQE1Tl"},"source":["class WScaledConv(nn.Module): #output shape tested\n","  \"\"\"\n","  Weight scaled conv2d,\n","  input: b *in_features *H *W\n","  output: b *out_features *H *W (weight scaled)\n","  \"\"\"\n","  def __init__(self, ins, outs, k_size=3, stride=1, padding=1):\n","    #super(WScaledConv, self).__init__()\n","    super().__init__()\n","    self.k_size = k_size\n","    self.stride = stride\n","    self.padding = padding\n","\n","    #gain is usually set to 2**0.5 as default\n","    self.scale = (2/(k_size*k_size*ins))**(1/2)\n","    self.w = torch.nn.Parameter(torch.randn(outs, ins, k_size, k_size))\n","    self.bias = torch.nn.Parameter(torch.zeros(outs))\n","  def forward(self, x):\n","    return F.conv2d(x, self.w*self.scale, self.bias, stride=self.stride, padding=self.padding)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O6NXAWyi-zb9"},"source":["class WScaledLinear(nn.Module): #output shape tested\n","  \"\"\"\n","  Weight scaled Linear,\n","  input: b *in_channels *H *W\n","  output: b *out_channels *H *W (weight scaled)\n","  \"\"\"\n","  def __init__(self, ins=512, outs=512, lr_mul=1.0):\n","    #super(WScaledLinear, self).__init__()\n","    super().__init__()\n","    self.ins=ins\n","    self.outs=outs\n","    self.lr_mul=lr_mul\n","\n","    self.scale=((2/ins)**(1/2))*self.lr_mul\n","    self.w=torch.nn.Parameter(torch.randn(outs, ins))\n","    self.bias=torch.nn.Parameter(torch.zeros(outs))\n","  def forward(self, x):\n","    return F.linear(x, self.w*self.scale, self.bias)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ew0zoafQOpB8"},"source":["class PixelNorm(nn.Module): #embedding into MappingNet, not used anymore\n","  \"\"\"\n","  Pixel normalization,\n","  input: b *z_dimension\n","  output: b *z_dimension (normalized)\n","  \"\"\"\n","  def __init__(self, epsilon=1e-8):\n","    #super(PixelNorm, self).__init__()\n","    super().__init__()\n","    self.epsilon=epsilon\n","  def forward(self, x):\n","    #normalize by avearage value across dimension 1 plus epsilon\n","    x_=(x*x).mean(dim=1,keepdim=True)+self.epsilon\n","    return x/(x_**0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hnbWGfFdR5xV"},"source":["class MappingNet(nn.Module): #output shape tested\n","  \"\"\"\n","  8-dense-layers MappingNet, projecting latent z(ins) to w(outs)\n","  PixelNorm is merged into here\n","  input: b *z_dimension\n","  output: b *w_dimension\n","  \"\"\"\n","  def __init__(self,ins=512,outs=512,n_layers=8):\n","    super().__init__()\n","    self.mapping=nn.ModuleList()\n","    #self.mapping.append(PixelNorm())\n","    self.mapping.append(WScaledLinear(ins,outs,lr_mul=0.01))\n","    for i in range(n_layers-1):\n","      self.mapping.append(nn.ReLU())\n","      self.mapping.append(WScaledLinear(outs,outs,lr_mul=0.01))\n","  def forward(self, x):\n","    #PixelNorm\n","    x_=(x*x).mean(dim=1,keepdim=True)+1e-8 #epsilon=1e-8\n","    x=x/(x_**0.5)\n","    #8 dense layers\n","    for model in self.mapping:\n","      x=model(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NQmu2L12S4Kh"},"source":["class AdaIN(nn.Module): #output shape tested\n","  \"\"\"\n","  Adaptive Instance Norm,\n","  latent w required for using \"style\", use WScaledLinear(ins(w), outs(c))\n","  where w is the #-output of the mapping net and c is the #-output channels of the previous layer\n","  input: w, b *w_dim, and x, b *in_features *H *W\n","  output: x, b *out_features *H *W (multiplied by and added with style)\n","  \"\"\"\n","  def __init__(self, ins=512, outs=512): \n","    #super(AdaIN, self).__init__()\n","    super().__init__()\n","    self.insnorm=nn.InstanceNorm2d(outs,affine=False)# facebookresearch uses eps=1e-08\n","    self.style_wfactor=WScaledLinear(ins,outs)\n","    self.style_bias=WScaledLinear(ins,outs)\n","  def forward(self, x, w):\n","    #latent w is the output of the mapping net\n","    #x is the output of the previous layer\n","    size=x.size()\n","    style_wf=self.style_wfactor(w).view(size[0],size[1],1,1)\n","    style_b=self.style_bias(w).view(size[0],size[1],1,1)\n","    return x*style_wf+style_b\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6SdSwOwpveo"},"source":["class Gblock(nn.Module): #output shape tested\n","  \"\"\"\n","  Generative block,\n","  each block contains one upscale layer and two conv layers (except for the initial block)\n","  input: w, b *w_dim, and x, b *in_features *H *W\n","  output: x, b *out_features *H *W \n","  \"\"\"\n","  def __init__(self, initial=False, ins=512, outs=512, b_size=32):\n","    #super(Gblock, self).__init__()\n","    super().__init__()\n","    self.initial=initial\n","    self.ins=ins\n","    self.outs=outs\n","    self.b_size=b_size\n","    \n","    if self.initial:\n","      self.const=nn.Parameter(torch.ones((b_size,ins,4,4)))\n","      self.noise_scaler1=((2/(4*4*self.ins))**(1/2))\n","    else:\n","      self.conv1=WScaledConv(ins=self.ins,outs=self.outs)\n","      self.noise_scaler1=((2/(3*3*self.ins))**(1/2))\n","    self.noise_w1=nn.Parameter(torch.zeros(1,self.outs,1,1))\n","    self.ada1=AdaIN(outs=outs)\n","\n","    self.conv2=WScaledConv(ins=self.outs,outs=self.outs)\n","    self.noise_scaler2=((2/(3*3*self.outs))**(1/2))\n","    self.noise_w2=nn.Parameter(torch.zeros(1,self.outs,1,1))\n","    self.ada2=AdaIN(outs=outs)\n","    self.lkrelu=nn.LeakyReLU(0.2,inplace=True)\n","    self.upscale_conv=WScaledConv(ins=self.ins,outs=self.ins,k_size=1,padding=0)\n","  def upscale(self, x):\n","    return self.upscale_conv(F.interpolate(x,scale_factor=2))\n","\n","  def forward(self, x, w):\n","    if self.initial:\n","      x=self.const\n","      #constant\n","      #or one dense layer for random inputs\n","    else:\n","      x=self.upscale(x)#upscale\n","      x=self.conv1(x)#conv1(WScaled)\n","      x=self.lkrelu(x)\n","    size=x.size()\n","    noise1=torch.randn((size[0], 1, size[2], size[3]),device=\"cuda\")*self.noise_scaler1\n","    x=x+self.noise_w1*noise1#add noise\n","    x=self.ada1(x,w)#AdaIn\n","\n","    x=self.conv2(x)\n","    x=self.lkrelu(x)\n","    noise2=torch.randn((size[0], 1, size[2], size[3]),device=\"cuda\")*self.noise_scaler2\n","    x=x+self.noise_w2*noise2#add noise\n","    x=self.ada2(x,w)#AdaIn\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gLcMeFlRpZck"},"source":["class Gnet(nn.Module):\n","  \"\"\"\n","  Generator,\n","  input: noise, b *num_features, 32*512\n","  output: image, b *num_channels *H *W, 32*1*256*256\n","  #-blocks = 7 [0 1 2 3 4 5 6]\n","  #-features= [ 512), 512, 256, 128, 64, 32, 16, 8 ]\n","  img_size = [ 4const), 4, 8, 16, 32, 64, 128, 256 ]\n","  \"\"\"\n","  def __init__(self, b_size=32, nc=1):\n","    super().__init__()\n","    #total #-batches is 354\n","    n_features=[512, 256, 128, 64, 32, 16, 8]\n","    self.n_layers=len(n_features)\n","    self.steps=0\n","    self.b_size=b_size\n","\n","    self.alpha=1.0\n","    self.cur_sacle=0\n","\n","    self.z2w=MappingNet()\n","    self.Gblocks=nn.ModuleList()\n","    self.Gblocks.append(Gblock(initial=True))\n","    for i in range(self.n_layers-1):\n","      self.Gblocks.append(Gblock(ins=n_features[i],outs=n_features[i+1]))\n","    \n","    self.toImg=nn.ModuleList()\n","    for i in range(self.n_layers):\n","      self.toImg.append(WScaledConv(ins=n_features[i],outs=nc,k_size=1,stride=1,padding=0))\n","    self.upscale_conv=nn.ModuleList()\n","    for i in range(self.n_layers-1):\n","      self.upscale_conv.append(WScaledConv(ins=1,outs=nc,k_size=1,stride=1,padding=0))###\n","  def fadeIn(self, x_cur=None, x_pre=None):\n","    last=self.toImg[self.steps](x_cur)\n","    if self.alpha>0:\n","      Sndlast=self.toImg[self.steps-1](x_pre)\n","      Sndlast=F.interpolate(Sndlast,scale_factor=2)\n","      Sndlast=self.upscale_conv[self.steps-1](Sndlast)###\n","      return self.alpha*Sndlast+(1-self.alpha)*last\n","    else:\n","      return last\n","  def forward(self, noise, alpha, steps):\n","    self.steps=steps\n","    self.alpha=alpha\n","    w=self.z2w(noise)\n","    if self.steps==0:\n","      return self.toImg[0](self.Gblocks[0](x=None,w=w))\n","    else:\n","      for i in range(0,self.steps+1):\n","        if i==0:\n","          x=self.Gblocks[0](x=None,w=w)\n","        else:\n","          x=self.Gblocks[i](x,w)\n","\n","        if i==self.steps-1:\n","          x_=x \n","      return self.fadeIn(x_cur=x, x_pre=x_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jq8QLS3sY7ln"},"source":["class Dblock(nn.Module):\n","  \"\"\"\n","  input: b*n_features*H*W\n","  output: b*(n_features/2)*H*W, for the initial(last) layer is b*1(classification result)\n","  minibatch_std not implemented yet\n","  \"\"\"\n","  def __init__(self, initial=False, ins=512, outs=512, b_size=32):\n","    super().__init__()\n","    self.initial=initial\n","    self.ins=ins if not initial else ins+1\n","    self.outs=outs\n","    self.b_size=b_size\n","    self.conv1=WScaledConv(self.ins,self.outs,k_size=3)\n","    if self.initial:\n","      self.conv2=WScaledConv(self.outs,self.outs,k_size=4,padding=0)\n","      self.conv3=WScaledConv(self.outs,1,k_size=1,padding=0)\n","    else:\n","      self.conv2=WScaledConv(self.outs,self.outs,k_size=3,padding=1)\n","      self.downscale=nn.AvgPool2d(kernel_size=2,stride=2)\n","    self.lkrelu=nn.LeakyReLU(0.2,inplace=True)\n","  def minibatch_std(self, x):\n","    size=x.size()\n","    batch_std=torch.std(x,dim=0)\n","    mean_std=batch_std.mean()\n","    return torch.cat([x,mean_std.repeat(size[0],1,size[2],size[3])],dim=1)\n","  def forward(self, x):\n","    if self.initial:\n","      x=self.minibatch_std(x)\n","      \n","    x=self.lkrelu(self.conv1(x))\n","    x=self.lkrelu(self.conv2(x))\n","    if self.initial:\n","      x=self.conv3(x).view(self.b_size,-1)\n","    else:\n","      x=self.downscale(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgnM1Ko0Tfex"},"source":["class Dnet(nn.Module): #output shape tested\n","  \"\"\"\n","  Discriminator,\n","  input: image b*1*H*W\n","  output: classification result b*1\n","  \"\"\"\n","  def __init__(self, b_size=32, nc=1):\n","    super().__init__()\n","    #total #-batches is 354\n","    n_features=[8, 16, 32, 64, 128, 256, 512]\n","    self.n_layers=len(n_features)\n","    self.steps=0\n","    self.b_size=b_size\n","\n","    self.alpha=1.0\n","    self.alpha_decay=2.26e-4\n","    self.cur_sacle=0\n","    \n","    self.Dblocks=nn.ModuleList()\n","    for i in range(self.n_layers-1):\n","      self.Dblocks.append(Dblock(ins=n_features[i],outs=n_features[i+1]))\n","    self.Dblocks.append(Dblock(initial=True))\n","\n","    self.fromImg=nn.ModuleList()\n","    for i in range(self.n_layers):\n","      self.fromImg.append(WScaledConv(ins=nc,outs=n_features[i],k_size=1,stride=1,padding=0))\n","    \n","  def fadeIn(self, x):\n","    t=self.n_layers-self.steps-1\n","    last=self.Dblocks[t](self.fromImg[t](x))\n","    if self.alpha>0:\n","      Sndlast=self.fromImg[t+1](nn.AvgPool2d(kernel_size=2,stride=2)(x))\n","      return self.alpha*Sndlast+(1-self.alpha)*last\n","    else:\n","      return last\n","\n","  def forward(self, x, alpha, steps):\n","    self.steps=steps\n","    self.alpha=alpha\n","    if self.steps==0:\n","      return self.Dblocks[-1](self.fromImg[-1](x))\n","    else:\n","      t=self.n_layers-self.steps-1\n","      x=self.fadeIn(x)\n","      for i in range(t+1,self.n_layers):\n","        x=self.Dblocks[i](x)\n","      return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r7b5bLRbRKpj"},"source":["class Trainer():\n","  \"\"\"\n","  styleGAN trainer,\n","  give dataroot(dir of image data) and sample_path(dir for saving results),\n","  then start training with training_loop(),\n","  prog_epochs define the epochs for each steps, from 0 to 6\n","  save_only set the number of output images to a fixed number\n","  \"\"\"\n","  def __init__(self, b_size=32, z_dim=512, nc=1, dataroot=f'sample_data/data',sample_path='drive/MyDrive/training_results_style/', device='cuda', prog_epochs=[10,10,10,15,15,20,20],save_only=9):\n","    self.b_size=b_size\n","    self.z_dim=z_dim\n","    self.nc=nc\n","    self.dataroot=dataroot\n","    self.sample_path=sample_path\n","    self.model_path=sample_path#\n","    self.device=device\n","    self.prog_epochs=prog_epochs\n","    \n","    self.gif=[]\n","    self.save_only=save_only\n","    self.cur_epoch=0\n","    self.img_size=4\n","    self.dataset_length=None\n","    self.dataloader=None\n","    self.step=0\n","    self.alpha=0.999\n","    self.fixed_noise1,self.fixed_noise2=torch.randn((self.b_size, self.z_dim)).to(device),torch.randn((self.b_size, self.z_dim)).to(device)    \n","    self.lr=0.001\n","    self.G,self.D=Gnet().to(self.device),Dnet().to(self.device)\n","    self.scaler_G,self.scaler_D=torch.cuda.amp.GradScaler(),torch.cuda.amp.GradScaler()\n","    self.opt_G = optim.Adam([{\"params\": [param for name, param in self.G.named_parameters() if \"map\" in name],\"lr\":self.lr*0.01},\n","                {\"params\": [param for name, param in self.G.named_parameters() if \"map\" not in name],\"lr\":self.lr}], betas=(0.0, 0.99))\n","    self.opt_D = optim.Adam(self.D.parameters(), lr=self.lr, betas=(0.0, 0.99))\n","\n","  def get_loader(self):\n","    transform = transforms.Compose([transforms.Resize((self.img_size, self.img_size)), transforms.ToTensor(),\n","                    transforms.Grayscale(1), transforms.Normalize(0.5,0.5)])\n","    dataset = datasets.ImageFolder(root=self.dataroot, transform=transform)\n","    self.dataloader = DataLoader(dataset, batch_size=self.b_size,\n","            shuffle=True, num_workers=0, pin_memory=True)\n","    self.dataset_length=len(dataset)\n","  def train_D(self,real):\n","    noise = torch.randn(self.b_size, self.z_dim).to(self.device)\n","    self.opt_D.zero_grad()\n","    with torch.cuda.amp.autocast():\n","      fake = self.G(noise, self.alpha, self.step)###fake1 and fake2\n","      D_real = self.D(real, self.alpha, self.step)\n","      D_fake = self.D(fake.detach(), self.alpha, self.step)\n","      loss_D1=F.softplus(D_fake)\n","      loss_D2=F.softplus(-D_real)\n","      loss_Dall=torch.mean(loss_D1+loss_D2)\n","      \n","    self.scaler_D.scale(loss_Dall).backward()\n","    self.scaler_D.step(self.opt_D)\n","    self.scaler_D.update()\n","  def train_G(self):\n","    noise = torch.randn(self.b_size, self.z_dim).to(self.device)\n","    self.opt_G.zero_grad()       \n","    with torch.cuda.amp.autocast():\n","      fake = self.G(noise, self.alpha, self.step)\n","      D_fake = self.D(fake, self.alpha, self.step)       \n","      loss_G=torch.mean(F.softplus(-D_fake))\n","    self.scaler_G.scale(loss_G).backward()\n","    self.scaler_G.step(self.opt_G)\n","    self.scaler_G.update()\n","  \n","  def train_one_epoch(self):\n","    iterations=tqdm(self.dataloader)\n","    samples_save=[]\n","    for i,[real,_] in enumerate(iterations):\n","      real = real.to(self.device)\n","      #Train D\n","      self.train_D(real)\n","      #Train G  \n","      self.train_G()      \n","      #Update alpha and ensure greater than 0\n","      self.alpha-=self.b_size/((self.prog_epochs[self.step]*0.5)*self.dataset_length)\n","      self.alpha=max(self.alpha,0)\n","      \n","  def save_samples_pkl(self):\n","    with torch.no_grad():\n","      fixed_fakes=(self.G(self.fixed_noise1, self.alpha, self.step)/2)+0.5\n","      fixed_fakes=torch.clamp(fixed_fakes,min=0.0,max=1.0)\n","      samples_save=[fixed_fakes]\n","      with open(self.sample_path+'train_samples_'+str(self.step)+'_'+str(self.cur_epoch)+'.pkl', 'wb') as f:\n","        pkl.dump(samples_save, f)\n","      print('Min',torch.min(fixed_fakes[0]).item(),'Mean',torch.mean(fixed_fakes[0]).item(),'Max',torch.max(fixed_fakes[0]).item())\n","  def save_samples(self):\n","    grid_cells=[]\n","    with torch.no_grad():\n","      fixed_fakes=(self.G(self.fixed_noise1, self.alpha, self.step)/2)+0.5\n","      fixed_fakes=torch.clamp(fixed_fakes,min=0.0,max=1.0)\n","      if fixed_fakes.shape[2]<256:\n","        fixed_fakes=F.interpolate(fixed_fakes,scale_factor=int(256/fixed_fakes.shape[2]))\n","      for i,img in enumerate(fixed_fakes):\n","        if i+1>self.save_only:\n","          break\n","        grid_cells.append(img)\n","        img=np.transpose(img.cpu().numpy(),(1, 2, 0))\n","        img=(img*255).astype(np.uint8)\n","        plt.imsave(self.sample_path+'train_samples_'+str(self.img_size)+'_'+str(self.cur_epoch)+'_'+str(i)+'.png',img.reshape(256,256),cmap='Greys_r')\n","      grid=make_grid(grid_cells,nrow=3,pad_value=10).cpu().numpy()\n","      grid=(grid*255).astype(np.uint8)\n","      grid=np.transpose(grid, (1, 2, 0))\n","      frame=Image.fromarray(grid).resize([500,500]).convert('L')\n","      self.gif.append(frame)\n","\n","  def make_gif(self):\n","    self.gif[0].save(self.sample_path+'brain.gif', save_all=True, append_images=self.gif[1:], loop=0, disposal=2,duration=800)\n","  def save_model(self):\n","    save_G={\"state_dict\":self.G.state_dict(),\"optimizer\":self.opt_G.state_dict()}\n","    torch.save(save_G,self.model_path+'G.pth')\n","    save_D={\"state_dict\":self.D.state_dict(),\"optimizer\":self.opt_D.state_dict()}\n","    torch.save(save_D,self.model_path+'D.pth')\n","    \n","  def update_para(self):\n","    self.step+=1\n","    self.img_size=2**(self.step+2)\n","    self.alpha=0.999\n","\n","  def training_loop(self):\n","    self.G.train()\n","    self.D.train()\n","    for n_epochs in self.prog_epochs[self.step:]:\n","      print(\"Current img size:\", self.img_size)\n","      self.get_loader()\n","      for epoch in range(n_epochs):\n","        self.cur_epoch=epoch+1\n","        print(\"Epoch: [\",epoch+1,\"/\",n_epochs,\"]\")\n","        self.train_one_epoch()\n","        self.save_samples()\n","      self.update_para()\n","    self.make_gif()\n","    self.save_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LkvlOpP2ALfa","executionInfo":{"status":"ok","timestamp":1635329735703,"user_tz":-600,"elapsed":4583156,"user":{"displayName":"Joe Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16493752761663840459"}},"outputId":"c983604f-34b1-4143-91b5-79f4b343364d"},"source":["t=Trainer()\n","t.training_loop()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current img size: 4\n","Epoch: [ 1 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:23<00:00, 14.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 2 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:23<00:00, 14.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 3 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:23<00:00, 14.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 4 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:23<00:00, 14.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 5 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:23<00:00, 14.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 6 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:23<00:00, 15.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 7 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:23<00:00, 15.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 8 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:23<00:00, 14.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 9 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:23<00:00, 15.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 10 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:23<00:00, 14.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Current img size: 8\n","Epoch: [ 1 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:28<00:00, 12.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 2 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:28<00:00, 12.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 3 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:28<00:00, 12.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 4 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:28<00:00, 12.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 5 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:28<00:00, 12.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 6 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:27<00:00, 12.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 7 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:27<00:00, 12.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 8 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:27<00:00, 12.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 9 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:28<00:00, 12.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 10 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:28<00:00, 12.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Current img size: 16\n","Epoch: [ 1 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:34<00:00, 10.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 2 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:34<00:00, 10.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 3 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:34<00:00, 10.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 4 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:34<00:00, 10.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 5 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:34<00:00, 10.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 6 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:33<00:00, 10.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 7 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:33<00:00, 10.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 8 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:33<00:00, 10.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 9 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:32<00:00, 10.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 10 / 10 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:32<00:00, 10.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Current img size: 32\n","Epoch: [ 1 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:38<00:00,  9.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 2 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:38<00:00,  9.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 3 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:38<00:00,  9.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 4 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:38<00:00,  9.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 5 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:38<00:00,  9.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 6 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:38<00:00,  9.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 7 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:38<00:00,  9.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 8 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:37<00:00,  9.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 9 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:37<00:00,  9.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 10 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:37<00:00,  9.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 11 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:37<00:00,  9.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 12 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:37<00:00,  9.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 13 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:37<00:00,  9.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 14 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:37<00:00,  9.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 15 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:36<00:00,  9.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Current img size: 64\n","Epoch: [ 1 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:44<00:00,  8.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 2 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:44<00:00,  8.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 3 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:44<00:00,  8.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 4 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:43<00:00,  8.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 5 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:44<00:00,  8.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 6 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:44<00:00,  8.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 7 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:43<00:00,  8.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 8 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:43<00:00,  8.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 9 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:43<00:00,  8.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 10 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:43<00:00,  8.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 11 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:43<00:00,  8.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 12 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:43<00:00,  8.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 13 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:43<00:00,  8.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 14 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:43<00:00,  8.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 15 / 15 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:43<00:00,  8.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Current img size: 128\n","Epoch: [ 1 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:53<00:00,  6.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 2 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:53<00:00,  6.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 3 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:54<00:00,  6.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 4 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:53<00:00,  6.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 5 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:53<00:00,  6.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 6 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:53<00:00,  6.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 7 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:54<00:00,  6.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 8 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:54<00:00,  6.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 9 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:54<00:00,  6.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 10 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:54<00:00,  6.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 11 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:52<00:00,  6.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 12 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:52<00:00,  6.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 13 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:52<00:00,  6.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 14 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:53<00:00,  6.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 15 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:52<00:00,  6.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 16 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:52<00:00,  6.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 17 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:52<00:00,  6.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 18 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:52<00:00,  6.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 19 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:52<00:00,  6.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 20 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [00:52<00:00,  6.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Current img size: 256\n","Epoch: [ 1 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:11<00:00,  4.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 2 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:11<00:00,  4.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 3 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:11<00:00,  4.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 4 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:11<00:00,  4.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 5 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:12<00:00,  4.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 6 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:11<00:00,  4.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 7 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:11<00:00,  4.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 8 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:12<00:00,  4.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 9 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:12<00:00,  4.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 10 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:12<00:00,  4.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 11 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:09<00:00,  5.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 12 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:09<00:00,  5.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 13 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:10<00:00,  5.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 14 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:09<00:00,  5.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 15 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:09<00:00,  5.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 16 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:09<00:00,  5.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 17 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:09<00:00,  5.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 18 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:09<00:00,  5.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 19 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:09<00:00,  5.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 20 / 20 ]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 354/354 [01:09<00:00,  5.09it/s]\n"]}]}]}