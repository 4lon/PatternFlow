{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Methods.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjZ_XxgC57LQ"
      },
      "source": [
        "import tensorflow as tf \n",
        "import pathlib\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "from matplotlib import image\n",
        "import glob"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPJNfJkC2R08"
      },
      "source": [
        "def download_oasis ():\n",
        "    \n",
        "    #download oasis brain MRI data\n",
        "    dataset_url = \"https://cloudstor.aarnet.edu.au/plus/s/n5aZ4XX1WBKp6HZ/download\"\n",
        "    data_dir = tf.keras.utils.get_file(origin=dataset_url,fname='oa-sis' ,untar=True)\n",
        "    data_dir = pathlib.Path(data_dir)\n",
        "    \n",
        "    # unzip data to current directory \n",
        "    print (data_dir)\n",
        "    ! unzip /root/.keras/datasets/oa-sis.tar.gz"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsEL-j0w5Gd-"
      },
      "source": [
        "def load_training (path):\n",
        "    # load training images (non segmented) in the path and store in numpy array\n",
        "    image_list = []\n",
        "    for filename in glob.glob(path+'/*.png'): \n",
        "        im=image.imread (filename)\n",
        "        image_list.append(im)\n",
        "\n",
        "    print('train_X shape:',np.array(image_list).shape)\n",
        "    train_set = np.array(image_list, dtype=np.float32)\n",
        "    return train_set\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnIbIVop69Dn"
      },
      "source": [
        "def process_training (data_set):\n",
        "    # the method normalizes training images and adds 4th dimention \n",
        "\n",
        "    train_set = data_set\n",
        "    train_set = (train_set - np.mean(train_set))/ np.std(train_set)\n",
        "    train_set= (train_set- np.amin(train_set))/ np.amax(train_set- np.amin(train_set))\n",
        "    train_set = train_set [:,:,:,np.newaxis]\n",
        "    \n",
        "    return train_set"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQRjoY8HFUoi"
      },
      "source": [
        "def load_labels (path):\n",
        "    # loads labels images and map pixel values to class indices and convert image data type to unit8 \n",
        "\n",
        "    n_classes = 4\n",
        "    image_list =[]\n",
        "    for filename in glob.glob(path+'/*.png'): \n",
        "        im=image.imread (filename)\n",
        "        one_hot = np.zeros((im.shape[0], im.shape[1]))\n",
        "        for i, unique_value in enumerate(np.unique(im)):\n",
        "          one_hot[:, :][im == unique_value] = i\n",
        "        image_list.append(one_hot)\n",
        "\n",
        "    print('train_y shape:',np.array(image_list).shape)\n",
        "    labels = np.array(image_list, dtype=np.uint8)\n",
        "    \n",
        "    pyplot.imshow(labels[2])\n",
        "    pyplot.show()\n",
        "\n",
        "    return labels"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsmg4eHmLJY5"
      },
      "source": [
        "def process_labels(seg_data):\n",
        "    # one hot encode label data and convert to numpy array\n",
        "    onehot_seg_data = []\n",
        "    for n in range(seg_data.shape[0]): \n",
        "      im = seg_data[n]\n",
        "      n_classes = 4\n",
        "      one_hot = np.zeros((im.shape[0], im.shape[1], n_classes),dtype=np.uint8)\n",
        "      for i, unique_value in enumerate(np.unique(im)):\n",
        "          one_hot[:, :, i][im == unique_value] = 1\n",
        "    onehot_seg_data.append(one_hot)\n",
        "    \n",
        "    onehot_seg_data =np.array(onehot_seg_data)\n",
        "    print (onehot_seg_data.dtype)\n",
        "    #print (np.unique(onehot_validate_Y))\n",
        "    print (onehot_seg_data.shape)\n",
        "\n",
        "    return onehot_seg_data\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqPbya4v4I1D",
        "outputId": "81cc6524-8c75-4ba3-bcbe-6b414a261209",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# test script \n",
        "#download_oasis()\n",
        "#train_X = load_training ('/content/keras_png_slices_data/keras_png_slices_train')\n",
        "#pyplot.imshow(train_X[2])\n",
        "#pyplot.show()\n",
        "\n",
        "#train_X = process_training(train_X)\n",
        "#print (train_X.shape)\n",
        "#print(np.min (train_X))\n",
        "#print(np.max (train_X))\n",
        "#np.unique(train_X[3])\n",
        "#train_Y = load_labels('/content/keras_png_slices_data/keras_png_slices_seg_train')\n",
        "train_Y = process_labels(train_Y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "uint8\n",
            "(1, 256, 256, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}