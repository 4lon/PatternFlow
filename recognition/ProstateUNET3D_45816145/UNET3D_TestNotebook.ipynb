{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99951d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1518553f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Labelled Scans: 211\n"
     ]
    }
   ],
   "source": [
    "# Formulate train, val, test file paths for \"scans\" and \"labels\"\n",
    "# Stored as filepaths, as the generator will do the file reading\n",
    "def get_nifti_files_in(directory):\n",
    "    paths = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".nii.gz\"):\n",
    "            paths.append(os.path.join(directory, file))\n",
    "    \n",
    "    # Sort so ordering is not file system order dependent\n",
    "    return sorted(paths)\n",
    "\n",
    "base_path = \"data\"\n",
    "data_dimensions = (256, 256, 128)\n",
    "\n",
    "# Background, Body, Bone, Bladder, Rectum, Prostate\n",
    "class_count = 6\n",
    "\n",
    "scans = get_nifti_files_in(os.path.join(base_path, \"semantic_MRs_anon\"))\n",
    "labels = get_nifti_files_in(os.path.join(base_path, \"semantic_labels_anon\"))\n",
    "\n",
    "# Make sure we have an equal number of scans and labels\n",
    "assert len(scans) == len(labels)\n",
    "\n",
    "# Zips the two \"scans\" and \"labels\" arrays together to produce [[scan_filename, label_filename], ...]\n",
    "data_paths = np.dstack((scans, labels))[0]\n",
    "\n",
    "print(\"Raw Labelled Scans: \" + str(len(data_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bccd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator:\n",
    "# Maximum scan voxel value in dataset was above 512 but below 1023 so i use closest power of two -> 1023, for normalisation\n",
    "class Prostate3DGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, data_paths, batch_size, data_dimensions, class_count):\n",
    "        self.data_paths = data_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.data_dimensions = data_dimensions\n",
    "        self.class_count = class_count\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.data_paths) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        start_index = index * self.batch_size\n",
    "        batch_data_paths = self.data_paths[start_index : start_index + self.batch_size]\n",
    "        \n",
    "        scans = np.empty((self.batch_size, *self.data_dimensions))\n",
    "        labels = np.empty((self.batch_size, *self.data_dimensions, self.class_count), dtype=int)\n",
    "        \n",
    "        for dataIndex in range(len(batch_data_paths)):\n",
    "            # Populate \"scans\"\n",
    "            scan_voxels = nib.load(batch_data_paths[dataIndex][0])\n",
    "            scans[dataIndex] = tf.cast(np.array(scan_voxels.dataobj) / 1023.0, tf.float32)\n",
    "            \n",
    "            # Populate \"labels\"\n",
    "            nibabel_voxels = nib.load(batch_data_paths[dataIndex][1])\n",
    "            prepared_voxels = tf.cast(np.array(nibabel_voxels.dataobj), tf.float32)\n",
    "            labels[dataIndex] = keras.utils.to_categorical(prepared_voxels, num_classes=self.class_count)\n",
    "            \n",
    "        return scans, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ae295c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Count: 180\n",
      "Val Count: 22\n",
      "Test Count: 9\n"
     ]
    }
   ],
   "source": [
    "# Create Train, Val, Test split (move into utility function)\n",
    "train_split = 0.85\n",
    "val_split = 0.1\n",
    "test_split = 0.05\n",
    "\n",
    "assert train_split + val_split + test_split == 1.0\n",
    "\n",
    "# Randomise input pairs array to get a random distribution in train, val, test\n",
    "np.random.shuffle(data_paths)\n",
    "source_data_length = len(data_paths)\n",
    "\n",
    "# Calculate number of data pairs for each bucket (test doesn't need to be calculated)\n",
    "train_count = int(np.floor(source_data_length * train_split))\n",
    "val_count = int(np.floor(source_data_length * val_split))\n",
    "\n",
    "# Slice data paths into each bucket to be fed into different generators\n",
    "train_paths = data_paths[0:train_count + 1]\n",
    "val_paths = data_paths[train_count + 1:train_count + 1 + val_count + 1]\n",
    "test_paths = data_paths[train_count + 1 + val_count + 1:]\n",
    "\n",
    "assert len(train_paths) + len(val_paths) + len(test_paths) == source_data_length\n",
    "\n",
    "print(\"Train Count: \" + str(len(train_paths)))\n",
    "print(\"Val Count: \" + str(len(val_paths)))\n",
    "print(\"Test Count: \" + str(len(test_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9e76c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generators\n",
    "batch_size = 1\n",
    "\n",
    "train_generator = Prostate3DGenerator(train_paths, batch_size, data_dimensions, class_count)\n",
    "val_generator = Prostate3DGenerator(val_paths, batch_size, data_dimensions, class_count)\n",
    "test_generator = Prostate3DGenerator(test_paths, batch_size, data_dimensions, class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddd7687f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256, 256, 12 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 256, 256, 128 1792        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256, 256, 128 256         conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 256, 256, 128 110656      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, 128, 128, 64, 0           conv3d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128, 128, 64, 0           max_pooling3d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 128, 128, 64, 221312      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128, 128, 64, 512         conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 128, 128, 64, 442496      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3D)  (None, 64, 64, 32, 1 0           conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64, 64, 32, 1 0           max_pooling3d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, 64, 64, 32, 2 884992      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 32, 2 1024        conv3d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)              (None, 64, 64, 32, 2 1769728     batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTrans (None, 128, 128, 64, 262272      conv3d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128, 128, 64, 0           conv3d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 64, 0           dropout_6[0][0]                  \n",
      "                                                                 conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)              (None, 128, 128, 64, 884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128, 128, 64, 512         conv3d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_24 (Conv3D)              (None, 128, 128, 64, 442496      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTrans (None, 256, 256, 128 65600       conv3d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 256, 256, 128 0           conv3d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           dropout_7[0][0]                  \n",
      "                                                                 conv3d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_25 (Conv3D)              (None, 256, 256, 128 221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 256, 256, 128 256         conv3d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_26 (Conv3D)              (None, 256, 256, 128 110656      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_27 (Conv3D)              (None, 256, 256, 128 390         conv3d_26[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,421,062\n",
      "Trainable params: 5,419,782\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Construct keras model\n",
    "first_layer = layers.Input((*data_dimensions, 1))\n",
    "\n",
    "# We will pass through \"previous\" to represent last layer\n",
    "previous = first_layer\n",
    "\n",
    "filters = [64, 128, 256]\n",
    "\n",
    "# LEFT SIDE\n",
    "downscale_layers = len(filters)\n",
    "downscale_filters = filters\n",
    "downscale_tails = []\n",
    "for i in range(downscale_layers):\n",
    "    previous = layers.Conv3D(downscale_filters[i], (3, 3, 3), padding='same', activation='relu')(previous)\n",
    "    previous = layers.BatchNormalization()(previous)\n",
    "    previous = layers.Conv3D(downscale_filters[i], (3, 3, 3), padding='same', activation='relu')(previous)\n",
    "    \n",
    "    if i != downscale_layers - 1:\n",
    "        downscale_tails.append(previous)\n",
    "        previous = layers.MaxPool3D((2, 2, 2), strides=(2, 2, 2))(previous)\n",
    "        previous = layers.Dropout(0.2)(previous)\n",
    "        \n",
    "# RIGHT SIDE\n",
    "# reverse references, since upscale is looped other way\n",
    "downscale_tails = list(reversed(downscale_tails))\n",
    "\n",
    "upscale_layers = len(filters) - 1\n",
    "upscale_filters = list(reversed(filters))[1:]\n",
    "for i in range(upscale_layers):\n",
    "    # Up Convolution\n",
    "    previous = layers.Conv3DTranspose(upscale_filters[i], (2, 2, 2), strides=(2, 2, 2))(previous)\n",
    "    previous = layers.Dropout(0.2)(previous)\n",
    "    \n",
    "    # Pull across\n",
    "    tail = downscale_tails[i]\n",
    "    previous = layers.concatenate([previous, tail])\n",
    "    \n",
    "    # Convolutions\n",
    "    previous = layers.Conv3D(upscale_filters[i], (3, 3, 3), padding='same', activation='relu')(previous)\n",
    "    previous = layers.BatchNormalization()(previous)\n",
    "    previous = layers.Conv3D(upscale_filters[i], (3, 3, 3), padding='same', activation='relu')(previous)\n",
    "        \n",
    "last_layer = layers.Conv3D(class_count, (1, 1, 1), activation='softmax')(previous)\n",
    "\n",
    "model = keras.Model(first_layer, last_layer)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "482884a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[1,256,256,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/batch_normalization_7/moments/SquaredDifference-0-0-TransposeNCDHWToNDHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_6633]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10520/2006485059.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#model.load_weights(\"oasis.h5\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Users\\Jake\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\Jake\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\Jake\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\Jake\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\Jake\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mE:\\Users\\Jake\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\Jake\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[1,256,256,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/batch_normalization_7/moments/SquaredDifference-0-0-TransposeNCDHWToNDHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_6633]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"oasis.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch.\n",
    "epochs = 15\n",
    "\n",
    "#model.load_weights(\"oasis.h5\")\n",
    "train_data = model.fit(train_generator, epochs=epochs, validation_data=val_generator, callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
