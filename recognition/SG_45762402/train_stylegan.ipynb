{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f048ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from Dataset import MultiResolutionDataset\n",
    "from Model2 import StyledGenerator, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8284d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting import_ipynb\n",
      "  Downloading import-ipynb-0.1.3.tar.gz (4.0 kB)\n",
      "Building wheels for collected packages: import-ipynb\n",
      "  Building wheel for import-ipynb (setup.py): started\n",
      "  Building wheel for import-ipynb (setup.py): finished with status 'done'\n",
      "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-py3-none-any.whl size=2975 sha256=07e86dd1ace146484249e4ab1ab7e6a868b8502f01e1b455513a90a184079edc\n",
      "  Stored in directory: c:\\users\\shane\\appdata\\local\\pip\\cache\\wheels\\06\\7e\\ad\\1cb03e935234186825cefc7e2c8f3451b4f654b5bc72232a7b\n",
      "Successfully built import-ipynb\n",
      "Installing collected packages: import-ipynb\n",
      "Successfully installed import-ipynb-0.1.3\n"
     ]
    }
   ],
   "source": [
    "#!pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc5ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "n_gpu             = 1\n",
    "device            = torch.device('cuda:0')\n",
    "Path='/content/drive/MyDrive/StyleGAN_rosin/LMDB_PATH' #Option\n",
    "ckpt=None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Setting\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#learning_rate     = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n",
    "batch_size_1gpu   = {4: 128, 8: 128, 16: 64, 32: 32, 64: 16, 128: 16}\n",
    "mini_batch_size_1 = 8\n",
    "#batch_size        = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}\n",
    "mini_batch_size   = 8\n",
    "batch_size_4gpus  = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32}\n",
    "mini_batch_size_4 = 16\n",
    "batch_size_8gpus  = {4: 512, 8: 256, 16: 128, 32: 64}\n",
    "mini_batch_size_8 = 32\n",
    "n_fc              = 8          #number of fully-connected layers\n",
    "dim_latent        = 512\n",
    "dim_input         = 4\n",
    "n_sample          = 120000     #number of samples used for each training phases\n",
    "#DGR               = 1\n",
    "#n_show_loss       = 500\n",
    "step              = 1 # Train from (8 * 8)\n",
    "max_step          = 8 # Maximum step (8 for 1024^2)\n",
    "#style_mixing      = [] # Waiting to implement\n",
    "#image_folder_path = '/content/drive/MyDrive/Dataset_brain/keras_png_slices_data'\n",
    "#save_folder_path  = '/content/drive/MyDrive/Stylegan_shang/results'\n",
    "\n",
    "\n",
    "# Used to continue training from last checkpoint\n",
    "startpoint        = 0\n",
    "used_sample       = 0\n",
    "alpha             = 0\n",
    "\n",
    "\n",
    "def set_grad_flag(module, flag=True):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "def reset_LR(optimizer, lr):\n",
    "    for pam_group in optimizer.param_groups:\n",
    "        mul = pam_group.get('mul', 1)\n",
    "        pam_group['lr'] = lr * mul\n",
    "\n",
    "\n",
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "\n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)\n",
    "\n",
    "        \n",
    "# Gain sample\n",
    "def gain_sample(dataset, batch_size, image_size=4):\n",
    "    dataset.resolution = image_size\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=1, drop_last=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "def imshow(tensor, i):\n",
    "    grid = tensor[0]\n",
    "    grid.clamp_(-1, 1).add_(1).div_(2)\n",
    "    # Add 0.5 after unnormalizing to [0, 255] to round to nearest integer\n",
    "    ndarr = grid.mul_(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to('cpu', torch.uint8).numpy()\n",
    "    img = Image.fromarray(ndarr)\n",
    "    #img.save(f'{save_folder_path}sample-iter{i}.png')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe29e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_size=8 #Initial image size,default=8\n",
    "batch_default=32\n",
    "max_size=1024  #Max image size,default=1024\n",
    "ckpt=None\n",
    "loss='wgan-gp'  #options:wgan-gp,r1\n",
    "gen_sample = {512: (8, 4), 1024: (4, 2)}\n",
    "mixing=True\n",
    "no_from_rgb_activate=True\n",
    "n_critic=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f036fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, generator, discriminator,loss):\n",
    "    step = int(math.log2(init_size)) - 2\n",
    "\n",
    "    resolution = 4 * 2 ** step\n",
    "    loader = gain_sample(\n",
    "        dataset, batch_size.get(resolution, batch_default), resolution\n",
    "    )\n",
    "    data_loader = iter(loader)\n",
    "\n",
    "    reset_LR(g_optimizer, learning_rate.get(resolution, 0.001))\n",
    "    reset_LR(d_optimizer, learning_rate.get(resolution, 0.001))\n",
    "\n",
    "    #Epoch=1,000,000\n",
    "\n",
    "    #pbar = tqdm(range(1000000))\n",
    "    pbar = tqdm(range(startpoint + 1, n_sample * 5))\n",
    "\n",
    "    set_grad_flag(generator, False)\n",
    "    set_grad_flag(discriminator, True)\n",
    "\n",
    "    #Initializing\n",
    "    disc_loss_val = 0\n",
    "    gen_loss_val = 0\n",
    "    grad_loss_val = 0\n",
    "\n",
    "    alpha = 0\n",
    "    used_sample = 0\n",
    "\n",
    "    max_step = int(math.log2(max_size)) - 2\n",
    "    final_progress = False\n",
    "\n",
    "    for i in pbar:\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        #alpha = min(1, 1 / n_sample * (used_sample + 1))\n",
    "        alpha = min(1, alpha + batch_size.get(resolution, mini_batch_size) / (n_sample * 2))\n",
    "\n",
    "        if (resolution == init_size and ckpt is None) or final_progress:\n",
    "            alpha = 1\n",
    "\n",
    "        if used_sample > n_sample * 2:\n",
    "            used_sample = 0\n",
    "            step += 1\n",
    "\n",
    "            if step > max_step:\n",
    "                step = max_step\n",
    "                final_progress = True\n",
    "                ckpt_step = step + 1\n",
    "\n",
    "            else:\n",
    "                alpha = 0\n",
    "                ckpt_step = step\n",
    "\n",
    "            resolution = 4 * 2 ** step\n",
    "\n",
    "            loader = gain_sample(\n",
    "                dataset, batch_size.get(resolution, batch_default), resolution\n",
    "            )\n",
    "            data_loader = iter(loader)\n",
    "            \n",
    "           #Save the model\n",
    "            torch.save(\n",
    "                {\n",
    "                    'generator': generator.module.state_dict(),\n",
    "                    'discriminator': discriminator.module.state_dict(),\n",
    "                    'g_optimizer': g_optimizer.state_dict(),\n",
    "                    'd_optimizer': d_optimizer.state_dict(),\n",
    "                    'g_running': g_running.state_dict(),\n",
    "                },\n",
    "                f'checkpoint/train_step-{ckpt_step}.model',\n",
    "            )\n",
    "\n",
    "            reset_LR(g_optimizer, learning_rate.get(resolution, 0.001))\n",
    "            reset_LR(d_optimizer, learning_rate.get(resolution, 0.001))\n",
    "\n",
    "        try:\n",
    "            real_image = next(data_loader)\n",
    "\n",
    "        except (OSError, StopIteration):\n",
    "            data_loader = iter(loader)\n",
    "            real_image = next(data_loader)\n",
    "        #Count used_sample\n",
    "        used_sample += real_image.shape[0]\n",
    "\n",
    "        b_size = real_image.size(0)\n",
    "        real_image = real_image.cuda()\n",
    "\n",
    "        #Loss function of discriminator\n",
    "        # Real image predict & backward\n",
    "        if loss == 'wgan-gp':\n",
    "            real_predict = discriminator(real_image, step=step, alpha=alpha)\n",
    "            real_predict = real_predict.mean() - 0.001 * (real_predict ** 2).mean()\n",
    "            (-real_predict).backward()\n",
    "\n",
    "        elif loss == 'r1':\n",
    "            real_image.requires_grad= True\n",
    "            real_scores = discriminator(real_image, step=step, alpha=alpha)\n",
    "            real_predict = F.softplus(-real_scores).mean()\n",
    "            real_predict.backward(retain_graph=True)\n",
    "\n",
    "            grad_real = grad(\n",
    "                outputs=real_scores.sum(), inputs=real_image, create_graph=True\n",
    "            )[0]\n",
    "            grad_penalty = (\n",
    "                grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
    "            ).mean()\n",
    "            grad_penalty = 10 / 2 * grad_penalty\n",
    "            grad_penalty.backward()\n",
    "            if i%10 == 0:\n",
    "                grad_loss_val = grad_penalty.item()\n",
    "                \n",
    "        #Generate latent code\n",
    "        if mixing==True and random.random() < 0.9:\n",
    "            gen_in11, gen_in12, gen_in21, gen_in22 = torch.randn(\n",
    "                4, b_size, dim_latent, device='cuda'\n",
    "            ).chunk(4, 0)\n",
    "            gen_in1 = [gen_in11.squeeze(0), gen_in12.squeeze(0)]\n",
    "            gen_in2 = [gen_in21.squeeze(0), gen_in22.squeeze(0)]\n",
    "\n",
    "        else:\n",
    "            gen_in1, gen_in2 = torch.randn(2, b_size, dim_latent, device='cuda').chunk(\n",
    "                2, 0\n",
    "            )\n",
    "            gen_in1 = gen_in1.squeeze(0)\n",
    "            gen_in2 = gen_in2.squeeze(0)\n",
    "\n",
    "        fake_image = generator(gen_in1, step=step, alpha=alpha)\n",
    "        fake_predict = discriminator(fake_image, step=step, alpha=alpha)\n",
    "\n",
    "        if loss == 'wgan-gp':\n",
    "            fake_predict = fake_predict.mean()\n",
    "            fake_predict.backward()\n",
    "\n",
    "            eps = torch.rand(b_size, 1, 1, 1).cuda()\n",
    "            x_hat = eps * real_image.data + (1 - eps) * fake_image.data\n",
    "            x_hat.requires_grad= True\n",
    "            hat_predict = discriminator(x_hat, step=step, alpha=alpha)\n",
    "            grad_x_hat = grad(\n",
    "                outputs=hat_predict.sum(), inputs=x_hat, create_graph=True\n",
    "            )[0]\n",
    "            grad_penalty = (\n",
    "                (grad_x_hat.view(grad_x_hat.size(0), -1).norm(2, dim=1) - 1) ** 2\n",
    "            ).mean()\n",
    "            grad_penalty = 10 * grad_penalty\n",
    "            grad_penalty.backward()\n",
    "            if i%10 == 0:\n",
    "                grad_loss_val = grad_penalty.item()\n",
    "                disc_loss_val = (-real_predict + fake_predict).item()\n",
    "\n",
    "        elif loss == 'r1':\n",
    "            fake_predict = F.softplus(fake_predict).mean()\n",
    "            fake_predict.backward()\n",
    "            if i%10 == 0:\n",
    "                disc_loss_val = (real_predict + fake_predict).item()\n",
    "\n",
    "        d_optimizer.step()\n",
    "\n",
    "        #Loss function of generator\n",
    "        if (i + 1) % n_critic == 0:\n",
    "            generator.zero_grad()\n",
    "\n",
    "            set_grad_flag(generator, True)\n",
    "            set_grad_flag(discriminator, False)\n",
    "\n",
    "            fake_image = generator(gen_in2, step=step, alpha=alpha)\n",
    "\n",
    "            predict = discriminator(fake_image, step=step, alpha=alpha)\n",
    "\n",
    "            if loss == 'wgan-gp':\n",
    "                loss = -predict.mean()\n",
    "\n",
    "            elif loss == 'r1':\n",
    "                loss = F.softplus(-predict).mean()\n",
    "\n",
    "            if i%10 == 0:\n",
    "                gen_loss_val = loss.item()\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            g_optimizer.step()\n",
    "            accumulate(g_running, generator.module)\n",
    "\n",
    "            set_grad_flag(generator, False)\n",
    "            set_grad_flag(discriminator, True)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            images = []\n",
    "\n",
    "            gen_i, gen_j = gen_sample.get(resolution, (10, 5))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for _ in range(gen_i):\n",
    "                    images.append(\n",
    "                        g_running(\n",
    "                            torch.randn(gen_j, dim_latent).cuda(), step=step, alpha=alpha\n",
    "                        ).data.cpu()\n",
    "                    )\n",
    "\n",
    "            utils.save_image(\n",
    "                torch.cat(images, 0),\n",
    "                f'sample/{str(i + 1).zfill(6)}.png',\n",
    "                nrow=gen_i,\n",
    "                normalize=True,\n",
    "                range=(-1, 1),\n",
    "            )\n",
    "\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            torch.save(\n",
    "                g_running.state_dict(), f'checkpoint/{str(i + 1).zfill(6)}.model'\n",
    "            )\n",
    "\n",
    "        state_msg = (\n",
    "            f'Size: {4 * 2 ** step}; G: {gen_loss_val:.3f}; D: {disc_loss_val:.3f};'\n",
    "            f' Grad: {grad_loss_val:.3f}; Alpha: {alpha:.5f}'\n",
    "        )\n",
    "\n",
    "        pbar.set_description(state_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db05fb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:106: UserWarning: \n",
      "GeForce RTX 3060 Laptop GPU with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the GeForce RTX 3060 Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
      "<ipython-input-3-a552d2c22c75>:60: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1025.)\n",
      "  par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "/content/drive/MyDrive/StyleGAN_rosin/LMDB_PATH: ???????????\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-62e4f585e075>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m     )\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m   \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiResolutionDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Recognition\\PatternFlow\\recognition\\SG_45762402\\Dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, transform, resolution)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mMultiResolutionDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         self.env = lmdb.open(\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mmax_readers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: /content/drive/MyDrive/StyleGAN_rosin/LMDB_PATH: ???????????\r\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "  generator = nn.DataParallel(StyledGenerator(dim_latent)).cuda()\n",
    "  discriminator = nn.DataParallel(\n",
    "        Discriminator(from_rgb_activate=not no_from_rgb_activate)\n",
    "    ).cuda()\n",
    "\n",
    "  g_running = StyledGenerator(dim_latent).cuda()\n",
    "  g_running.train(False)\n",
    "\n",
    "  g_optimizer = optim.Adam(\n",
    "        generator.module.generator.parameters(), lr=0.001, betas=(0.0, 0.99)\n",
    "    )\n",
    "  \n",
    "  g_optimizer.add_param_group(\n",
    "        {\n",
    "            'params': generator.module.style.parameters(),\n",
    "            'lr': 0.001 * 0.01,\n",
    "            'mult': 0.01,\n",
    "        }\n",
    "    )\n",
    "  \n",
    "  d_optimizer = optim.Adam(discriminator.parameters(), lr=0.001, betas=(0.0, 0.99))\n",
    "  accumulate(g_running, generator.module, 0)\n",
    "\n",
    "\n",
    "#Load pre-trained models\n",
    "  if ckpt is not None:\n",
    "        ckpt = torch.load(ckpt)\n",
    "\n",
    "        generator.module.load_state_dict(ckpt['generator'])\n",
    "        discriminator.module.load_state_dict(ckpt['discriminator'])\n",
    "        g_running.load_state_dict(ckpt['g_running'])\n",
    "        g_optimizer.load_state_dict(ckpt['g_optimizer'])\n",
    "        d_optimizer.load_state_dict(ckpt['d_optimizer'])\n",
    "\n",
    "  transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  dataset = MultiResolutionDataset(Path, transform)\n",
    "\n",
    "\n",
    "  learning_rate = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n",
    "  batch_size        = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}\n",
    "\n",
    "\n",
    "  gen_sample = {512: (8, 4), 1024: (4, 2)}\n",
    "\n",
    "  batch_default = 32\n",
    "\n",
    "  loss='wgan-gp'\n",
    "\n",
    "  train(dataset, generator, discriminator,loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079c101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
