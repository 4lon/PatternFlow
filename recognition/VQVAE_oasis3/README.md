# VQVAE Implementation for OASIS Dataset

### VQVAE Algorithm
This project sought to implement a VQVAE-based image generator for the OASIS3 dataset. To achieve this, the algorithm used by Razavi et al in *'Generating Diverse High-Fidelity Images with VQ-VAE-2'* was adapted into a Tensorflow Keras implementation that worked on the monochrome image data. The final form of this algorithm as implemented here is shown below.

![vqvae_diagram](vqvae_diagram.png)

The filter values given in the figure above resulted in a Structured Similarity (SSIM) score of 0.817. This was achieved by training the algorithm for 400 epochs, and the step-wise results of this training are shown in the graph below. As can be seen, the SSIM and reconstruction loss stalled for the first 50 epochs, however, this hurdle was overcome and the rest of the training progressed smoothly after this.

![vqvae_loss](vqvae_losses.png)

The results of this algorithm can speak for themselves, as they recreate the image very faithfully. Below is a sample of reconstructed test images from the VQVAE, followed by a graphical representation of its encodings. While the reconstructions are a little blurry, they are considered *reasonably clear* for the purposes of this design.

![vqvae_recon](vqvae_reconstructions.png)

![vqvae_encoded](vqvae_encodings.png)

These encodings are generated from a set of internal codebook indices within each VectorQuantizer layer, and are therefore what is sought to be generated to create a facsimile image of a brain. These encodings take the shape of (32, 32, 256) and (64, 64, 128), and are generated by the PixelCNN in the following section.


### PixelCNN Generator
The PixelCNN is used to generate a set of encodings that can be decoded by the VQVAE to generate a new brain image. The data used by the PixelCNN comes from the codebook indices of a VectorQuantizer, which can then in turn be decoded by the VQVAE to create the final image. As such, two separate instances are required to generate encodings for the top and bottom level encodings within the algorithm. This is mostly boilerplate code from *https://keras.io/examples/generative/pixelcnn/*, so please refer there for greater detail on this functionality.
