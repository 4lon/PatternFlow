{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "sess = tf.compat.v1.Session(\n",
    "    config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(\n",
    "    devices=[\"/gpu:0\", \"/gpu:1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data Pre-processing\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "def get_filenames(isic_dir):\n",
    "    feature_dir = os.path.join(\n",
    "        isic_dir, 'ISIC2018_Task1-2_Training_Input', '*.jpg')\n",
    "\n",
    "    # the dataset actually shuffles here due to arbitrary reading order\n",
    "    features = glob.glob(feature_dir)\n",
    "    # make sure the features and labels have the same order\n",
    "    labels = [f.replace('ISIC2018_Task1-2_Training_Input',\n",
    "                        'ISIC2018_Task1_Training_GroundTruth').replace('.jpg', '_segmentation.png') for f in features]\n",
    "\n",
    "    print(\"Number of images loaded:\", len(features), len(labels))\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def split_data(features, labels, validation_split=0.2, test_split=0.2):\n",
    "    # calculate the split size\n",
    "    training_split = 1 - (validation_split + test_split)\n",
    "    num_train = int(training_split * len(features))\n",
    "    num_val = int(validation_split * len(features))\n",
    "    num_test = len(features) - num_train - num_val\n",
    "\n",
    "    print(\"Number of training images:\", num_train)\n",
    "    print(\"Number of validation images:\", num_val)\n",
    "    print(\"Number of test images:\", num_test)\n",
    "\n",
    "    # split the features and labels into training set, validation set and test set\n",
    "    train_features, val_features, test_features = tf.split(\n",
    "        features, [num_train, num_val, num_test])\n",
    "    train_labels, val_labels, test_labels = tf.split(\n",
    "        labels, [num_train, num_val, num_test])\n",
    "\n",
    "    return train_features, train_labels, val_features, val_labels, test_features, test_labels\n",
    "\n",
    "\n",
    "def __load_features(image_file, image_size):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "\n",
    "    # normalise the image\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def __load_labels(label_file, image_size, num_classes):\n",
    "    label = tf.io.read_file(label_file)\n",
    "    label = tf.image.decode_png(label, channels=1)\n",
    "    label = tf.image.resize(label, image_size)\n",
    "\n",
    "    # convert the label to one-hot encoding\n",
    "    label = label / 255.0\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    label = tf.squeeze(label, axis=2)\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return label\n",
    "\n",
    "\n",
    "def __create_dataset(features, labels, image_size, num_classes):\n",
    "    # create and shuffle dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    dataset = dataset.shuffle(len(features))\n",
    "\n",
    "    # load features and labels\n",
    "    dataset = dataset.map(\n",
    "        lambda feature, label: (__load_features(feature, image_size),\n",
    "                                __load_labels(label, image_size, num_classes)))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def create_datasets(train_featrues, train_labels, val_features, val_labels,\n",
    "                    test_features, test_labels, image_size, num_classes):\n",
    "    \"\"\"Create the training, validation and test datasets.\n",
    "\n",
    "    Args:\n",
    "        train_featrues ([type]): list of training features\n",
    "        train_labels ([type]): list of training labels\n",
    "        val_features ([type]): list of validation features\n",
    "        val_labels ([type]): list of validation labels\n",
    "        test_features ([type]): list of test features\n",
    "        test_labels ([type]): list of test labels\n",
    "        image_size ([type]): image size\n",
    "        num_classes ([type]): number of classes\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    train_set = __create_dataset(train_featrues, train_labels,\n",
    "                                 image_size, num_classes)\n",
    "    val_set = __create_dataset(val_features, val_labels,\n",
    "                               image_size, num_classes)\n",
    "    test_set = __create_dataset(test_features, test_labels,\n",
    "                                image_size, num_classes)\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Metrics for training the UNet model\n",
    "\"\"\"\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import models, optimizers\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred) -> float:\n",
    "    # flatten array for faster computation\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "\n",
    "    intersect = K.sum(K.abs(y_true * y_pred))\n",
    "    total = K.sum(K.square(y_true)) + K.sum(K.square(y_pred))\n",
    "    return (2. * intersect + 1.) / (total + 1.)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred) -> float:\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Improved UNet implementation (2D version)\n",
    "\n",
    "Reference: https://arxiv.org/abs/1802.10508v1\n",
    "\"\"\"\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "def __encoder_module(input, num_filters, strides=(1, 1)):\n",
    "    conv = layers.Conv2D(num_filters, (3, 3), strides,\n",
    "                         padding=\"same\", activation=layers.LeakyReLU(0.01))(input)\n",
    "\n",
    "    # context module (pre-activation residual blocks)\n",
    "    ctx1 = tfa.layers.InstanceNormalization()(conv)\n",
    "    ctx1 = layers.Activation(layers.LeakyReLU(0.01))(ctx1)\n",
    "    ctx1 = layers.Conv2D(num_filters, (3, 3), padding=\"same\")(ctx1)\n",
    "    ctx_drop = layers.Dropout(0.3)(ctx1)\n",
    "    ctx2 = tfa.layers.InstanceNormalization()(ctx_drop)\n",
    "    ctx2 = layers.Activation(layers.LeakyReLU(0.01))(ctx2)\n",
    "    ctx2 = layers.Conv2D(num_filters, (3, 3), padding=\"same\")(ctx2)\n",
    "\n",
    "    # element-wise sum\n",
    "    sum = layers.Add()([conv, ctx2])\n",
    "    return sum\n",
    "\n",
    "\n",
    "def __decoder_module(input, encode_output, num_filters, localization_module=True):\n",
    "    # upsampling module\n",
    "    up = layers.UpSampling2D((2, 2))(input)\n",
    "    conv1 = layers.Conv2D(num_filters, (3, 3), padding=\"same\",\n",
    "                          activation=layers.LeakyReLU(0.01))(up)\n",
    "    concat = layers.Concatenate()([conv1, encode_output])\n",
    "\n",
    "    if not localization_module:\n",
    "        return concat\n",
    "\n",
    "    # localization module\n",
    "    conv2 = layers.Conv2D(num_filters, (3, 3), padding=\"same\",\n",
    "                          activation=layers.LeakyReLU(0.01))(concat)\n",
    "    conv2 = layers.Conv2D(num_filters, (1, 1), padding=\"same\",\n",
    "                          activation=layers.LeakyReLU(0.01))(conv2)\n",
    "    return conv2\n",
    "\n",
    "\n",
    "def build_model(input_shape):\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    # downsampling\n",
    "    down1 = __encoder_module(inputs, 16)\n",
    "    down2 = __encoder_module(down1, 32, strides=(2, 2))\n",
    "    down3 = __encoder_module(down2, 64, strides=(2, 2))\n",
    "    down4 = __encoder_module(down3, 128, strides=(2, 2))\n",
    "    down5 = __encoder_module(down4, 256, strides=(2, 2))\n",
    "\n",
    "    # upsampling\n",
    "    up1 = __decoder_module(down5, down4, 128)\n",
    "    up2 = __decoder_module(up1, down3, 64)\n",
    "    up3 = __decoder_module(up2, down2, 32)\n",
    "    up4 = __decoder_module(up3, down1, 16, localization_module=False)\n",
    "    conv = layers.Conv2D(32, (3, 3), padding=\"same\",\n",
    "                         activation=layers.LeakyReLU(0.01))(up4)\n",
    "\n",
    "    # segmentation layers\n",
    "    seg1 = layers.Conv2D(1, (1, 1), padding=\"same\",\n",
    "                         activation=layers.LeakyReLU(0.01))(up2)\n",
    "    seg1 = layers.UpSampling2D((2, 2), interpolation=\"bilinear\")(seg1)\n",
    "    seg2 = layers.Conv2D(1, (1, 1), padding=\"same\",\n",
    "                         activation=layers.LeakyReLU(0.01))(up3)\n",
    "    seg2 = layers.Add()([seg2, seg1])\n",
    "    seg2 = layers.UpSampling2D((2, 2), interpolation=\"bilinear\")(seg2)\n",
    "    seg3 = layers.Conv2D(1, (1, 1), padding=\"same\",\n",
    "                         activation=layers.LeakyReLU(0.01))(conv)\n",
    "    seg3 = layers.Add()([seg3, seg2])\n",
    "\n",
    "    outputs = layers.Activation(\"sigmoid\")(seg3)\n",
    "    model = models.Model(inputs, outputs, name=\"AdvUNet\")\n",
    "    return model\n",
    "\n",
    "\n",
    "class AdvUNet:\n",
    "    def __init__(self, input_shape):\n",
    "        self.model = build_model(input_shape)\n",
    "\n",
    "    def compile(self):\n",
    "        self.model.compile(optimizer=optimizers.Adam(learning_rate=5e-4),\n",
    "                           loss=dice_loss, metrics=[\"accuracy\", dice_coef])\n",
    "\n",
    "    def fit(self, train_dataset, val_dataset, batch_size, epochs):\n",
    "        self.model.fit(train_dataset.batch(batch_size), validation_data=val_dataset.batch(batch_size),\n",
    "                       epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Driver script for Improved UNet\n",
    "\"\"\"\n",
    "\n",
    "ISIC_DIR = \"../datasets/ISIC2018\"\n",
    "\n",
    "# height, width\n",
    "IMAGE_HEIGHT = 192\n",
    "IMAGE_WIDTH = 256\n",
    "NUM_CLASSES = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# load datasets\n",
    "features, labels = get_filenames(isic_dir=ISIC_DIR)\n",
    "train_features, train_labels, val_features, val_labels, test_features, test_labels = split_data(\n",
    "    features, labels, validation_split=0.2, test_split=0.2)\n",
    "\n",
    "# create datasets\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(\n",
    "    train_features, train_labels, val_features, val_labels,\n",
    "    test_features, test_labels, [IMAGE_HEIGHT, IMAGE_WIDTH], NUM_CLASSES)\n",
    "\n",
    "for image, label in train_dataset.take(1):\n",
    "    print(\"Dataset shapes:\", image.shape, label.shape)\n",
    "    break\n",
    "\n",
    "# create model\n",
    "model = AdvUNet(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "print(model.model.summary())\n",
    "\n",
    "# compile and train the model\n",
    "model.compile()\n",
    "history = model.fit(train_dataset, val_dataset,\n",
    "                    batch_size=BATCH_SIZE, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
