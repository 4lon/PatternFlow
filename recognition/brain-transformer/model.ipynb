{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messing about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vit_pytorch\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "\n",
    "train_data, valid_data = dataset.torch_train()\n",
    "test_data = dataset.torch_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = vit_pytorch.ViT(\n",
    "#     dim=512, \n",
    "#     image_size=256, \n",
    "#     patch_size=32,\n",
    "#     num_classes=2,\n",
    "#     depth=6,heads=12,\n",
    "#     mlp_dim=1024,\n",
    "#     channels=1,\n",
    "#     dropout=0.5\n",
    "#     ).cuda()\n",
    "\n",
    "\n",
    "model = vit_pytorch.SimpleViT(\n",
    "    dim=512, \n",
    "    image_size=256, \n",
    "    patch_size=32,\n",
    "    num_classes=2,\n",
    "    depth=6,heads=12,\n",
    "    mlp_dim=1024,\n",
    "    channels=1,\n",
    "    # dropout=0.5\n",
    "    ).cuda()\n",
    "\n",
    "\n",
    "# criterion = torch.nn.BCELoss()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer,step_size=1,gamma=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 0.7287280436785251\n",
      "Train Accuracy: 0.5257434944237919\n",
      "Valid Loss: 0.7052050058046977\n",
      "Valid Accuracy: 0.5225555555555556\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 0.6638504094793892\n",
      "Train Accuracy: 0.5957713754646841\n",
      "Valid Loss: 0.7547770191298587\n",
      "Valid Accuracy: 0.5218888888888888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_data)\n",
    "train_size = 0\n",
    "valid_iter = iter(test_data)\n",
    "valid_size = 0\n",
    "for i in train_iter:\n",
    "    train_size += i[0].shape[0]\n",
    "for i in valid_iter:\n",
    "    valid_size += i[0].shape[0]\n",
    "\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "history = {'train_loss':[], 'train_acc':[],'valid_loss':[],'valid_acc':[]}\n",
    "for epoch in range(20):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_iter = iter(train_data)\n",
    "    model.train()\n",
    "    for batch, labels in train_iter:\n",
    "        batch, labels = batch.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(batch)\n",
    "        loss = criterion(prediction, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = sum(torch.argmax(prediction,dim=1) == torch.argmax(labels,dim=1)).cpu().detach().numpy()\n",
    "        train_acc += acc\n",
    "        train_loss += loss.cpu().detach().numpy() * len(batch)/train_size\n",
    "    train_acc /= train_size\n",
    "\n",
    "    valid_loss = 0\n",
    "    valid_acc = 0\n",
    "    model.eval()\n",
    "    valid_iter = iter(test_data)\n",
    "    for batch, labels in valid_iter:\n",
    "        batch, labels = batch.cuda(),labels.cuda()\n",
    "        prediction = model(batch)\n",
    "        loss = criterion(prediction, labels)\n",
    "        acc = sum(torch.argmax(prediction,dim=1) == torch.argmax(labels,dim=1)).cpu().detach().numpy()\n",
    "        valid_acc += acc\n",
    "        valid_loss += loss.cpu().detach().numpy()*len(batch)/valid_size\n",
    "    valid_acc /= valid_size\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(valid_acc)\n",
    "    history['train_loss'].append(valid_loss)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}\\nTrain loss: {train_loss}\\nTrain Accuracy: {train_acc}\\nValid Loss: {valid_loss}\\nValid Accuracy: {valid_acc}\\n\")\n",
    "\n",
    "    if min_valid_loss > valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved/best_model.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6124444444444445\n"
     ]
    }
   ],
   "source": [
    "test_iter = iter(test_data)\n",
    "test_acc = 0\n",
    "test_size = 0\n",
    "model.eval()\n",
    "for batch, labels in test_iter:\n",
    "    batch, labels = batch.cuda(),labels.cuda()\n",
    "    prediction = model(batch)\n",
    "    acc = sum(torch.argmax(prediction,dim=1) == torch.argmax(labels,dim=1)).cpu().detach().numpy()\n",
    "    test_acc += acc\n",
    "    test_size+= len(batch)\n",
    "\n",
    "test_acc /= test_size\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\Users\\Dan\\Desktop\\University\\Sem 2 2022\\Pattern Recog\\project\\PatternFlow\\recognition\\brain-transformer\\model.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Users/Dan/Desktop/University/Sem%202%202022/Pattern%20Recog/project/PatternFlow/recognition/brain-transformer/model.ipynb#Y121sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history[\u001b[39m'\u001b[39m\u001b[39mtrain_acc\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history['train_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        g = self.projection(patch)\n",
    "        h = self.position_embedding(positions)\n",
    "\n",
    "        print(g.shape)\n",
    "        print(h.shape)\n",
    "        4 + '4'\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "#ViT Model\n",
    "def create_model(patch_size = 32, num_patches = 8,projection_dim=64,num_heads=4,transformers=8,transformer_units=[128,64],mlp_head_units=[2048,1024]):\n",
    "    inputs = layers.Input(shape=(256,256,1))\n",
    "\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(2)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6da927ccafd6642d9ccb03b2d8170da6f0652bff5ba8036b751f41afd51c2042"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
