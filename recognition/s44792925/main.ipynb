{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "\n",
    "MOUNTPOINT = '/content/gdrive'\n",
    "drive.mount(MOUNTPOINT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "input_dataset = '/content/gdrive/My Drive/Colab Notebooks/datasets/ISIC2018_Task1-2_Training_Data/ISIC2018_Task1-2_Training_Input_x2'\n",
    "output_dataset = '/content/gdrive/My Drive/Colab Notebooks/datasets/ISIC2018_Task1-2_Training_Data/ISIC2018_Task1_Training_GroundTruth_x2'\n",
    "\n",
    "train_x = tf.keras.utils.image_dataset_from_directory(directory=input_dataset, labels=None, shuffle=False, image_size=(256,256), validation_split=0.1, subset='training')\n",
    "val_x = tf.keras.utils.image_dataset_from_directory(directory=input_dataset, labels=None, shuffle=False, image_size=(256,256), validation_split=0.1, subset='validation')\n",
    "\n",
    "# normalize\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(scale= 1./255)\n",
    "train_x = train_x.map(lambda x: normalization_layer(x))\n",
    "\n",
    "\n",
    "# 10% test and val split with 80% train\n",
    "\n",
    "#train_x = train_x.skip(9)\n",
    "test_x = train_x.take(9)\n",
    "train_x = train_x.skip(9)\n",
    "\n",
    "print(len(val_x))\n",
    "print(len(train_x))\n",
    "print(len(test_x))\n",
    "\n",
    "train_y = tf.keras.utils.image_dataset_from_directory(directory=output_dataset, labels=None, shuffle=False, image_size=(256,256), validation_split=0.1, subset='training', color_mode='grayscale')\n",
    "val_y = tf.keras.utils.image_dataset_from_directory(directory=output_dataset, labels=None, shuffle=False, image_size=(256,256), validation_split=0.1, subset='validation', color_mode='grayscale')\n",
    "train_y = train_y.map(lambda x: normalization_layer(x))\n",
    "\n",
    "# 10% test and val split with 80% train\n",
    "\n",
    "test_y = train_y.take(9)\n",
    "train_y = train_y.skip(9)\n",
    "\n",
    "print(len(val_y))\n",
    "print(len(train_y))\n",
    "print(len(test_y))\n",
    "\n",
    "# need to convert y data to tf.dataset and then zip them together\n",
    "train_ds = tf.data.Dataset.zip((train_x , train_y))\n",
    "val_ds = tf.data.Dataset.zip((val_x , val_y))\n",
    "test_ds = tf.data.Dataset.zip((test_x , test_y))\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# copy paste contents of model.py into here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "height = 256\n",
    "width = 256\n",
    "channels = 3\n",
    "\n",
    "unet = model(height, width, channels)\n",
    "\n",
    "unet.summary()\n",
    "history =  unet.fit(train_ds, validation_data=val_ds, batch_size=16, epochs=10)\n",
    "\n",
    "predict_test = unet.predict(test_x)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}