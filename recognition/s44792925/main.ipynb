{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "\n",
    "MOUNTPOINT = '/content/gdrive'\n",
    "drive.mount(MOUNTPOINT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# load data code cell taken from demo 2\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "\n",
    "\n",
    "train_dir = '/content/gdrive/My Drive/Colab Notebooks/keras_png_slices_data/keras_png_slices_train'\n",
    "val_dir = '/content/gdrive/My Drive/Colab Notebooks/keras_png_slices_data/keras_png_slices_validate'\n",
    "test_dir = '/content/gdrive/My Drive/Colab Notebooks/keras_png_slices_data/keras_png_slices_test'\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  labels=None,\n",
    "  color_mode='grayscale',\n",
    "  #subset='training',\n",
    "  #validation_split=0.3,\n",
    "  batch_size=batch_size)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  test_dir,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  labels=None,\n",
    "  color_mode='grayscale',\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  val_dir,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  labels=None,\n",
    "  color_mode='grayscale',\n",
    "  batch_size=batch_size)\n",
    "\n",
    "# normalize\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(scale= 1./255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x: normalization_layer(x))\n",
    "test_ds = test_ds.map(lambda x: normalization_layer(x))\n",
    "val_ds = val_ds.map(lambda x: normalization_layer(x))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-387583a98ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#from google.colab import drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_quant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optimizer = tf.keras.optimizers.Adam(5e-4)\n",
    "\n",
    "def compute_loss(images, training):\n",
    "    loss = 0\n",
    "    # loss = reconstruction loss + codebook loss + commitment loss\n",
    "\n",
    "    # reconstruction loss optimizes decoder and encoder (standard what we were doing before)\n",
    "    # embedding loss optimizes vector_quant (calculated in model)\n",
    "\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def train(images, training):\n",
    "    with tf.GradientTape() as tf_encoder, tf.GradientTape() as tf_decoder:\n",
    "        loss = compute_loss(images, training)\n",
    "\n",
    "    return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# calculate SSIM\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}