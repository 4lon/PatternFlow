{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "\n",
    "MOUNTPOINT = '/content/gdrive'\n",
    "drive.mount(MOUNTPOINT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import sklearn.model_selection\n",
    "\n",
    "input_dataset = '/content/gdrive/My Drive/Colab Notebooks/datasets/ISIC2018_Task1-2_Training_Data/ISIC2018_Task1-2_Training_Input_x2/*.jpg'\n",
    "output_dataset = '/content/gdrive/My Drive/Colab Notebooks/datasets/ISIC2018_Task1-2_Training_Data/ISIC2018_Task1_Training_GroundTruth_x2/*.png'\n",
    "\n",
    "input = sorted(glob.glob(input_dataset))\n",
    "output = sorted(glob.glob(output_dataset))\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(input, output, test_size=0.2)\n",
    "x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(x_train, y_train, test_size=0.25) \n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "\n",
    "\n",
    "def process(input_path, output_path):\n",
    "  img = tf.image.decode_jpeg(tf.io.read_file(input_path), channels=3)\n",
    "  img = tf.image.resize(img, [256,256])\n",
    "  img = tf.cast(img, tf.float32) / 255 #normalize\n",
    "  img = tf.reshape(img, (-1, 256, 256, 3)) # resize\n",
    "\n",
    "  mask = tf.image.decode_png(tf.io.read_file(output_path), channels=1)\n",
    "  mask = tf.image.resize(mask, [256,256])\n",
    "  mask = tf.math.round(tf.cast(mask, tf.float32) / 255)\n",
    "  mask = tf.reshape(mask, (-1, 256, 256, 1))\n",
    "\n",
    "  return img, mask\n",
    "\n",
    "train_ds = train_ds.map(process)\n",
    "test_ds = test_ds.map(process)\n",
    "val_ds = val_ds.map(process)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# If you are using Google Colab -> copy paste contents of model.py into here OR upload model.py into Google Drive\n",
    "# If you are using local PC -> import model "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "height = 256\n",
    "width = 256\n",
    "channels = 3\n",
    "\n",
    "unet = model(height, width, channels)\n",
    "\n",
    "unet.summary()\n",
    "history =  unet.fit(train_ds, validation_data=val_ds, batch_size=32, epochs=50)\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b37993dbb31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0munet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#calc dice coefficient between predict_test and test_y\n",
    "\n",
    "predict_test = unet.predict(test_ds.map(lambda a, b: a))\n",
    "y_test = np.stack(list(test_ds.map(lambda a, b: b)))\n",
    "\n",
    "print(len(predict_test))\n",
    "print(len(y_test))\n",
    "\n",
    "\n",
    "total = 0\n",
    "\n",
    "for num in range(len(predict_test)):\n",
    "    # get total dice coefficient of each sample and then divide by num samples\n",
    "\n",
    "    #for i in range(32): #batch size = 32\n",
    "\n",
    "      #float_batch = tf.cast(batch[i], tf.float32)\n",
    "      #float_pred = tf.cast(predict_test[num + i], tf.float32)\n",
    "\n",
    "    flat_pred = tf.keras.backend.flatten(predict_test[num])\n",
    "    flat_test = tf.keras.backend.flatten(y_test[num])\n",
    "\n",
    "    total += 2. * tf.keras.backend.sum(flat_pred * flat_test) / (tf.keras.backend.sum(flat_pred) + tf.keras.backend.sum(flat_test)) #2 * intersection / union\n",
    "\n",
    "dice_coefficient = total / len(predict_test)\n",
    "\n",
    "tf.print(dice_coefficient, summarize=-1)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}