# -*- coding: utf-8 -*-
"""COMP3702_UNet_ISIC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F-1aAkPv29pH6VJSzzeJ6n-twuxkQGyO

"""

# Start by importing dependencies.

import pathlib
import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import load_img
import PIL.Image

print(tf.__version__)


# Some stuff to bug fix.

# Start by creating a basic U-NET model.

def get_model(img_size_params=(128, 128, 3), num_classes=1):
    inputs = keras.Input(shape=img_size_params)
    ### [First half of the network: downsampling inputs] ###

    # Entry block
    x = layers.Conv2D(32, 3, strides=2, padding="same")(inputs)
    x = layers.UpSampling2D(size=(2, 2))(x)
    outputs = layers.Conv2D(num_classes, 1, activation="sigmoid", padding="same")(x)

    # Define the model
    model = keras.Model(inputs, outputs)
    return model


def get_UNET_model(img_size_params=(128, 128, 3), num_classes=1):  # Only 3 layers deep for now.
    inputs = keras.Input(shape=img_size_params)

    # [First half of the network: downsampling inputs] ###
    # Entry block
    conv1 = layers.Conv2D(16, 3, strides=1, padding="same")(inputs)
    # Split the above input. Then plug it into the below and across the skip connection.
    context1 = context_module(conv1, n_filters=16)
    add1 = layers.Add()([conv1, context1])

    skip1 = add1

    conv2 = layers.Conv2D(32, 3, strides=2, padding="same")(add1)  # + the split connection from prev conv3d layer
    context2 = context_module(conv2, n_filters=32)
    add2 = layers.Add()([conv2, context2])

    skip2 = add2

    conv3 = layers.Conv2D(64, 3, strides=2, padding="same")(add2)
    context3 = context_module(conv3, n_filters=64)
    add3 = layers.Add()([conv3, context3])

    #skip3 = add3

    # x = layers.UpSampling2D(size=(2,2))(x)

    # Second half of the network, the decoder.
    upsample1 = upsampling_module(add3, n_filters=32)

    concat1 = layers.Concatenate(axis=-1)([upsample1, skip2])
    localize1 = localization_module(concat1, n_filters=32)

    upsample2 = upsampling_module(localize1, n_filters=16)

    concat2 = layers.Concatenate(axis=-1)([upsample2, skip1])

    conv4 = layers.Conv2D(32, 3, strides=1, padding="same")(concat2)


    
    outputs = layers.Conv2D(num_classes, 1, activation="sigmoid", padding="same")(conv4)

    # Define the model
    model = keras.Model(inputs, outputs)
    return model


# Modules

def context_module(inputs, n_filters=32, drop_prob=0.3):
    conv1 = layers.Conv2D(filters=n_filters, kernel_size=(3, 3), strides=1, padding="same")(inputs)
    leaky_relu1 = layers.LeakyReLU(0.01)(conv1)
    batch_norm1 = layers.BatchNormalization()(leaky_relu1)

    dropout = layers.Dropout(drop_prob)(batch_norm1)

    conv2 = layers.Conv2D(filters=n_filters, kernel_size=(3, 3), padding="same")(dropout)
    leaky_relu2 = layers.LeakyReLU(0.01)(conv2)
    batch_norm2 = layers.BatchNormalization()(leaky_relu2)

    return batch_norm2


def upsampling_module(inputs, n_filters=32, drop_prob=0.3):
    upsampling1 = layers.UpSampling2D(size=(2, 2))(inputs)
    conv1 = layers.Conv2D(filters=n_filters, kernel_size=(3, 3), padding="same")(upsampling1)
    leaky_relu1 = layers.LeakyReLU(0.01)(conv1)
    batch_norm1 = layers.BatchNormalization()(leaky_relu1)

    return batch_norm1


def localization_module(inputs, n_filters=32, drop_prob=0.3):
    conv1 = layers.Conv2D(filters=n_filters, kernel_size=(3, 3), padding="same")(inputs)
    leaky_relu1 = layers.LeakyReLU(0.01)(conv1)
    batch_norm1 = layers.BatchNormalization()(leaky_relu1)

    conv2 = layers.Conv2D(filters=n_filters/2, kernel_size=(1, 1), padding="same")(batch_norm1)
    leaky_relu2 = layers.LeakyReLU(0.01)(conv2)
    batch_norm2 = layers.BatchNormalization()(leaky_relu2)

    return batch_norm2


