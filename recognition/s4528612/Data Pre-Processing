
import re

import tensorflow as tf
import random, os
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import tensorflow.keras as keras
from tensorflow.keras import layers
left = 0
right = 0
labels = []
image_data = []
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        if re.search('right', filename.replace("_",""), re.IGNORECASE):
            right += 1
            labels.append(1)
        else:
            left += 1
            labels.append(0)
        image_data.append(img_to_array(load_img(dirname+"/"+filename,
                target_size=(73, 64),
                color_mode="grayscale")))
print(left)
print(right)


#Cross Attention Layer
def cross_attention(image_size):
    
    # Number of Pixels in the Scaled Image
    print(image_size)
    latent_input = layers.Input(shape=(256, 2*(2*6 + 1) + 1))
    data_array_input = layers.Input(shape=(image_size, 2*(2*6 + 1) + 1))

    latent_array = layers.LayerNormalization()(latent_input)
    data_array = layers.LayerNormalization()(data_array_input)

    query_key_value_vector = []
    

    query_key_value_vector.append(layers.Dense(units=2*(2*6 + 1) + 1)(latent_array))
    for _ in range(2):
        query_key_value_vector.append(layers.Dense(units=2*(2*6 + 1) + 1)(data_array))

    attention = layers.Attention(use_scale=True, dropout=0.1)(
        query_key_value_vector
    )
    attention = layers.Add()([attention, latent_array])

    attention = layers.LayerNormalization()(attention)
    
    # Feedforward network.
    feedforward_network = [] # May need to add more layers
    feedforward_network.append(layers.Dense(units=2*(2*6 + 1) + 1))
    outputs = keras.Sequential(feedforward_network)(attention)
    
    outputs = layers.Add()([outputs, attention])

    return keras.Model(inputs=[latent_input,data_array_input], outputs=outputs)

model = cross_attention(73*64, 2*(2*6 + 1) + 1)
model.summary()

#Reshape The Fourier Encoder to The array shape then performe calculation
def fourier_encode(array):
    array = tf.expand_dims(array-1)
    array = tf.cast(array, dtype=tf.float32)
    original_array = array.copy()
    encode = tf.reshape(tf.experimental.numpy.logspace(
            start=0.0,
            stop=0.7,
            num=10,
            dtype=tf.float32,
        ),((len(array.shape) - 1), 4))
    array =  3.14 * array * encode
    return tf.concat([tf.math.sin(array), tf.math.cos(array)], axis=-1)
def transformer_layer():
    inputs = layers.Input(shape=(256, 27))
    input_normalized = layers.LayerNormalization()(inputs)
    i = 0
    while i < 6:
        input_output_sum = layers.Add()([layers.Dense(27)(attention_component(inputs,input_normalized)[1]), attention_component(inputs,input_normalized)[0]])
        print(i)
        i += 1
    return tf.keras.Model(inputs=inputs, outputs=input_output_sum)



# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory
import re

import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
import tensorflow as tf
import matplotlib.pyplot as plt
import random, os
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import img_to_array
import numpy as np
# Constants
import tensorflow_addons as tfa
import tensorflow.keras as keras
from tensorflow.keras import layers

left = 0
right = 0
labels = []
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        if re.search('right', filename.replace("_",""), re.IGNORECASE):
            right += 1
            labels.append(0)
        else:
            left += 1
            labels.append(1)
print(left)
print(right)
# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

7760
10920

 

def cross_attention_layer(latent_size, data_size, proj_size):
    # projection_dim = data (1) + 2 * (2*bands + 1)
    # Input processed with a norm layer
    input_latent = layers.Input((latent_size, proj_size))
    latent_array = layers.LayerNormalization()(input_latent)

    input_data = layers.Input((data_size, proj_size))
    data_array = layers.LayerNormalization()(input_data)

    # QKV cross attention
    # K and V are projections of the input byte array, Q is a projection of a learned latent array
    q = layers.Dense(proj_size)(latent_array)
    k = layers.Dense(proj_size)(data_array)
    v = layers.Dense(proj_size)(data_array)
    
    # Generate cross-attention outputs: [batch_size, latent_dim, projection_dim].
    attention = layers.Attention(use_scale=True)([q, k ,v])
    
    # pass to a linear layer
    attention = layers.Dense(proj_size)(attention)
    # Add input to output
    attention = layers.Add()([attention, latent_array])

    # Normalize
    attention = layers.LayerNormalization()(attention)

    # Pass the attention to a Dense block (MLPs)
    outputs = layers.Dense(proj_size, activation=tf.nn.gelu)(attention)

    # Final linear layer
    outputs = layers.Dense(proj_size)(outputs)

    # Add input to output
    outputs = layers.Add()([outputs, attention])

    # Create the Keras model and return it
    return tf.keras.Model(inputs=[input_latent, input_data], outputs=outputs)

model = cross_attention_layer(256, 73*64, 2*(2*6 + 1) + 1)
model.summary()

2021-10-30 11:53:24.665457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-30 11:53:24.800994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-30 11:53:24.801729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-30 11:53:24.803205: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-10-30 11:53:24.804521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-30 11:53:24.805408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-30 11:53:24.806235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-30 11:53:27.210191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-30 11:53:27.210974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-30 11:53:27.211656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-30 11:53:27.212506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0

Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 27)]    0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 4672, 27)]   0                                            
__________________________________________________________________________________________________
layer_normalization (LayerNorma (None, 256, 27)      54          input_1[0][0]                    
__________________________________________________________________________________________________
layer_normalization_1 (LayerNor (None, 4672, 27)     54          input_2[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 256, 27)      756         layer_normalization[0][0]        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 4672, 27)     756         layer_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4672, 27)     756         layer_normalization_1[0][0]      
__________________________________________________________________________________________________
attention (Attention)           (None, 256, 27)      1           dense[0][0]                      
                                                                 dense_1[0][0]                    
                                                                 dense_2[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 256, 27)      756         attention[0][0]                  
__________________________________________________________________________________________________
add (Add)                       (None, 256, 27)      0           dense_3[0][0]                    
                                                                 layer_normalization[0][0]        
__________________________________________________________________________________________________
layer_normalization_2 (LayerNor (None, 256, 27)      54          add[0][0]                        
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 256, 27)      756         layer_normalization_2[0][0]      
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 256, 27)      756         dense_4[0][0]                    
__________________________________________________________________________________________________
add_1 (Add)                     (None, 256, 27)      0           dense_5[0][0]                    
                                                                 layer_normalization_2[0][0]      
==================================================================================================
Total params: 4,699
Trainable params: 4,699
Non-trainable params: 0
__________________________________________________________________________________________________

def create_ffn():
    ffn_layers = []
    #for units in hidden_units[:-1]:

    ffn_layers.append(layers.Dense(units=2*(2*6 + 1) + 1))
    #ffn_layers.append(layers.Dropout(dropout_rate))

    ffn = keras.Sequential(ffn_layers)
    return ffn

2*(2*6 + 1) + 1

27

def create_cross_attention_module(
    data_dim, projection_dim
):
    
    # Number of Pixels in the Scaled Image
    print(data_dim)
    print(projection_dim)
    latent_input = layers.Input(shape=(256, projection_dim))
    data_array_input = layers.Input(shape=(data_dim, projection_dim))

    latent_array = layers.LayerNormalization(epsilon=1e-6)(latent_input)
    data_array = layers.LayerNormalization(epsilon=1e-6)(data_array_input)

    query_key_value_vector = []
    

    query_key_value_vector.append(layers.Dense(units=projection_dim)(latent_array))
    for _ in range(2):
        query_key_value_vector.append(layers.Dense(units=projection_dim)(data_array))

    attention_output = layers.Attention(use_scale=True, dropout=0.1)(
        query_key_value_vector, return_attention_scores=False
    )
    attention_output = layers.Add()([attention_output, latent_array])

    attention_output = layers.LayerNormalization(epsilon=1e-6)(attention_output)
    
    # Feedforward network.
    ffn_layers = [] # May need to add more layers
    ffn_layers.append(layers.Dense(units=2*(2*6 + 1) + 1))
    outputs = keras.Sequential(ffn_layers)(attention_output)
    
    outputs = layers.Add()([outputs, attention_output])

    return keras.Model(inputs=[latent_input,data_array_input], outputs=outputs)

model = create_cross_attention_module(73*64, 2*(2*6 + 1) + 1)
model.summary()

4672
27
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 256, 27)]    0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            [(None, 4672, 27)]   0                                            
__________________________________________________________________________________________________
layer_normalization_3 (LayerNor (None, 256, 27)      54          input_3[0][0]                    
__________________________________________________________________________________________________
layer_normalization_4 (LayerNor (None, 4672, 27)     54          input_4[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 256, 27)      756         layer_normalization_3[0][0]      
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 4672, 27)     756         layer_normalization_4[0][0]      
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 4672, 27)     756         layer_normalization_4[0][0]      
__________________________________________________________________________________________________
attention_1 (Attention)         (None, 256, 27)      1           dense_6[0][0]                    
                                                                 dense_7[0][0]                    
                                                                 dense_8[0][0]                    
__________________________________________________________________________________________________
add_2 (Add)                     (None, 256, 27)      0           attention_1[0][0]                
                                                                 layer_normalization_3[0][0]      
__________________________________________________________________________________________________
layer_normalization_5 (LayerNor (None, 256, 27)      54          add_2[0][0]                      
__________________________________________________________________________________________________
sequential (Sequential)         (None, 256, 27)      756         layer_normalization_5[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 256, 27)      0           sequential[0][0]                 
                                                                 layer_normalization_5[0][0]      
==================================================================================================
Total params: 3,187
Trainable params: 3,187
Non-trainable params: 0
__________________________________________________________________________________________________

from tensorflow.keras import layers
import tensorflow as tf 


def dense_block(dense_layers):
    block = tf.keras.Sequential()
    # for units in dense_layers[:-1]:
    # use GELU activation as in paper
    block.add(layers.LayerNormalization())
    block.add(layers.Dense(dense_layers[0], activation=tf.nn.gelu))

    # Final linear layer
    block.add(layers.Dense(units=dense_layers[-1]))
    # block.add(layers.Dropout(dropout_rate))
    return block

def cross_attention(image_size):
    
    # Number of Pixels in the Scaled Image
    print(image_size)
    latent_input = layers.Input(shape=(256, 2*(2*6 + 1) + 1))
    data_array_input = layers.Input(shape=(image_size, 2*(2*6 + 1) + 1))

    latent_array = layers.LayerNormalization(epsilon=1e-6)(latent_input)
    data_array = layers.LayerNormalization(epsilon=1e-6)(data_array_input)

    query_key_value_vector = []
    

    query_key_value_vector.append(layers.Dense(units=2*(2*6 + 1) + 1)(latent_array))
    for _ in range(2):
        query_key_value_vector.append(layers.Dense(units=2*(2*6 + 1) + 1)(data_array))

    attention = layers.Attention(use_scale=True, dropout=0.1)(
        query_key_value_vector
    )
    attention = layers.Add()([attention, latent_array])

    attention = layers.LayerNormalization(epsilon=1e-6)(attention)
    
    # Feedforward network.
    feedforward_network = [] # May need to add more layers
    feedforward_network.append(layers.Dense(units=2*(2*6 + 1) + 1))
    outputs = keras.Sequential(feedforward_network)(attention)
    
    outputs = layers.Add()([outputs, attention])

    return keras.Model(inputs=[latent_input,data_array_input], outputs=outputs)

from tensorflow.keras import layers
import tensorflow as tf 
import math

"""
Fourier class to embed image data with fourier encoding, as described in the paper
"""
class FourierEncode(layers.Layer):
    """
    Init the Fourier class
    Params:
        max_freq: int, Nyquist frequency of the Fourier features
        num_bands: int, number of frequency bands in fourier features
    """
    def __init__(self, max_freq=10, num_bands=4):
        super(FourierEncode, self).__init__()
        self.max_freq = max_freq
        self.num_bands = num_bands

    """
    Process a call to the class with supplied data
    Params:
        imgs: an array containing img data
    Returns:
        img_encode: img encoded with its fourier features
    """
    def call(self, imgs):
        # Based on fourier encode from https://github.com/Rishit-dagli/Perceiver/blob/main/perceiver/
        batch_size, *axis, _ = imgs.shape
        axis = tuple(axis)
        rows, cols = axis[0], axis[1]
        # scales positions to [-1,1] and stack it
        # shape = list(tensor, tensor)
        axis_pos = list(map(lambda size: tf.linspace(-1.0, 1.0, num=size), axis))
        # shape = (*axis, 2)
        pos = tf.stack(tf.meshgrid(*axis_pos, indexing="ij"), axis=-1)

        # get the encoded fourier features
        enc_pos = self._fourier_encode(pos)
        del pos
        enc_pos = tf.reshape(enc_pos, (1, rows, cols, 2*(2*self.num_bands+1)))

        # repeat batch_size times
        enc_pos = tf.repeat(enc_pos, repeats=batch_size, axis=0)
        # combine image with encoded position
        img_encode = tf.concat((imgs, enc_pos), axis=-1)

        # flatten image
        img_encode = tf.reshape(img_encode, (batch_size, rows*cols, -1)) 
        return img_encode

    """
    Calculate the Fourier features and concat it into original position labels
    Params:
        pos: a tf matrix containing the positions scaled to range (-1, 1)
    Returns:
        concatenation of fourier feature and original position matrix
    """
    def _fourier_encode(self, pos):
        # shape = (*axis, 2 , 1)
        pos = tf.expand_dims(pos, -1)
        pos = tf.cast(pos, dtype=tf.float32)
        orig_pos = pos
        
        fk = tf.experimental.numpy.logspace(
            start=0.0,
            stop=math.log(self.max_freq / 2) / math.log(10),
            num=self.num_bands,
            dtype=tf.float32,
        )
        # reshape to match position matrix (4D)
        fk = tf.reshape(fk, (*((1,) * (len(pos.shape) - 1)), self.num_bands))

        # get fkπxd
        pos = pos * fk * math.pi

        # get fourier features: [sin(fkπxd), cos(fkπxd)]
        pos = tf.concat([tf.math.sin(pos), tf.math.cos(pos)], axis=-1)
        pos = tf.concat((pos, orig_pos), axis=-1)
        return pos

#Reshape The Fourier Encoder to The array shape then performe calculation
def fourier_encode(array):
    array = tf.expand_dims(array-1)
    array = tf.cast(array, dtype=tf.float32)
    original_array = array.copy()
    encode = tf.reshape(tf.experimental.numpy.logspace(
            start=0.0,
            stop=0.7,
            num=10,
            dtype=tf.float32,
        ),((len(array.shape) - 1), 4))
    array =  3.14 * array * encode
    return tf.concat([tf.math.sin(array), tf.math.cos(array)], axis=-1)

from tensorflow.keras import layers import tensorflow as tf import copy

def transformer_layer(): 
    inputs_orig = layers.Input(shape=(256, 27))

    input_plus_output = copy.deepcopy(inputs_orig)
    i = 0
    while i < 6:
        norm = layers.LayerNormalization()(inputs_orig)
        attention = layers.MultiHeadAttention(8, 27)(norm, norm)

        attention = layers.Dense(27)(attention)

        attention = layers.Add()([layers.MultiHeadAttention(8, 27)(norm, norm), inputs_orig])

        attention = layers.LayerNormalization()(attention)

        outputs = layers.Dense(27, activation=tf.nn.gelu)(attention)

        outputs = layers.Dense(27)(outputs)

        # Add output to input
        input_plus_output = layers.Add()([outputs, attention])

    # Create the Keras model.
    return tf.keras.Model(inputs=inputs_orig, outputs=input_plus_output)

 

def attention_component(inputs,input_normalized):
        attention_layer = layers.MultiHeadAttention(8, 27)(input_normalized, input_normalized)

        attention_layer = layers.Dense(27)(attention_layer)

        attention_layer = layers.Add()([attention_layer, inputs])

        attention_layer = layers.LayerNormalization()(attention_layer)

        return attention_layer, layers.Dense(27, activation=tf.nn.gelu)(attention_layer)

