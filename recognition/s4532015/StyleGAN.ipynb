{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Style GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, LeakyReLU, AveragePooling2D, Add, Input, InputSpec, UpSampling2D, Activation, Lambda, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.keras.utils import conv_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "depth = 16          #filters\n",
    "latent_size = 64    #size of input vector z\n",
    "im_size = 32        #final image size\n",
    "n_layers = 8        #no. layers in the synthesis network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" #load raw data\\nraw_ds = tf.keras.preprocessing.image_dataset_from_directory('D:\\\\Datasets\\\\keras_png_slices_data\\\\keras_png_slices_train', labels=None, color_mode='grayscale', batch_size=batch_size)\\nprint(raw_ds)\\n\\n#check range of values in raw data\\nimage_batch = next(iter(raw_ds))\\nfirst_image = image_batch[0]\\nprint(np.min(first_image), np.max(first_image))\\n\\n#normalise the data\\nnormalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset=-1)\\nnorm_ds = raw_ds.map(lambda img: (normalization_layer(img)))\\n\\n#check range of values in raw data\\nimage_batch = next(iter(norm_ds))\\nfirst_image = image_batch[0]\\nprint(np.min(first_image), np.max(first_image))\\n \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" #load raw data\n",
    "raw_ds = tf.keras.preprocessing.image_dataset_from_directory('D:\\Datasets\\keras_png_slices_data\\keras_png_slices_train', labels=None, color_mode='grayscale', batch_size=batch_size)\n",
    "print(raw_ds)\n",
    "\n",
    "#check range of values in raw data\n",
    "image_batch = next(iter(raw_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "\n",
    "#normalise the data\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset=-1)\n",
    "norm_ds = raw_ds.map(lambda img: (normalization_layer(img)))\n",
    "\n",
    "#check range of values in raw data\n",
    "image_batch = next(iter(norm_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #visualise raw data\\nfor images in raw_ds.take(1):\\n    plt.imshow(images[0].numpy().astype(\"float32\"), cmap=\\'gray\\')\\n    plt.show() '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" #visualise raw data\n",
    "for images in raw_ds.take(1):\n",
    "    plt.imshow(images[0].numpy().astype(\"float32\"), cmap='gray')\n",
    "    plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #visualise norm data\\nfor images in norm_ds.take(1):\\n    plt.imshow(images[0].numpy().astype(\"float32\"), cmap=\\'gray\\')\\n    plt.show() '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" #visualise norm data\n",
    "for images in norm_ds.take(1):\n",
    "    plt.imshow(images[0].numpy().astype(\"float32\"), cmap='gray')\n",
    "    plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv2DMod layer\n",
    "#https://github.com/manicman1999/StyleGAN2-Tensorflow-2.0/blob/989306792ca49dcbebb353c4f06c7b48aeb3a9e3/conv_mod.py#L15\n",
    "\n",
    "class ModConv2D (keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides=(1,1), padding = 'valid', kernel_initializer='glorot_uniform', \n",
    "                    kernel_regularizer=None, activity_regularizer=None, kernel_constraint=None, demod = True, **kwargs):\n",
    "        #define all the parameters of the layer\n",
    "        super(ModConv2D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.rank = 2\n",
    "        self.kernel_size= conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n",
    "        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n",
    "        self.padding = conv_utils.normalize_padding(padding)\n",
    "        #?\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        #?\n",
    "        self.demod = demod\n",
    "\n",
    "        #input with ndim=4 is previous convolution layer\n",
    "        #input with ndim=2 is the input style for this layer (output from style generator)\n",
    "        self.Input_spec = [InputSpec(ndim=4), InputSpec(ndim=2)]\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #define weights after shape of input is known\n",
    "        channel_axis = -1\n",
    "        input_dim = input_shape[0][channel_axis] #should be 1 for this dataset since it's only grayscale images being sent through the system\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape, initializer=self.kernel_initializer, name='kernel', \n",
    "                                        regularizer=self.kernel_regularizer, constraint=self.kernel_constraint)\n",
    "\n",
    "        #input specifications\n",
    "        #input_shape[0] is the output of the previous layer\n",
    "        #input_shape[1] is the style\n",
    "        self.input_spec = [InputSpec(ndim=4, axes={channel_axis: input_dim}), InputSpec(ndim=2)]\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #execute the code when the layer is used\n",
    "            #modulation stuff\n",
    "        style = inputs[1]\n",
    "        #print(\"style shape:\", style.shape)\n",
    "        #print(\"kernel shape:\", self.kernel.shape)\n",
    "\n",
    "        #make the input style W shape compatible with kernel\n",
    "        inp_mods = K.expand_dims(K.expand_dims(K.expand_dims(style, axis = 1), axis = 1), axis = -1)\n",
    "        my_kernel = K.expand_dims(self.kernel, axis=0)\n",
    "\n",
    "        #modulate\n",
    "        #print(\"kernel\", (int)(tf.rank(my_kernel)), my_kernel.shape)\n",
    "        #print(\"kernel shape:\", my_kernel.shape)\n",
    "        #print(\"input style\", (int)(tf.rank(inp_mods)), inp_mods.shape)\n",
    "        #print(\"input style shape:\", inp_mods.shape)\n",
    "        weights = my_kernel * (inp_mods + 1)\n",
    "        #weights = 0\n",
    "\n",
    "        #demodulate\n",
    "        if self.demod:\n",
    "            weights /= K.sqrt(K.sum(K.square(weights), axis=[1,2,3], keepdims = True) + 1e-8)\n",
    "        \n",
    "        x = tf.transpose(inputs[0], [0,3,1,2])\n",
    "        x = tf.reshape(x, [1, -1, x.shape[2], x.shape[3]])\n",
    "\n",
    "        w = tf.transpose(weights, [1,2,3,0,4])\n",
    "        w = tf.reshape(w, [weights.shape[1], weights.shape[2], weights.shape[3], -1])\n",
    "\n",
    "        #normal convolution 2d\n",
    "        #data is stored in [batch_size, channels, height, width]\n",
    "        x = tf.nn.conv2d(x, w, strides=self.strides, padding='SAME', data_format='NCHW')\n",
    "\n",
    "        #print(x.shape)\n",
    "\n",
    "        x = tf.reshape(x, [-1, self.filters, tf.shape(x)[2], tf.shape(x)[3]]) # Fused => reshape convolution groups back to minibatch.\n",
    "        x = tf.transpose(x, [0, 2, 3, 1])\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define generator\n",
    "#mapping network\n",
    "    #for taking an image (style) and converting it to latent space to use in the weights of the synthesis network\n",
    "#synthesis network\n",
    "    #network used to generate images using input style and noise\n",
    "    #skip connections\n",
    "\n",
    "#https://github.com/manicman1999/StyleGAN2-Tensorflow-2.0/blob/master/stylegan_two.py\n",
    "\n",
    "def noise(n):\n",
    "    return np.random.normal(0.0, 1.0, size = [n, latent_size]).astype('float32')\n",
    "\n",
    "def noiseList(n):\n",
    "    return [noise(n)] * n_layers\n",
    "\n",
    "def crop_to_fit(x):\n",
    "    #makes sure that x[0] has the same dimensions as x[1]\n",
    "    height = x[1].shape[1]\n",
    "    width = x[1].shape[2]\n",
    "\n",
    "    return x[0][:, :height, :width, :]\n",
    "\n",
    "def make_output_size(s1=4, s2=im_size):\n",
    "    ss = int(s2 / s1)\n",
    "    #print(ss)\n",
    "    def upsample_to_size(x, y = ss):\n",
    "        x = K.resize_images(x, y, y, \"channels_last\", interpolation='bilinear')\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "    return upsample_to_size\n",
    "\n",
    "def to_output(inputs, style):\n",
    "    #want to do a ModConv2D on input with styles like norma;\n",
    "    size = inputs.shape[2]\n",
    "    print(inputs.shape, size)\n",
    "    x = ModConv2D(1, 1, kernel_initializer=VarianceScaling(200/size), demod=False)([inputs, style])\n",
    "    #upsample image to be (None, im_size, im_size, None)\n",
    "    print(x.shape)\n",
    "    return Lambda(make_output_size(size, im_size), output_shape=[None, im_size, im_size, None])(x)\n",
    "\n",
    "def make_style_generator():\n",
    "    #standard deep NN\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(512, input_shape=[latent_size]))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    return model\n",
    "\n",
    "def g_block(inputs, input_style, input_noise, filters, upsampling=True):\n",
    "\n",
    "    #optional upsampling\n",
    "    if upsampling:\n",
    "        out = UpSampling2D(interpolation='bilinear')(inputs)\n",
    "    else:\n",
    "        out = Activation('linear')(inputs)\n",
    "\n",
    "    #residual\n",
    "    out_style = Dense(filters, kernel_initializer = VarianceScaling(200/out.shape[2]))(input_style)\n",
    "\n",
    "    #main block\n",
    "    #style stuff\n",
    "    style = Dense(inputs.shape[-1], kernel_initializer = 'he_uniform')(input_style)\n",
    "    delta = Lambda(crop_to_fit)([input_noise, out])\n",
    "    d = Dense(filters, kernel_initializer='zeros')(delta)\n",
    "\n",
    "    #ModConv2D block\n",
    "    out = ModConv2D(filters, (3,3), strides=(1,1), padding=\"same\", kernel_initializer = 'he_uniform')([out, style])\n",
    "    out = Add()([out, d])\n",
    "    out = LeakyReLU(0.2)(out)\n",
    "\n",
    "    return out, to_output(out, out_style)\n",
    "\n",
    "\n",
    "def make_synthesis_network ():\n",
    "    #Inputs\n",
    "    input_styles = []\n",
    "    #input_noises = []\n",
    "    for i in range(n_layers):\n",
    "        input_styles.append(Input(shape=[512]))\n",
    "\n",
    "    input_noise = Input(shape=[im_size, im_size, 1])\n",
    "    outs = []\n",
    "\n",
    "    x = Lambda(lambda x: x[:, :1]*0 + 1)(input_styles[0])\n",
    "\n",
    "    x = Dense(4*4*4*depth, activation='relu', kernel_initializer='random_normal')(x) #learned constant input vector\n",
    "    x = Reshape([4, 4, 4*depth])(x) #a [4, 4, 4*depth] tensor --> to feed next layer of 4x4\n",
    "\n",
    "    x, r = g_block(x, input_styles[1], input_noise, 64*depth, upsampling=False)    #4x4\n",
    "    outs.append(r)\n",
    "    #print(x.shape) #, r.shape)\n",
    "    x, r = g_block(x, input_styles[2], input_noise, 32*depth)                      #8x8\n",
    "    outs.append(r)\n",
    "    #print(x.shape) #, r.shape)\n",
    "    x, r = g_block(x, input_styles[3], input_noise, 16*depth)                      #16x16\n",
    "    outs.append(r)\n",
    "    #print(x.shape) #, r.shape)\n",
    "    x, r = g_block(x, input_styles[3], input_noise, 8*depth)                       #32x32\n",
    "    \"\"\" \n",
    "    outs.append(r)\n",
    "    #print(x.shape) #, r.shape)\n",
    "    x, r = g_block(x, input_styles[5], input_noise, 4*depth)                       #64x64\n",
    "    outs.append(r)\n",
    "    print(x.shape) #, r.shape)\n",
    "    x, r = g_block(x, input_styles[6], input_noise, 2*depth)                       #128x128\n",
    "    outs.append(r)\n",
    "    print(x.shape) #, r.shape)\n",
    "    x, r = g_block(x, input_styles[7], input_noise, depth)                         #256x256\n",
    "    outs.append(r)\n",
    "    print(x.shape) #, r.shape)\n",
    "    \"\"\"\n",
    "\n",
    "    x = Add()(outs)\n",
    "\n",
    "    #normalise\n",
    "    x = Lambda(lambda y: y/2 + 0.5)(x)\n",
    "\n",
    "    print(\"end shape\", x.shape)\n",
    "    \n",
    "    model = Model(inputs = [input_styles, input_noise], outputs = x)\n",
    "    return model\n",
    "\n",
    "def make_generator_model(S, G):\n",
    "    input_z = []\n",
    "    W = []\n",
    "    for i in range(n_layers):\n",
    "        input_z.append(Input([latent_size]))\n",
    "        W.append(S(input_z[-1]))\n",
    "\n",
    "    input_noise = Input([im_size, im_size, 1])\n",
    "\n",
    "    generated_image = G((W, input_noise))\n",
    "    \n",
    "    gen_model = Model(inputs = [input_z, input_noise], outputs = generated_image)\n",
    "\n",
    "    return gen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 4, 4, 1024) 4\n",
      "(None, None, None, 1)\n",
      "(None, 8, 8, 512) 8\n",
      "(None, None, None, 1)\n",
      "(None, 16, 16, 256) 16\n",
      "(None, None, None, 1)\n",
      "(None, 32, 32, 128) 32\n",
      "(None, None, None, 1)\n",
      "end shape (None, None, None, 1)\n"
     ]
    }
   ],
   "source": [
    "#make generator model\n",
    "S = make_style_generator()\n",
    "G = make_synthesis_network()\n",
    "\n",
    "gen_model = make_generator_model(S, G)\n",
    "\n",
    "#gen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = noiseList(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f00526c7c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "w = []\n",
    "for i in range(n_layers):\n",
    "    w.append(S(z[i]))\n",
    "\n",
    "added_noise = tf.random.normal((batch_size, im_size, im_size, 1))\n",
    "image = G((w, added_noise))\n",
    "print(image.shape)\n",
    "plt.imshow(image[1].numpy().astype(\"float32\"), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1efdc1c5d30>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#z = noiseList(batch_size)\n",
    "added_noise = tf.random.normal((batch_size, im_size, im_size, 1))\n",
    "image = gen_model((z, added_noise))\n",
    "print(image.shape)\n",
    "plt.imshow(image[0].numpy().astype(\"float32\"), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define discriminator\n",
    "    #residual connections\n",
    "\n",
    "#https://github.com/manicman1999/StyleGAN2-Tensorflow-2.0/blob/master/stylegan_two.py\n",
    "\n",
    "def d_block(inputs, filters, pooling=True):\n",
    "    residual = Conv2D(filters, 1)(inputs)\n",
    "\n",
    "    out = Conv2D(filters, (3,3), padding='same')(inputs)\n",
    "    out = LeakyReLU(0.2)(out)\n",
    "    out = Conv2D(filters, (3,3), padding='same')(out)\n",
    "    out = LeakyReLU(0.2)(out)\n",
    "\n",
    "    out = Add()([residual, out])\n",
    "\n",
    "    if pooling:\n",
    "        out = AveragePooling2D()(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def make_discriminator_model():\n",
    "    inputs = Input(shape=(256, 256, 1))\n",
    "\n",
    "    x = d_block(inputs, depth)\n",
    "    x = d_block(x, depth * 2)\n",
    "    x = d_block(x, depth * 4)\n",
    "    x = d_block(x, depth * 8)\n",
    "    x = d_block(x, depth * 16, pooling=False)\n",
    "\n",
    "    #classification stuff\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs= inputs, outputs = x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_37 (InputLayer)           [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 16) 160         input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 16) 2320        leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 16) 32          input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 256, 256, 16) 0           conv2d[0][0]                     \n",
      "                                                                 leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 128, 128, 16) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 32) 4640        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 128, 128, 32) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 32) 9248        leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 32) 544         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 128, 128, 32) 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 128, 128, 32) 0           conv2d_3[0][0]                   \n",
      "                                                                 leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 64, 64, 32)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 64)   18496       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 64, 64, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 64)   36928       leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 64)   2112        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 64, 64, 64)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 64, 64, 64)   0           conv2d_6[0][0]                   \n",
      "                                                                 leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 32, 32, 64)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 128)  73856       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 32, 32, 128)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 128)  147584      leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 128)  8320        average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 32, 32, 128)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 128)  0           conv2d_9[0][0]                   \n",
      "                                                                 leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 16, 16, 128)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 256)  295168      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 16, 16, 256)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 256)  590080      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 256)  33024       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 16, 16, 256)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 256)  0           conv2d_12[0][0]                  \n",
      "                                                                 leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 65536)        0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1)            65537       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,288,049\n",
      "Trainable params: 1,288,049\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create discriminator\n",
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#losses and inference"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a3b76dc9f98c3b7c2833723de1f287f5b2fddd8af30239771319b1a6738189a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
