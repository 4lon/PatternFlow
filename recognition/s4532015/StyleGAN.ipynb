{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Style GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, LeakyReLU, AveragePooling2D, Add, Input, InputSpec, UpSampling2D, Activation, Lambda, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.keras.utils import conv_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "depth = 32\n",
    "latent_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load raw data\n",
    "raw_ds = tf.keras.preprocessing.image_dataset_from_directory('D:\\Datasets\\keras_png_slices_data\\keras_png_slices_train', labels=None, color_mode='grayscale', batch_size=batch_size)\n",
    "print(raw_ds)\n",
    "\n",
    "#check range of values in raw data\n",
    "image_batch = next(iter(raw_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "\n",
    "#normalise the data\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset=-1)\n",
    "norm_ds = raw_ds.map(lambda img: (normalization_layer(img)))\n",
    "\n",
    "#check range of values in raw data\n",
    "image_batch = next(iter(norm_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise raw data\n",
    "for images in raw_ds.take(1):\n",
    "    plt.imshow(images[0].numpy().astype(\"float32\"), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise norm data\n",
    "for images in norm_ds.take(1):\n",
    "    plt.imshow(images[0].numpy().astype(\"float32\"), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv2DMod layer\n",
    "#https://github.com/manicman1999/StyleGAN2-Tensorflow-2.0/blob/989306792ca49dcbebb353c4f06c7b48aeb3a9e3/conv_mod.py#L15\n",
    "\n",
    "class ModConv2D (keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides=(1,1), padding = 'valid', kernel_initializer='glorot_uniform', \n",
    "                    kernel_regularizer=None, activity_regularizer=None, kernel_constraint=None, demod = True, **kwargs):\n",
    "        #define all the parameters of the layer\n",
    "        super(ModConv2D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.rank = 2\n",
    "        self.kernel_size= conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n",
    "        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n",
    "        self.padding = conv_utils.normalize_padding(padding)\n",
    "        #?\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        #?\n",
    "        self.demod = demod\n",
    "\n",
    "        #input with ndim=4 is previous convolution layer\n",
    "        #input with ndim=2 is the input style for this layer (output from style generator)\n",
    "        self.Input_spec = [InputSpec(ndim=4), InputSpec(ndim=2)]\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #define weights after shape of input is known\n",
    "        channel_axis = -1\n",
    "        input_dim = input_shape[0][channel_axis] #should be 1 for this dataset since it's only grayscale images being sent through the system\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape, initializer=self.kernel_initializer, name='kernel', \n",
    "                                        regularizer=self.kernel_regularizer, constraint=self.kernel_constraint)\n",
    "\n",
    "        #input specifications\n",
    "        #input_shape[0] is the output of the previous layer\n",
    "        #input_shape[1] is the style\n",
    "        self.input_spec = [InputSpec(ndim=4, axes={channel_axis: input_dim}), InputSpec(ndim=2)]\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #execute the code when the layer is used\n",
    "            #modulation stuff\n",
    "        style = inputs[1]\n",
    "        #print(\"style shape:\", style.shape)\n",
    "        #print(\"kernel shape:\", self.kernel.shape)\n",
    "\n",
    "        #make the input style W shape compatible with kernel\n",
    "        inp_mods = K.expand_dims(K.expand_dims(style, axis = 1), axis = 1)\n",
    "        my_kernel = K.expand_dims(self.kernel, axis=0)\n",
    "\n",
    "        #modulate\n",
    "        #print(\"kernel\", (int)(tf.rank(my_kernel)), my_kernel.shape)\n",
    "        #print(\"kernel shape:\", my_kernel.shape)\n",
    "        #print(\"input style\", (int)(tf.rank(inp_mods)), inp_mods.shape)\n",
    "        #print(\"input style shape:\", inp_mods.shape)\n",
    "        weights = my_kernel * (inp_mods + 1)\n",
    "        #weights = 0\n",
    "\n",
    "        #demodulate\n",
    "        if self.demod:\n",
    "            weights /= K.sqrt(K.sum(K.square(weights), axis=[1,2,3], keepdims = True) + 1e-8)\n",
    "        \n",
    "        x = tf.transpose(inputs[0], [0,3,1,2])\n",
    "        x = tf.reshape(x, [1, -1, x.shape[2], x.shape[3]])\n",
    "\n",
    "        w = tf.transpose(weights, [1,2,3,0,4])\n",
    "        w = tf.reshape(w, [weights.shape[1], weights.shape[2], weights.shape[3], -1])\n",
    "\n",
    "        #normal convolution 2d\n",
    "        #data is stored in [batch_size, channels, height, width]\n",
    "        x = tf.nn.conv2d(x, w, strides=self.strides, padding='SAME', data_format='NCHW')\n",
    "\n",
    "        #print(x.shape)\n",
    "\n",
    "        x = tf.reshape(x, [-1, self.filters, tf.shape(x)[2], tf.shape(x)[3]]) # Fused => reshape convolution groups back to minibatch.\n",
    "        x = tf.transpose(x, [0, 2, 3, 1])\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define generator\n",
    "#mapping network\n",
    "    #for taking an image (style) and converting it to latent space to use in the weights of the synthesis network\n",
    "#synthesis network\n",
    "    #network used to generate images using input style and noise\n",
    "    #skip connections\n",
    "\n",
    "#https://github.com/manicman1999/StyleGAN2-Tensorflow-2.0/blob/master/stylegan_two.py\n",
    "\n",
    "def crop_to_fit(x):\n",
    "    #makes sure that x[0] has the same dimensions as x[1]\n",
    "    height = x[1].shape[1]\n",
    "    width = x[1].shape[2]\n",
    "\n",
    "    return x[0][:, :height, :width, :]\n",
    "\n",
    "def make_style_generator():\n",
    "    #standard deep NN\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(512, input_shape=[1, latent_size]))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def g_block(inputs, input_style, input_noise, filters, upsampling=True):\n",
    "\n",
    "    #optional upsampling\n",
    "    if upsampling:\n",
    "        out = UpSampling2D(interpolation='bilinear')(inputs)\n",
    "    else:\n",
    "        out = Activation('linear')(inputs)\n",
    "\n",
    "\n",
    "    #main block\n",
    "    #style stuff\n",
    "    style = Dense(filters, kernel_initializer = VarianceScaling(200/out.shape[2]))(input_style)\n",
    "    delta = Lambda(crop_to_fit)([input_noise, out])\n",
    "    d = Dense(filters, kernel_initializer='zeros')(delta)\n",
    "\n",
    "    #ModConv2D block\n",
    "    out = ModConv2D(filters, (3,3), strides=(1,1), padding=\"same\", kernel_initializer = 'he_uniform')([out, style])\n",
    "    out = Add()([out, d])\n",
    "    out = LeakyReLU(0.2)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def make_generator_model ():\n",
    "    #constant input\n",
    "    ''' inputs = Input(shape=[[512,1],[64,64,1]])\n",
    "    input_style = inputs[0]\n",
    "    input_noise = inputs[1] '''\n",
    "    input_style = Input(shape=(512))\n",
    "    input_noise = Input(shape=(256, 256, 1))\n",
    "\n",
    "    x = tf.ones((1, 512))#Lambda(lambda x: x[:, :1]*0 + 1)(input_style) #just a 512 vector of 1s\n",
    "\n",
    "    x = Dense(4*4*4*depth, activation='relu', kernel_initializer='random_normal')(x)\n",
    "    x = Reshape([4, 4, 4*depth])(x) #a [4, 4, 4*depth] tensor\n",
    "\n",
    "    x = g_block(x, input_style, input_noise, 64*depth, upsampling=False)    #4x4\n",
    "    x = g_block(x, input_style, input_noise, 32*depth)                      #8x8\n",
    "    x = g_block(x, input_style, input_noise, 16*depth)                      #16x16\n",
    "    #x = g_block(x, input_style, input_noise, 8*depth)                       #32x32\n",
    "    #x = g_block(x, input_style, input_noise, 4*depth)                       #64x64\n",
    "    #x = g_block(x, input_style, input_noise, 2*depth)                       #128x128\n",
    "    #x = g_block(x, input_style, input_noise, depth)                         #256x256\n",
    "\n",
    "    model = Model(inputs = [input_style, input_noise], outputs = x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1, 512)            262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 512)            262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1, 512)            262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1, 512)            262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1, 512)            0         \n",
      "=================================================================\n",
      "Total params: 1,050,624\n",
      "Trainable params: 1,050,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "style_generator = make_style_generator()\n",
    "style_generator.summary()\n",
    "\n",
    "style_vector = style_generator(tf.random.normal((1,512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2048)         1050624     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 4, 4, 1)      0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mod_conv2d_3 (ModConv2D)        (1, 4, 4, 2048)      2359296     dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 4, 4, 2048)   4096        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4, 4, 2048)   0           mod_conv2d_3[0][0]               \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 4, 4, 2048)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 2048)   0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1024)         525312      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 8, 8, 1)      0           input_4[0][0]                    \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mod_conv2d_4 (ModConv2D)        (1, 8, 8, 1024)      18874368    up_sampling2d_2[0][0]            \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 8, 8, 1024)   2048        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 1024)   0           mod_conv2d_4[0][0]               \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 8, 8, 1024)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 1024) 0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 512)          262656      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16, 16, 1)    0           input_4[0][0]                    \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mod_conv2d_5 (ModConv2D)        (1, 16, 16, 512)     4718592     up_sampling2d_3[0][0]            \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 16, 16, 512)  1024        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 512)  0           mod_conv2d_5[0][0]               \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 512)  0           add_5[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 27,798,016\n",
      "Trainable params: 27,798,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create generator\n",
    "generator = make_generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c0df632fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD4CAYAAAAjDTByAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAARZ0lEQVR4nO3dfWyd5XnH8e8Vx7Fjx4mdBIhDogAFIbFqGyhC0FWsWhgLGSKd1D+C1g1KpVJtbDB1QumQ1mp/tevWvVatMmBlG4JqFFZUwUpGW1WTlqwQwlteSGAZccgrJHbeYzvX/jhP0InjE/u5npc4u38fycqxz3P5vvOc8/NzznPOfS5zd0QkPdMu9ARE5MJQ+EUSpfCLJErhF0mUwi+SqOl1Dtbd3e29vb25606cOJG7Znh4OHcNwOnTp3PXRF8xMbPa6qZNi/2db2trq60uOseI0dHRUF3kvghw6tSp3DWR/TE8PMzo6Oik7iC1hr+3t5f77rsvd92WLVty1+zfvz93DcCRI0dy10T+YED8zt7R0ZG7ZubMmaGxZs2aFarr6+vLXdPd3R0aK7L/BwcHQ2Nt3bo1VLdr167cNZHbeefOnZPeVg/7RRKl8IskqlD4zWy5mW01s+1mtrqsSYlI9cLhN7M24FvA7cB1wF1mdl1ZExORahU58t8IbHf3d939FPAUsLKcaYlI1YqE/3Kg+dTiQPazs5jZF8zsZTN7+ejRowWGE5EyVX7Cz93XuPtSd18afSlHRMpXJPy7gMVN3y/KfiYiF4Ei4f85cI2ZXWlmM4BVwHPlTEtEqhZ+h5+7j5jZ/cCPgDbgMXd/q7SZiUilCr29192fB54vaS4iUiO9w08kUbUu7Onp6eHWW2/NXXfzzTfnroku7NmzZ0/umugikehLn5EVadGFPfPmzQvV9ff3566JLGQBOHjwYO6aTZs2hcY6duxYqG5oaCh3zfz580NjTZaO/CKJUvhFEqXwiyRK4RdJlMIvkiiFXyRRCr9IohR+kUQp/CKJUvhFEqXwiyRK4RdJVK0Le6IOHTqUuyaykAJi7ZiiHXumT4/t/s7Oztw10c470QVBIyMjuWsOHDgQGuvtt9/OXbNu3brQWNu2bQvVRdp1Rdqy5dnvOvKLJErhF0mUwi+SqCIdexab2U/MbJOZvWVmD5Q5MRGpVpETfiPAl9x9g5n1AK+Y2Vp3j31EiojUKnzkd/fd7r4hu3wY2Mw4HXtEZGoq5Tm/mV0BXA+sH+e6j9p1RV6yE5FqFA6/mc0Cvg886O7nvLje3K6rt7e36HAiUpJC4TezdhrBf8LdnylnSiJShyJn+w14FNjs7t8sb0oiUociR/5fAX4H+DUz25h9rShpXiJSsSK9+v4TyP/mYxGZEvQOP5FEXRSr+o4cOZK7JtquK7KyLLISEKCtrS1UF3nVpKurKzTW7NmzQ3WRVYTR9mWRFXPRFmuR1YoQa7E2Y8aM3DV5VgLqyC+SKIVfJFEKv0iiFH6RRCn8IolS+EUSpfCLJErhF0mUwi+SKIVfJFEKv0iiFH6RRNW+sCeyMCJSc+zYsdw1AIcPH85dMzw8HBor0nYLoL29PXfNnDlzQmP19/eH6iKLjzo6OkJjRRbpbN26NTTWwMBAqC56H6mSjvwiiVL4RRKl8IskqoyP7m4zs1fN7IdlTEhE6lHGkf8BGt16ROQiUvRz+xcBvwk8Us50RKQuRY/8fw08BJwuPhURqVORph13APvc/ZUJtlOvPpEpqGjTjjvNbAfwFI3mHf8ydiP16hOZmoq06P6yuy9y9yuAVcCP3f2zpc1MRCql1/lFElXKe/vd/afAT8v4XSJSDx35RRJV66q+06dPh1bbRVb1uXvummhddKzp02O7P7IasKenJzTW3LlzQ3V9fX25ayKrFSG2gnP79u2hsV599dVQXaSl2MmTJ3PX5Lkv6sgvkiiFXyRRCr9IohR+kUQp/CKJUvhFEqXwiyRK4RdJlMIvkiiFXyRRCr9IohR+kUQp/CKJqnVV3+joKENDQ7nrIqv6urq6ctcAdHd35645evRoaKyoOlcemlmoLrJiMbISEGDJkiW5a66++urQWNFVjidOnMhdc/p0/s/F1ao+EZmQwi+SKIVfJFFFO/b0mtnTZrbFzDab2c1lTUxEqlX0hN/fAP/u7p8xsxlA7CybiNQuHH4zmwPcAtwD4O6ngPwfVCYiF0SRh/1XAvuBf8xadD9iZue8TtbcrivyMp+IVKNI+KcDNwDfdvfrgaPA6rEbNbfrmj17doHhRKRMRcI/AAy4+/rs+6dp/DEQkYtAkV59e4CdZnZt9qNlwKZSZiUilSt6tv8PgCeyM/3vAp8rPiURqUOh8Lv7RmBpOVMRkTrV3q7r+PHjuesii0sWLFiQuwYgclLy8OHDobGii20ic+zo6AiNFW0pNm1a/meU0bEii7FmzZpV21gQu60jLb60sEdEJqTwiyRK4RdJlMIvkiiFXyRRCr9IohR+kUQp/CKJUvhFEqXwiyRK4RdJlMIvkiiFXyRRta7qi2pvb89ds3DhwtrGOnLkSGiskydPhura2tpy10T+XwDDw8Ohukh7qhkzZoTGiqz6jO6PmTNnhuoicxwdHc1do1V9IjIhhV8kUQq/SKKKtuv6IzN7y8zeNLMnzayzrImJSLXC4Tezy4E/BJa6+8eBNmBVWRMTkWoVfdg/HZhpZtNp9Ol7v/iURKQORT63fxfwF8B7wG5g0N1fHLtdc7uu6Addikj5ijzs7wNW0ujZtxDoNrPPjt2uuV1XT09PfKYiUqoiD/tvBf7H3fe7+zDwDPCJcqYlIlUrEv73gJvMrMsab19aBmwuZ1oiUrUiz/nX02jOuQF4I/tda0qal4hUrGi7rq8AXylpLiJSI73DTyRRta/qi/Rwi7xKsGTJktw1APPnz89dE+mpBvEef5G6OlfnRUVXzEVWR0ZW2UHsvgixPoTR22yydOQXSZTCL5IohV8kUQq/SKIUfpFEKfwiiVL4RRKl8IskSuEXSZTCL5IohV8kUQq/SKJqXdgzbdo0Ojo6ctd1dXXlroks0AHo7+8P1UUMDQ2F6g4cOJC75tChQ6Gxjh07FqobHBzMXRPdH8ePH89dE5lfEZEWayMjI7lr8ixY0pFfJFEKv0iiFH6RRE0YfjN7zMz2mdmbTT+ba2ZrzWxb9m9ftdMUkbJN5sj/XWD5mJ+tBl5y92uAl7LvReQiMmH43f1nwIdjfrwSeDy7/Djw6XKnJSJViz7nv8zdd2eX9wCXtdqwuV1X9KUcESlf4RN+7u6An+f6j9p1zZ49u+hwIlKSaPj3mlk/QPbvvvKmJCJ1iIb/OeDu7PLdwA/KmY6I1GUyL/U9CfwXcK2ZDZjZ54GvAb9uZttoNOz8WrXTFJGyTfjefne/q8VVy0qei4jUSO/wE0lUrav6zIzOzs7cdd3d3RXMZnyR1luRFVsQa10G0N7enrsm0i4KYHR0NFQXaSkWbQ0WqYuOFd2PkftIZKw8KwF15BdJlMIvkiiFXyRRCr9IohR+kUQp/CKJUvhFEqXwiyRK4RdJlMIvkiiFXyRRCr9Iompd2OPuoQUVeVoQnbFz587cNQAffPBB7ppIOzGILdCBWAut6EKWyAIdgP379+euOXjwYGisyP6IzA9ircEgdh+umo78IolS+EUSpfCLJCrarusbZrbFzF43s2fNrLfSWYpI6aLtutYCH3f3XwTeBr5c8rxEpGKhdl3u/qK7n/m8oHXAogrmJiIVKuM5/73AC62uVLsukampUPjN7GFgBHii1TZq1yUyNYXf5GNm9wB3AMuyfn0ichEJhd/MlgMPAb/q7vnfXiUiF1y0XdffAz3AWjPbaGbfqXieIlKyaLuuRyuYi4jUSO/wE0lUrav6hoeH2bNnTy1jvf/++6G6SFulOXPmhMa65JJLQnWRNk4nT54MjRVZMQdw4MCB3DXRlZiR1YDRVX3ROUbankVbpU2WjvwiiVL4RRKl8IskSuEXSZTCL5IohV8kUQq/SKIUfpFEKfwiiVL4RRKl8IskSuEXSZTCL5KoWlf1jYyMhHrhRVax1Snavy3aq6+npyd3TbRXXGSVIzRu67wGBwdDYw0MDOSu2b17d2isQ4cOheoiK/Sq/nQ8HflFEqXwiyQq1K6r6bovmZmb2fxqpiciVYm268LMFgO3Ae+VPCcRqUGoXVfmr2h8fLc+s1/kIhR6zm9mK4Fd7v7aJLb9qF1X9PPgRKR8uV9DM7Mu4E9oPOSfkLuvAdYALFy4UI8SRKaIyJH/Y8CVwGtmtoNGh94NZragzImJSLVyH/nd/Q3g0jPfZ38Alrp7/s9qFpELJtquS0QuctF2Xc3XX1HabESkNnqHn0iial0xc+rUKXbs2JG77tJLL514ozFmzpyZuwZg3rx5uWv6+vpCY0XbMUUWwETH+vDD8d7iMbHIApjoWHv37s1dE2nxBfEFUpFFXJ2dnblr8tw3dOQXSZTCL5IohV8kUQq/SKIUfpFEKfwiiVL4RRKl8IskSuEXSZTCL5IohV8kUQq/SKIUfpFEWdUtgc4azGw/8L8trp4PTIVPA9I8zqZ5nG2qz2OJu18ymV9Qa/jPx8xedvelmofmoXnUMw897BdJlMIvkqipFP41F3oCGc3jbJrH2f7fzGPKPOcXkXpNpSO/iNRI4RdJVK3hN7PlZrbVzLab2epxru8ws+9l1683sysqmMNiM/uJmW0ys7fM7IFxtvmUmQ2a2cbs60/LnkfTWDvM7I1snJfHud7M7G+zffK6md1Q8vjXNv0/N5rZkJk9OGabyvaHmT1mZvvM7M2mn801s7Vmti37d9yPRzazu7NttpnZ3RXM4xtmtiXb78+aWW+L2vPehiXM46tmtqtp/69oUXvefJ3D3Wv5AtqAd4CrgBnAa8B1Y7b5PeA72eVVwPcqmEc/cEN2uQd4e5x5fAr4YU37ZQcw/zzXrwBeAAy4CVhf8W20h8YbRWrZH8AtwA3Am00/+3NgdXZ5NfD1cermAu9m//Zll/tKnsdtwPTs8tfHm8dkbsMS5vFV4I8ncdudN19jv+o88t8IbHf3d939FPAUsHLMNiuBx7PLTwPLLPpB6S24+25335BdPgxsBi4vc4ySrQT+yRvWAb1m1l/RWMuAd9y91bswS+fuPwPGfmB/8/3gceDT45T+BrDW3T9094PAWmB5mfNw9xfdfST7dh2NprSVarE/JmMy+TpLneG/HNjZ9P0A54buo22ynT4I5O+iMUnZ04rrgfXjXH2zmb1mZi+Y2S9UNQfAgRfN7BUz+8I4109mv5VlFfBki+vq2h8Al7n77uzyHuCycbapc78A3EvjEdh4JroNy3B/9vTjsRZPg3Lvj2RP+JnZLOD7wIPuPjTm6g00Hvr+EvB3wL9VOJVPuvsNwO3A75vZLRWO1ZKZzQDuBP51nKvr3B9n8cZj2gv6erSZPQyMAE+02KTq2/DbwMeAXwZ2A39Zxi+tM/y7gMVN3y/KfjbuNmY2HZgDfFD2RMysnUbwn3D3Z8Ze7+5D7n4ku/w80G5m88ueR/b7d2X/7gOepfHwrdlk9lsZbgc2uPs5va/q3B+ZvWee2mT/7htnm1r2i5ndA9wB/Hb2h+gck7gNC3H3ve4+6u6ngX9o8ftz7486w/9z4BozuzI7yqwCnhuzzXPAmbO2nwF+3GqHR2XnEB4FNrv7N1tss+DMuQYzu5HGfqrij1C3mfWcuUzjBNObYzZ7Dvjd7Kz/TcBg00PiMt1Fi4f8de2PJs33g7uBH4yzzY+A28ysL3sYfFv2s9KY2XLgIeBOdz/WYpvJ3IZF59F8jue3Wvz+yeTrbGWcocxxJnMFjbPr7wAPZz/7Mxo7F6CTxsPO7cB/A1dVMIdP0ngY+TqwMftaAXwR+GK2zf3AWzTOmK4DPlHR/rgqG+O1bLwz+6R5LgZ8K9tnbwBLK5hHN40wz2n6WS37g8YfnN3AMI3nqZ+ncZ7nJWAb8B/A3GzbpcAjTbX3ZveV7cDnKpjHdhrPo8/cT868ErUQeP58t2HJ8/jn7LZ/nUag+8fOo1W+zvelt/eKJCrZE34iqVP4RRKl8IskSuEXSZTCL5IohV8kUQq/SKL+D4G8e7GD8no+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = tf.random.normal((256,256,1))\n",
    "generated_image = generator((style_vector, noise))\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define discriminator\n",
    "    #residual connections\n",
    "\n",
    "#https://github.com/manicman1999/StyleGAN2-Tensorflow-2.0/blob/master/stylegan_two.py\n",
    "\n",
    "def d_block(inputs, filters, pooling=True):\n",
    "    residual = Conv2D(filters, 1)(inputs)\n",
    "\n",
    "    out = Conv2D(filters, (3,3), padding='same')(inputs)\n",
    "    out = LeakyReLU(0.2)(out)\n",
    "    out = Conv2D(filters, (3,3), padding='same')(out)\n",
    "    out = LeakyReLU(0.2)(out)\n",
    "\n",
    "    out = Add()([residual, out])\n",
    "\n",
    "    if pooling:\n",
    "        out = AveragePooling2D()(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def make_discriminator_model():\n",
    "    inputs = Input(shape=(256, 256, 1))\n",
    "\n",
    "    x = d_block(inputs, depth)\n",
    "    x = d_block(x, depth * 2)\n",
    "    x = d_block(x, depth * 4)\n",
    "    x = d_block(x, depth * 8)\n",
    "    x = d_block(x, depth * 16, pooling=False)\n",
    "\n",
    "    #classification stuff\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs= inputs, outputs = x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create discriminator\n",
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#losses and inference"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a3b76dc9f98c3b7c2833723de1f287f5b2fddd8af30239771319b1a6738189a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
