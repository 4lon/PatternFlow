{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcadaba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: '../datasets/DogData/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ecc6a8788085>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'../datasets/DogData/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;31m#a = data_loader(1, 3, './train_image')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-ecc6a8788085>\u001b[0m in \u001b[0;36mdata_loader\u001b[1;34m(step, batch_size, path, num_workers)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# 비복원 추출로 1000개 제한\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-ecc6a8788085>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, step, path)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: '../datasets/DogData/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils import data\n",
    "import torch\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "\n",
    "class TrainDataset(data.Dataset) :\n",
    "    def __init__(self, step, path) :\n",
    "        self.path = path\n",
    "        self.samples = os.listdir(self.path)\n",
    "        self.step = step\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "        \n",
    "        sample = os.path.join(self.path, self.samples[index])\n",
    "        image = Image.open(sample)\n",
    "\n",
    "        # step별 resize\n",
    "        width = 2 ** (self.step + 1)\n",
    "        image = image.resize((width, width))\n",
    "        image_array = np.array(image, dtype=np.float32).transpose(2,0,1) / 255.\n",
    "\n",
    "        return image_array\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.samples)\n",
    "\n",
    "class MaxSampler(data.Sampler) :\n",
    "    def __init__(self, data_source, max_sample) :\n",
    "        self.data_source = data_source\n",
    "        \n",
    "        if len(self.data_source ) < max_sample :\n",
    "            self.num_samples = len(self.data_source)\n",
    "        else :\n",
    "            self.num_samples = max_sample\n",
    "\n",
    "    def __iter__(self) :\n",
    "        return iter(torch.randperm(self.num_samples).tolist())\n",
    "\n",
    "    def __len__(self) :\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "def data_loader(step, batch_size, path, num_workers = 0) :\n",
    "    dataset = TrainDataset(step, path)\n",
    "    sampler = MaxSampler(dataset, 100)\n",
    "    loader = data.DataLoader(dataset = dataset,\n",
    "                            batch_size = batch_size,\n",
    "                            num_workers = num_workers,\n",
    "                            sampler = sampler)\n",
    "    return loader\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    a = data_loader(1, 128, 'D:/githubcomp3710/PatternFlow/recognition/s4547377_haoxiang/images/keras_png_slices_data/keras_png_slices_data')\n",
    "    len(a)\n",
    "\n",
    "    for i, b in enumerate(a) :\n",
    "        print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a62087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\torch\\nn\\functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 64, 64])\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "# Channels Per Layer\n",
    "# list        0   1   2   3   4   5   6   7   8    9       \n",
    "CHANNELS = [512,512,512,512,512,256,128, 64, 32,  16]\n",
    "\n",
    "# Pixels Per Layer\n",
    "PIXELS =   [  0,  4,  8, 16, 32, 64,128,256,512,1024]\n",
    "\n",
    "# Noise Ratio Per Layer\n",
    "NOISE_PROB = [0,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1, 0.1]\n",
    "\n",
    "EPSILON = 1e-8\n",
    "\n",
    "# Latent Size\n",
    "Z_SIZE = 512\n",
    "\n",
    "# Mapping Network Units\n",
    "MAPPING_UNITS = 512\n",
    "\n",
    "# Mapping Network\n",
    "class MappingNet(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(MappingNet, self).__init__()\n",
    "\n",
    "        # FCL List\n",
    "        self.dense = nn.ModuleList([nn.Linear(Z_SIZE, MAPPING_UNITS)])\n",
    "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "        for i in range(7) :\n",
    "            self.dense.append(nn.Linear(MAPPING_UNITS, MAPPING_UNITS))\n",
    "\n",
    "    def forward(self, x) :\n",
    "        \n",
    "        for i in range(0,4) :\n",
    "            rc = x\n",
    "            x = self.dense[ i*2 ](x)\n",
    "            x = self.act(x)\n",
    "            x = self.dense[ i*2 +1 ](x)\n",
    "            x = rc + x\n",
    "            x = self.act(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Define Generator\n",
    "class Generator(nn.Module) :\n",
    "    def __init__(self, block_count = 9) :\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Sub Module Create \n",
    "        # self.mapping = MappingNet()\n",
    "        self.block = nn.ModuleDict()\n",
    "        self.to_RGB = nn.ModuleDict()\n",
    "\n",
    "        # Const Initialize (4 x 4)\n",
    "        self.const = torch.ones(1, CHANNELS[1], PIXELS[1], PIXELS[1])\n",
    "                     \n",
    "\n",
    "        # Layers\n",
    "        for i in range(1, block_count+1) :\n",
    "            # Style Block\n",
    "            self.block[str(i)] = GBlock(i)\n",
    "\n",
    "            # To RGB Convert Layer\n",
    "            self.to_RGB[str(i)] = ToRGB(i)\n",
    "\n",
    "\n",
    "    def forward(self, w, step, noise = None, alpha=1):\n",
    "        ###########################################\n",
    "        # w : Embedded Latent Vector \n",
    "        #     shape = ( b, MAPPING_UNITS )\n",
    "        #   \n",
    "        # step : Progressive Step \n",
    "        #\n",
    "        # noise : Noise List \n",
    "        #     shape = layers * ( h * w )\n",
    "        # \n",
    "        # alpha : Smoothing Parameter ( init 0 to 1 )\n",
    "        #         0 : Upsample Result\n",
    "        #         1 : StyleBlock Result \n",
    "        ###########################################\n",
    "\n",
    "        # Get Batch Size\n",
    "        b, _ = w.shape\n",
    "        \n",
    "        # Const Vector Start\n",
    "        x = self.const.expand(b, CHANNELS[1], 4, 4)\n",
    "\n",
    "        # Main Generator\n",
    "        for i in range(1, step+1) :\n",
    "\n",
    "            if (i == step) and (i != 1) :\n",
    "                ux = F.interpolate(x, scale_factor=2)\n",
    "                # ux = F.upsample(x, scale_factor= 2, mode='bilinear')\n",
    "\n",
    "            # if noise is None :\n",
    "            noise = torch.randn(1, 1, PIXELS[i], PIXELS[i])\n",
    "\n",
    "            x = self.block[str(i)]( x, w, noise )\n",
    "\n",
    "        # To RGB with Smoothing\n",
    "        if step == 1 :\n",
    "            y = self.to_RGB[str(i)](x)\n",
    "            \n",
    "        else : \n",
    "            ux = self.to_RGB[str(i-1)](ux)\n",
    "            x = self.to_RGB[str(i)](x)\n",
    "            y = ux * (1 - alpha) + (x * alpha)\n",
    "\n",
    "        return y\n",
    "\n",
    "        \n",
    "                    \n",
    "# Define Style Block \n",
    "class GBlock(nn.Module) :\n",
    "    def __init__(self, step) :\n",
    "        super(GBlock, self).__init__()\n",
    "\n",
    "        # Current Step\n",
    "        self.step = step\n",
    "\n",
    "        # Pixel, Channel of Current Layer\n",
    "        self.pixel = PIXELS[self.step]\n",
    "        self.prev_channel = CHANNELS[self.step - 1]\n",
    "        self.channel = CHANNELS[self.step]\n",
    "        # self.noise_prob = NOISE_PROB[self.step]\n",
    "\n",
    "        # Main Convolution layer\n",
    "        self.conv0 = nn.Conv2d(self.prev_channel, self.channel, 3, padding = 1)\n",
    "        self.conv1 = nn.Conv2d(self.channel, self.channel, 3, padding = 1)\n",
    "\n",
    "        # Layer Shape \n",
    "        self.layer_shape = [2, -1, self.channel, 1, 1]\n",
    "        self.noise_shape = [1, self.channel, self.pixel, self.pixel]\n",
    "\n",
    "        # Style Mapping ( mu + sigma ) \n",
    "        self.style = nn.Linear(MAPPING_UNITS, 2 * self.channel)\n",
    "\n",
    "        # Noise Factor Per Channel\n",
    "        self.noise_factor = nn.Parameter( torch.zeros(1, self.channel, 1, 1 ) )\n",
    "\n",
    "        # Upsample\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "\n",
    "        # Activation\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "          \n",
    "\n",
    "\n",
    "    def forward(self, x, w, noise) :\n",
    "\n",
    "        # Not Using Upsample Layer in First Block\n",
    "        if self.step != 1 :\n",
    "            x = self.upsample(x)\n",
    "        \n",
    "        x = self.conv0(x)\n",
    "\n",
    "        # Add Noise\n",
    "        x = x + noise * self.noise_factor #* self.noise_prob\n",
    "        x = self.act(x)\n",
    "\n",
    "        # Adaptive Instance Normalization\n",
    "        x = x - torch.mean(x, dim=(2,3), keepdim=True)\n",
    "        p = torch.rsqrt(torch.mean(x**2, dim=(2,3), keepdim=True) + EPSILON) \n",
    "        x = torch.mul(p,x)\n",
    "        \n",
    "        style = self.style(w)\n",
    "        style = style.view(self.layer_shape)\n",
    "        x = x * style[0] + style[1]\n",
    "\n",
    "        # Repeat \n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = x + noise * self.noise_factor #* self.noise_prob\n",
    "        x = self.act(x)\n",
    "\n",
    "        x = x - torch.mean(x, dim=(2,3), keepdim=True)\n",
    "        p = torch.rsqrt(torch.mean(x**2, dim=(2,3), keepdim=True) + EPSILON) \n",
    "        x = torch.mul(p,x)\n",
    "\n",
    "        style = self.style(w)\n",
    "        style = style.view(self.layer_shape)\n",
    "        x = x * style[0] + style[1]\n",
    "\n",
    "        return x\n",
    "\n",
    "# ToRGB\n",
    "class ToRGB(nn.Module) :\n",
    "    def __init__(self, step) :\n",
    "        super(ToRGB, self).__init__()\n",
    "        self.conv = nn.Conv2d(CHANNELS[step] ,3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# FromRGB\n",
    "class FromRGB(nn.Module) :\n",
    "    def __init__(self, step) :\n",
    "        super(FromRGB, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, CHANNELS[step], 1)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        return self.conv(x)\n",
    "         \n",
    "\n",
    "# Define Discriminator \n",
    "class Discriminator(nn.Module) :\n",
    "    def __init__(self, block_count = 9) :\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.block = nn.ModuleDict()\n",
    "        self.from_RGB = nn.ModuleDict()\n",
    "\n",
    "        for i in range(block_count, 0, -1) :\n",
    "            self.block[str(i)] = DBlock(i)\n",
    "            self.from_RGB[str(i)] = FromRGB(i)\n",
    "            \n",
    "\n",
    "\n",
    "    def forward(self, x, step) :\n",
    "        # From RGB, Using First Block Only\n",
    "        x = self.from_RGB[str(step)](x)\n",
    "\n",
    "        # Main Block\n",
    "        for i in range(step, 0, -1) :\n",
    "            x = self.block[str(i)](x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DBlock(nn.Module):\n",
    "    def __init__(self, step):\n",
    "        super(DBlock, self).__init__()\n",
    "\n",
    "        self.step = step\n",
    "        self.pixel = PIXELS[self.step]\n",
    "        self.channel = CHANNELS[self.step]\n",
    "        self.next_channel = CHANNELS[self.step - 1]\n",
    "\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "        self.stddev = MinibatchStandardDeviation()\n",
    "\n",
    "        if self.step != 1 :\n",
    "            self.conv1 = nn.Conv2d(self.channel, self.channel, 3, padding=1)\n",
    "            self.conv2 = nn.Conv2d(self.channel, self.next_channel, 3, padding=1) \n",
    "            self.avgpool = nn.AvgPool2d(2)\n",
    "\n",
    "        else :\n",
    "            self.conv1 = nn.Conv2d(self.channel+1, self.channel, 3, padding=1)\n",
    "            self.conv2 = nn.Conv2d(self.channel, self.channel, 4, padding=0)\n",
    "            self.fc = nn.Linear(self.next_channel, 1)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x) :\n",
    "\n",
    "        # MiniBatch Standard Deviation\n",
    "        if self.step == 1 :\n",
    "            x = self.stddev(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        if self.step != 1 :\n",
    "            x = self.avgpool(x)\n",
    "        else :\n",
    "            x = x.view(x.shape[0], -1)\n",
    "            x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class MinibatchStandardDeviation(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(MinibatchStandardDeviation, self).__init__()\n",
    "\n",
    "    def forward(self, x) :\n",
    "        b, c, h, w = x.shape\n",
    "\n",
    "        # Calculate STD\n",
    "        y = x - x.mean(dim = 0, keepdim = True)\n",
    "        y = (y**2).mean(0)\n",
    "        y = torch.sqrt(y + EPSILON)\n",
    "\n",
    "        # Average To Single Value\n",
    "        y = y.mean()\n",
    "        \n",
    "        # Expand and Concat Channel\n",
    "        y = y.expand((b, 1, h, w))\n",
    "        x = torch.cat([x, y], 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 테스트\n",
    "if __name__ == \"__main__\" :\n",
    "    z = torch.randn(1, 512)\n",
    "    print(z.shape)\n",
    "    step = 5\n",
    "\n",
    "    m = MappingNet()\n",
    "    g = Generator(step)\n",
    "    d = Discriminator(step)\n",
    "\n",
    "    w = m(z)\n",
    "    print(w.shape)\n",
    "\n",
    "    y = g(w, step)\n",
    "    print(y.shape)\n",
    "\n",
    "    z = d(y, step)\n",
    "    print(z.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def set_requires_grad(module, flag) :\n",
    "    for p in module.parameters() :\n",
    "        p.requires_grad = flag\n",
    "\n",
    "def train(num_block, generator, discriminator, \n",
    "          batch_size, epochs, path_image) :\n",
    "\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "\n",
    "    # Progressive \n",
    "    for step in range(2, num_block + 1) :\n",
    "\n",
    "        #for epoch in tqdm(range(1, epochs[step] + 1)):\n",
    "        for epoch in range(1, epochs[step] + 1):\n",
    "\n",
    "            loader = data_loader(step, batch_size, path=path_image, num_workers=1)\n",
    "\n",
    "            \n",
    "            print(f'step = {step}, epoch = {epoch}')\n",
    "\n",
    "\n",
    "            for real_image in loader :\n",
    "                z = [torch.rand(100), torch.rand(100)]\n",
    "                #z.append()\n",
    "                #z.append(torch.rand(100))\n",
    "                \n",
    "                if torch.cuda.is_available() :\n",
    "                    real_image = real_image.cuda()\n",
    "                    z[0] = z[0].cuda()\n",
    "                    z[1] = z[1].cuda()\n",
    " \n",
    "            \n",
    "                # Discriminator \n",
    "                discriminator.zero_grad()            \n",
    "                set_requires_grad(generator, False)\n",
    "                set_requires_grad(discriminator, True)\n",
    "\n",
    "                real_image.requires_grad = True\n",
    "                real_predict = discriminator(real_image, step)\n",
    "                real_predict = F.softplus(-real_predict).mean()\n",
    "                real_predict.backward(retain_graph=True)\n",
    "\n",
    "                # R1 \n",
    "                grad_real = torch.autograd.grad(outputs=real_predict.sum(), inputs=real_image, create_graph=True)[0]\n",
    "                grad_penalty = (grad_real.view(grad_real.size(0), -1).norm(2, dim=1)**2).mean()\n",
    "                grad_penalty = 10 / 2 * grad_penalty\n",
    "                grad_penalty.backward()\n",
    "\n",
    "\n",
    "                # Loss\n",
    "                fake_image = generator(z[0], step)\n",
    "                fake_predict = discriminator(fake_image, step)\n",
    "                \n",
    "                fake_predict = F.softplus(fake_predict).mean()\n",
    "                fake_predict.backward()\n",
    "                \n",
    "                d_losses.append((real_predict + fake_predict).item())\n",
    "\n",
    "                d_optim = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "                d_optim.step()\n",
    "\n",
    "                del fake_image, real_image, grad_penalty, grad_real\n",
    "\n",
    "                # Generator \n",
    "                generator.zero_grad()\n",
    "                set_requires_grad(discriminator, False)\n",
    "                set_requires_grad(generator, True)\n",
    "\n",
    "                fake_image = generator(z[0], step)\n",
    "                fake_predict = discriminator(fake_image, step)\n",
    "                fake_predict = F.softplus(-fake_predict).mean()\n",
    "                fake_predict.backward()\n",
    "                \n",
    "                g_optim = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "                g_optim.step()\n",
    "\n",
    "                g_losses.append(fake_predict.item())\n",
    "\n",
    "    return d_losses, g_losses\n",
    "\n",
    "def save_model(file_model, generator, discriminator ) :\n",
    "    torch.save({\n",
    "        'generator' : generator.state_dict(),\n",
    "        'discriminator' : discriminator.state_dict()\n",
    "        }, file_model)\n",
    "\n",
    "def load_model(file_model) :\n",
    "    model_dict = torch.load(file_model)\n",
    "    return model_dict\n",
    "\n",
    "\n",
    "def main(num_block, epochs_list, batch_size, is_train, is_continue, is_save) :\n",
    "\n",
    "    \n",
    "    #path_image = os.path.join(os.getcwd(), 'train_image/')\n",
    "    path_image = os.path.join(os.getcwd(), 'D:/githubcomp3710/PatternFlow/recognition/s4547377_haoxiang/images/keras_png_slices_data/keras_png_slices_data'),)\n",
    "    path_model = os.path.join(os.getcwd(), 'save_model/')\n",
    "    print(f' Path of Image : {path_image}')\n",
    "\n",
    "    model_name = 'model.pth'\n",
    "\n",
    "    if(num_block <= 1) :\n",
    "        print('Not enough block, Terminated')\n",
    "        return \n",
    "\n",
    "    generator = Generator(9)\n",
    "    discriminator = Discriminator(9)\n",
    "\n",
    "    if torch.cuda.is_available() == True : \n",
    "        generator = generator.cuda()\n",
    "        discriminator = discriminator.cuda()\n",
    "    \n",
    "    if is_continue :  \n",
    "        file_model = os.path.join(path_model, model_name)\n",
    "\n",
    "        if os.path.exists(file_model) :  \n",
    "            model_dict = load_model(file_model)\n",
    "            generator.load_state_dict(model_dict['generator'])\n",
    "            discriminator.load_state_dict(model_dict['discriminator'])\n",
    "    \n",
    "\n",
    "    if is_train :\n",
    "        train(num_block, generator, discriminator,\n",
    "                 batch_size, epochs_list, path_image)\n",
    "        print(f'Train End')\n",
    "\n",
    "    if is_save :\n",
    "        if os.path.exists(path_model) == False :\n",
    "            os.mkdir(path_model)\n",
    "        file_model = os.path.join(path_model, model_name)\n",
    "        save_model(file_model, generator, discriminator)\n",
    "\n",
    "    for i in range(5) :\n",
    "        ###############################33\n",
    "        z = torch.rand(100)\n",
    "        if torch.cuda.is_available() :\n",
    "            z = z.cuda()\n",
    "\n",
    "        image = generator(z, num_block).cpu().detach().numpy()[0]\n",
    "        image = image.transpose((1,2,0))\n",
    "        img = Image.fromarray(np.uint8(image*255))\n",
    "        img.save(os.path.join('save_image/',f'save{i}.png'), format='png')\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "\n",
    "    num_block = 5\n",
    "    epochs_list = [-1, -1, 50, 50, 50, 50, 50, 0, 0, 0, 0]\n",
    "    batch_size = 4\n",
    "\n",
    "    main(num_block, epochs_list, batch_size, \n",
    "        is_train = True, is_continue = False, is_save = True)\n",
    "    \n",
    "    print('End of main')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
