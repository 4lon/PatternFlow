{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7nMWamKiJbisWM/P21Uid"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qoD8PSxAQ33",
        "outputId": "3ac71052-f3b6-46d5-db7b-542fad19ddde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 14 07:06:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P0    44W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "recognition/s45533675/Demo3.ipynb"
      ],
      "metadata": {
        "id": "X2kTWolYqnsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requirement: Implement a brain MRI super-resolution network by training on the ADNI brain dataset. Create down-sampled data (approximately by a factor of 4) using Tensorflow implementations. The network should be trained to up-scale from 4x down-sampled input and produce a â€œreasonably clear image\"."
      ],
      "metadata": {
        "id": "hiY8DCW_FHL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up Environment\n"
      ],
      "metadata": {
        "id": "1XlMcN5SrrVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "pIm9mNqDB0Wv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "GHAofah6riE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download dataset.\n",
        "I use the built-in keras.utils.get_file utility to retrieve the dataset."
      ],
      "metadata": {
        "id": "mU4jnWMkvI0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://cloudstor.aarnet.edu.au/plus/s/L6bbssKhUoUdTSI/download\"\n",
        "data_dir = keras.utils.get_file(origin=dataset_url, fname=\"ADNI\", extract=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBQm519ErgqS",
        "outputId": "cbcc2c13-db51-4403-89df-45d673ef4578"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://cloudstor.aarnet.edu.au/plus/s/L6bbssKhUoUdTSI/download\n",
            "185710993/185710993 [==============================] - 12s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Because this task is not a classification problem, I just use the images in the AD train as my whole dataset.\n",
        "*   The number of images is 10400 and it completely fits the training requirement.\n",
        "*   The origin path is ADNI_AD_NC_2D\\AD_NC\\train\\AD and I rename the ADNI_AD_NC_2D to ADNI and newpath is ADNI\\AD_NC\\train\\AD."
      ],
      "metadata": {
        "id": "hWWl77q4wZAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = os.path.join(\"/root/.keras/datasets/AD_NC/train/AD\")\n"
      ],
      "metadata": {
        "id": "qr5_v3H9upG7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I create training and validation datasets via image_dataset_from_directory.\n",
        "\n",
        "The image size is 256 x 240. The number of images is 10400 so I set 10% valication set which is 1040."
      ],
      "metadata": {
        "id": "C3gv0Ba3xFaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    root_dir,\n",
        "    labels=None,\n",
        "    label_mode=None,\n",
        "    class_names=None,\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=64,\n",
        "    image_size=(256, 240),\n",
        "    shuffle=True,\n",
        "    seed=1334,\n",
        "    validation_split=0.1,\n",
        "    subset=\"training\",\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        ")\n",
        "\n",
        "valid_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    root_dir,\n",
        "    labels=None,\n",
        "    label_mode=None,\n",
        "    class_names=None,\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=64,\n",
        "    image_size=(256, 240),\n",
        "    shuffle=True,\n",
        "    seed=1334,\n",
        "    validation_split=0.1,\n",
        "    subset=\"validation\",\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOh-R7FdxIIF",
        "outputId": "c10abf82-26a4-4b41-eb3d-9ca658b3fba4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10400 files belonging to 1 classes.\n",
            "Using 9360 files for training.\n",
            "Found 10400 files belonging to 1 classes.\n",
            "Using 1040 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization\n",
        "\n",
        "I rescale the images to take values in the range [0, 1]."
      ],
      "metadata": {
        "id": "pgR3Tabl_s0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaling(input_image):\n",
        "    input_image = input_image / 255.0\n",
        "    return input_image\n",
        "\n",
        "\n",
        "# Scale from (0, 255) to (0, 1)\n",
        "train_dataset = train_dataset.map(scaling)\n",
        "valid_dataset = valid_dataset.map(scaling)"
      ],
      "metadata": {
        "id": "gJ0xvuY-_shh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataset.take(1):\n",
        "    for img in batch:\n",
        "        display(array_to_img(img))"
      ],
      "metadata": {
        "id": "fI5uFTy7Ah0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use images in AD_NC/test/AD as test images for visual evaluation at the end.\n"
      ],
      "metadata": {
        "id": "FZoMUnfIBUhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = os.path.join(\"/root/.keras/datasets/AD_NC/test/AD\")\n",
        "\n",
        "test_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(test_path, fname)\n",
        "        for fname in os.listdir(test_path)\n",
        "        if fname.endswith(\".jpeg\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "xJLBxKhoBU7w"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WyljITcMBu8O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qcauwgacCKZw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}