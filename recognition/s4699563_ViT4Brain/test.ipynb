{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT4Brain\n",
    "This project utilize Vision <a href='https://arxiv.org/abs/2010.11929'>Transformer(ViT)</a> to classify Alzheimerâ€™s disease (normal and AD) of the <a href='http://adni.loni.usc.edu/'>ADNI brain data</a>.\n",
    "\n",
    "The input image will first be splitted into fixed-size pactches, with posional embeddings obtained by linear projection. And then, the patches will be fed into transformer encoder, afther that a multilayer perceptron(MLP) will handle the output to perfrom final clssification.\n",
    "<img src=\"./vit.gif\" width=\"500px\"></img>\n",
    "\n",
    "\n",
    "The original idea of <a href='https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf'>transfomer</a> can be illustrated as follow, it utilizes multi-headed self-attention which can handle sequence data effectively by focusing on a certain part of the input.\n",
    "<img src=\"./transformer.png\" width=\"500px\"></img>\n",
    "\n",
    "### Data preparation\n",
    "Put the unzipped preprocessed image files in the `datasets` folder. The path of the dataset is supposed to be like `./datasets/AD_NC/train/AD`\n",
    "\n",
    "***Preprecessing***\n",
    "\n",
    "***Training/Validation/Testing Set Spliting***\n",
    "### Required Dependencies:\n",
    "\n",
    "* Python 3.6+\n",
    "* torch==1.11.0\n",
    "* torchvision==0.12.0\n",
    "* tensorboard==2.9.1\n",
    "* pandas==1.4.2\n",
    "* nump==1.21.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Usage\n",
    "```bash\n",
    "usage: main.py [-h] [--batch_size BATCH_SIZE] [--dim DIM] \n",
    "                [--lr LR] [--depth DEPTH][--heads HEADS] [--epochs EPOCHS] [--mlp_dim MLP_DIM]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  --batch_size BATCH_SIZE\n",
    "                        batch size\n",
    "  --dim DIM             neural network dimension\n",
    "  --lr LR               learning rate of the optimizer\n",
    "  --depth DEPTH         depth of the network\n",
    "  --heads HEADS         number of heads in the multihead attention\n",
    "  --epochs EPOCHS       number of epochs to train\n",
    "  --mlp_dim MLP_DIM     dimension of the mlp on top of the attention block\n",
    "```\n",
    "\n",
    "### Results\n",
    "\n",
    "### More file description**:\n",
    "* initialization_converage.py includes the implementation of coverage driven initialization.\n",
    "* utility.py includes a set of helper functions.\n",
    "* intermediate_files folder includes some useful intermediate_files for fast replication.\n",
    "* testbeds and datasets folder includes the raw file of all datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be96a02d3811e2a19ea5e1dae83c39640313aaefdc0e822e9fd50ff5f0caa095"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
